%% LyX 2.1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[12pt,oneside,english,reqno]{amsbook}
\renewcommand{\familydefault}{\rmdefault}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\usepackage{mathrsfs}
\usepackage{url}
\usepackage{amsthm}
\usepackage{amstext}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{setspace}
\doublespacing

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% A simple dot to overcome graphicx limitations
\newcommand{\lyxdot}{.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\numberwithin{section}{chapter}
\numberwithin{equation}{section}
\numberwithin{figure}{section}

\makeatother

\usepackage{babel}
\begin{document}


\global\long\def\sandwich#1#2#3{ \left\langle #1\left|#2\right|#3\right\rangle }
\global\long\def\ket#1{\left|#1\right>}
\global\long\def\braket#1#2{\left\langle #1\mid#2\right\rangle }
\global\long\def\bra#1{\left\langle #1\right|}
\global\long\def\indep{\perp\!\!\!\perp}




 \thispagestyle{empty}\pagenumbering{gobble}

\vphantom{}

\textbf{\large{}Quantum State Discrimination and Quantum Cloning: }{\large \par}

\textbf{\large{}\hspace{2.7cm}Optimization and Implementation }{\large \par}

\vspace{1.2cm}


{\huge{}\hspace{5cm}\hspace{1cm}\hspace{1cm}}by

\vspace{0.7cm}


{\huge{}\hspace{5cm}\hspace{1.1cm}}Andi Shehu

\vfill{}


\begin{singlespace}
A dissertation submitted to the Graduate Faculty in Physics in partial
fulfillment of the requirements for the degree of Doctor of Philosophy,
The City University of New York 
\end{singlespace}

\begin{center}
2015
\par\end{center}

\pagebreak{}

 \pagenumbering{roman}\setcounter{page}{2}\vphantom{}

\begin{singlespace}
\begin{center}
\vfill{}

\par\end{center}


\begin{center}
2015\\
Andi Shehu\\
Some rights reserved.\\
This work is licensed under a Creative Commons\\
Attribution 4.0 United States License.\\
\url{http://creativecommons.org/licenses/by/4.0/}
\par\end{center}
\end{singlespace}

\pagebreak{}

\vphantom{}

\vfill{}


\begin{center}
\begin{minipage}[c][1\totalheight][t]{1\columnwidth}%
\begin{singlespace}
\begin{center}
This manuscript has been read and accepted for the\\
Graduate Faculty in Physics in satisfaction of the \\
dissertation requirement for the degree of Doctor of Philosophy.
\par\end{center}\end{singlespace}
%
\end{minipage}
\par\end{center}

\vspace{3cm}


\begin{minipage}[t]{0.25\columnwidth}%
\begin{singlespace}
\rule[0.5ex]{1\columnwidth}{1pt}

Date\end{singlespace}
%
\end{minipage} \hfill{}%
\begin{minipage}[t]{0.6\columnwidth}%
\begin{singlespace}
\rule[0.5ex]{1\columnwidth}{1pt}

Prof. J�nos A. Bergou

Chair of Examining Committee\end{singlespace}
%
\end{minipage}

\vspace{2cm}


\begin{minipage}[t]{0.25\columnwidth}%
\begin{singlespace}
\rule[0.5ex]{1\columnwidth}{1pt}

Date\end{singlespace}
%
\end{minipage} \hfill{}%
\begin{minipage}[t]{0.6\columnwidth}%
\begin{singlespace}
\rule[0.5ex]{1\columnwidth}{1pt}

Prof. Igor L. Kuskovsky

Executive Officer\end{singlespace}
%
\end{minipage}

\vspace{1.5cm}


\begin{center}
\begin{minipage}[t]{0.8\columnwidth}%
\begin{singlespace}
Supervisory Committee:

\vspace{1cm}


Prof. Mark Hillery\hfill{}

\vspace{1cm}


Prof. Christopher C. Gerry\hfill{} 

\vspace{1cm}


Prof. Ed Fieldman\hfill{}

\vspace{1cm}


Prof. Neepa T. Maitra\hfill{}\end{singlespace}
%
\end{minipage}
\par\end{center}

\vspace{0.5cm}


\begin{center}
THE CITY UNIVERSITY OF NEW YORK
\par\end{center}

\pagebreak{}

{\huge{}\hspace{5cm}\hspace{1.2cm}}\textbf{\Large{}Abstract}{\Large \par}

\vspace{1.5cm}


\textbf{\large{}Quantum State Discrimination and Quantum Cloning: }{\large \par}

\textbf{\large{}\hspace{2.7cm}Optimization and Implementation }{\large \par}

\vspace{1.2cm}


{\huge{}\hspace{5cm}\hspace{1cm}\hspace{1cm}}by

\vspace{0.7cm}


{\huge{}\hspace{5cm}\hspace{1.1cm}}Andi Shehu

\vspace{1cm}


\textbf{Advisor:}\textbf{\small{} }J�nos A. Bergou

\vspace{1cm}


In our work we explore the field of quantum state discrimination and
quantum cloning. Recently the problem of optimal state discrimination
with a Fixed Rate of Inconclusive Outcomes (FRIO strategy) has been
solved for two pure quantum states and a few other highly symmetric
cases. An optical implementation to FRIO for pure states is provided.
The physical implementation can be carried out with the use of a six-port
interferometer constructed with optical fibers beam splitters, phase
shifters and mirrors. The input states are composed of qubits which
are realized as photons in the dual-rail representation. The non-unitary
measurements are carried out at the output for the presence or absence
of a photon. The setup optimally interpolates between minimum error
and unambiguous state discrimination. We also extend the FRIO strategy
to two mixed states, whose eigenvectors in their spectral representation
form a Jordan basis. We derive the minimum error rate $P_{E}$ for
a fixed inconclusive rate $Q$ and, in particular, the optimal distribution
of the total $Q$ over the Jordan subspaces. As $Q$ is varied between
the two limits, $0<Q<Q_{c}$, a structure with multiple thresholds,
$Q_{1}^{(th)}(=0)<Q_{2}^{(th)}<\ldots<Q_{N}^{(th)}<Q_{c}$, emerges.
We also solve the problem of state separation of two known pure states
in the general case where the known states have arbitrary prior probabilities.
The solution emerges from a geometric formulation of the problem.
This formulation also reveals a deeper connection between cloning
and state discrimination. The results are then applied in designing
a scheme for hybrid cloning which interpolates between approximate
and probabilistic exact cloning. It is shown that state separation
and hybrid cloning are generalized schemes to well established state
discrimination and cloning strategies. The relationships between cloning,
state separation and state discrimination are derived in several limints. 

\pagebreak{}

\tableofcontents{}

\listoffigures


 \pagenumbering{arabic}\pagebreak{}


\chapter{Quantum State Discrimination }

An integral part of quantum information and quantum processing is
measurement theory \cite{Bergou2013}. It is the probabilistic nature
of quantum mechanics that one cannot simply obtain information encoded
in states \cite{Nielsen2010}, the state is not an observable in quantum
mechanics \cite{Peres1995}. When a quantum circuit or processor has
acted on the input states to perform a task, the output needs to be
read out. Thus after the processing occurs the task is to determine
the state of the system. If the input states are orthogonal the process
is trivial. Simply setting up detectors along the orthogonal directions
and a click in those detectors will determine the state of the system.
On the other hand discriminating among non orthogonal quantum states
is not trivial. Since quantum mechanics does not allow for perfect
discrimination of non orthogonal states the task becomes that of a
measurement optimization problem. Not being able to perfectly discriminate
quantum states is key to various quantum cryptographic schemes and
quantum computing. The origin of the state discrimination field is
attributed to the works of Helstrom \cite{Helstrom1969} and Holevo
\cite{Holevo2011}. The field however gained momentum in the 90's
as quantum information theory became very active primarily due to
the factorization work of Peter Schor \cite{Shor1994} and quantum
key distribution protocols such as B92 \cite{Bennett1992}. 

Various optimum state discrimination measurement strategies have been
developed with respect to some figure of merit. Two of those methods
which we focus on are optimum Unambiguous Discrimination (UD) and
Minimum Error (ME). In UD strategy, first suggested by Ivanovic \cite{Ivanovic1987},
the observer Bob, is not allowed to make an error. Whenever he is
handed a state $|\psi_{i}\rangle$ he cannot conclude that he was
given $|\psi_{j}\rangle.$ We will show that this cannot be done with
100\% success rate and that the observer must allow for inconclusive
results and find an optimum measurement strategy which minimizes the
average rate of inconclusive results. In the Minimum Error strategy
the observer is not allowed to have inconclusive results. Thus errors
are allowed and the task is to find optimum measurements that minimize
the average error rate. It has been shown that ME and UD are special
cases of a more general scheme of optimum state discrimination measurement
which can be approached by relaxing the conditions at either end \cite{Chefles1998b}.
In the ME scheme the optimal error rate can be further reduced by
allowing for some rate of inconclusive results. Thus the optimal average
error rate, $P_{E},$ becomes a function of a given rate of allowed
inconclusive results $Q$, $P_{E}(Q)$. On the other hand, in UD,
the optimal rate of the average inconclusive outcomes, $Q,$ may be
reduced by allowing for some error rate $P_{E}$. The failure rate
becomes a function of a given error rate $Q(P_{E}).$ 

In our work we use various quantum measurements schemes to read out
information out of a quantum system. For a more thorough understanding
of quantum theory of measurements we go along the lines of the review
paper by J.A Bergou \cite{Bergou2010}. Starting with the standard
quantum measurement theory due essentially to von Neumann the generalized
measurements (Positive Operator Valued Measures, POVMs) are introduced
as more useful measurement schemes in optimization problems. Using
Neumark's theorem the POVMs can be realized experimentally. 


\subsection{Standard Quantum Measurements}

We start with the postulates of standard or projective quantum measurements
introduced by von Neumann \cite{Neumann1955} analyzing a model for
the coupling of the system with the meter or ancilla and generalizing
the predictions of the model. 

The postulates are:
\begin{enumerate}
\item Observables in quantum mechanics have a Hermintian operator $\chi$
which has a spectral representation $\chi=\sum_{j}^{N}\lambda_{j}\ket j\bra j$,
where the eigenvalues are real and assuming non-degeneracy for simplicity.
The eigenvectors $\left\{ \ket j\right\} $ form a complete orthonormal
basis set.
\item The Hilbert space is spanned by the projectors $P_{j}=\ket j\bra j$,
such that $\sum_{j}P_{j}=1.$ 
\item The eigenvalues of the projectors are $0$ or $1$ due to the orthogonality
of the states $P_{i}P_{j}=P_{i}\delta_{ij}$.
\item Any measurement of the $\chi$ will yield one of the eigenvalues $\lambda_{j}$.
\item If $\lambda_{j}$ is obtained in a measurements, the state of the
system collapses onto: $\ket{\phi_{j}}=\frac{P_{j}\ket{\psi}}{\sqrt{\sandwich{\psi}{P_{j}}{\psi}}}$
if the system was initially in a pure state, $\rho_{j}=\frac{P_{j}\rho P_{j}}{Tr(P_{j}\rho)}$
if the system was initially in a mixed state. 
\item The probability of obtaining $\ket{\phi_{j}}$ is $p_{j}=\left|\left|P_{j}\psi\right|\right|^{2}=\sandwich{\psi}{P_{j}^{2}}{\psi}=\sandwich{\psi}{P_{j}}{\psi}$.
The probability of obtaining $\rho_{j}$ is $p_{j}=Tr(P_{j}\rho P_{j})=Tr(P_{j}^{2}\rho)=Tr(P_{j}\rho)$. 
\item If a measurement is performed but the result is not recorded the post-measurement
state collapses onto: $\rho=\sum_{j}P_{j}\ket{\psi}\bra{\psi}P_{j}$
if the system was initially in a pure state, $\tilde{\rho}=\sum_{j}p_{j}\rho_{j}=\sum_{j}P_{j}\rho P_{j}$
if the system was initially in a mixed state.
\end{enumerate}

\subsection{POVMs}

Due to the orthogonality condition of the projective measurements
one cannot have more orthogonal projections than the dimensionality,
hence the possible outcomes cannot exceed the number of the dimensionality.
Sometimes we would like to allow for more outcomes than the dimensionality,
as in the case of optimal UD measurements where we have three outcomes
in a two dimensional problem. 

Next we introduce a positive operator $\Pi_{j}\geq0$ as a generalization
of $P_{j}^{2}$ and the probability of obtaining state $j$ becomes
$p_{j}=Tr(\Pi_{j}\rho_{j})$. To normalize the probabilities we require
that the positive operators $\Pi_{j}$ are a decomposition of the
identity $\sum_{j}\Pi_{j}=I$. This is decomposition is called a Positive
Operator Valued Measure (POVM) and $\Pi_{j}$ the elements of the
POVM. 

The generalization of the postulates of quantum mechanics in terms
of the POVM can be expressed as:
\begin{enumerate}
\item The decomposition of the identity in terms of positive operators,
$\Pi_{j}\geq0$, $\sum_{j}\Pi_{j}=I$ is called a POVM.
\item The elements of the POVM can be expressed in terms of the detection
operators $\Pi_{j}=A_{j}^{\dagger}A_{j}$ where the operators satisfy
the requirements $\sum_{j}A_{j}^{\dagger}A_{j}=I$ but they need not
be Hermitian.
\item A detection yields an element on POVM.
\item The state of the system collapses onto: $\ket{\phi_{j}}=\frac{A_{j}\ket{\psi}}{\sqrt{\sandwich{\psi}{A_{j}^{\dagger}A_{j}}{\psi}}}$
if the system was initially in a pure state, $\rho_{j}=\frac{A_{j}^{\dagger}\rho A_{j}}{Tr(A_{j}\rho A_{j}^{\dagger})}=\frac{A_{j}^{\dagger}\rho A_{j}}{Tr(A_{j}^{\dagger}A_{j}\rho)}=\frac{A_{j}^{\dagger}\rho A_{j}}{Tr(\Pi_{j}\rho)}$
if the system was initially in a mixed state. 
\item The probability of obtaining $\rho_{j}$ is $p_{j}=Tr(A_{j}\rho_{j}A_{j}^{\dagger})=Tr(A_{j}^{\dagger}A_{j}\rho_{j})=Tr(\Pi_{j}\rho_{j})$.
\item If a measurement is performed but the result is not recorded the post-measurement
state collapses onto: $\tilde{\rho}=\sum_{j}p_{j}\rho_{j}=\sum_{j}A_{j}\rho A_{j}^{\dagger}$.
\end{enumerate}
It is these generalized measurements we will use in our optimization
work. In the following sections POVM elements are used to optimize
the unambiguous discrimination and minimum error schemes. 


\section{Unambiguous Discrimination}

In this section we give a review of the existing schemes of Unambiguous
Discrimination (UD). Particularly that of two pure states as it is
directly related with our work. When performing UD the detectors are
not allowed to make an error but can admit inconclusive outcomes.
We first show by contradiction that it is not possible to succeed
at unambiguously discriminating quantum states with 100\% success
rate. Then we show that in order to perform UD a third detector must
be added which accounts for inconclusive results. The task is to minimize
this rate of inconclusive outcomes. In Subsection (1.1.1) the problem
is solved via the POVM strategy. In the following Subsection (1.1.2)
we show how the solution can be implemented via the Neumark theorem. 


\subsection{Unambiguous Discrimination: Two pure states via POVM}

An ensemble of quantum states is prepared with two possible pure states
$|\psi_{1}\rangle$ or $|\psi_{2}\rangle.$ Each state is prepared
with an a priori probability $\eta_{1}$ or $\eta_{2}$, such that
$\eta_{1}+\eta_{2}=1.$ The observer has full knowledge of the states
and their priors. The preparer, Alice, picks up a state and hands
it over to the observer, Bob. Bob's task it to determine which state
he is given by performing a single a POVM on the individual system
he is given. 

As it was stated earlier, the observer is not allowed to make an error
when performing a measurement. Let us assume Bob can indeed discriminate
the given states with 100\% success rate. Let $\Pi_{1}$ and $\Pi_{2}$
be detectors which cover the full Hilbert space spanned by the states
$|\psi_{1}\rangle$ and $|\psi_{2}\rangle$, 

\begin{equation}
\Pi_{1}+\Pi_{2}=I\label{eq:2POVM}
\end{equation}


In the UD strategy the detector $\Pi_{i}$ identifies only the state
$|\psi_{i}\rangle$ and never clicks for $|\psi_{j}\rangle,$ such
that $\Pi_{i}|\psi_{j}\rangle=0.$ Multiplying Equation (\ref{eq:2POVM})
by $|\psi_{1}\rangle$ from the right and $\langle\psi_{1}|$ from
the left results in $p_{1}=\langle\psi_{1}|\Pi_{1}|\psi_{1}\rangle=1$,
which is the probability of successfully identifying $\mbox{|\ensuremath{\psi_{1}\rangle}}$.
Similarly it can be shown that the state $\ket{\psi_{2}}$ can be
detected with a probability one, $p_{2}=\langle\psi_{2}|\Pi_{2}|\psi_{2}\rangle=1.$
Seems as if one can indeed discriminate two non-orthogonal quantum
states with a 100\% success rate. However multiplying Equation. (\ref{eq:2POVM})
with $\langle\psi_{1}|$ from the left and $|\psi_{2}\rangle$ from
the right it follows that $\langle\psi_{1}|\psi_{2}\rangle=0,$ where
we use $\Pi_{i}|\psi_{j}\rangle=0.$ This means that the input states
are orthogonal to begin with, which is a contradiction because we
started with nonorthogonal quantum states. Thus one cannot discriminate
non-orthogonal quantum state with 100\% success rate (orthogonal states
can indeed be discriminated with no error rate, they correspond to
classical states). 

One can still perform Unambiguous Discrimination but with a modified
scheme. Equation (\ref{eq:2POVM}) is modified by adding a third detector
$\Pi_{0}$ which can click for both states $|\psi_{1}\rangle$ and
$|\psi_{2}\rangle:$

\begin{equation}
\Pi_{1}+\Pi_{2}+\Pi_{0}=I\label{eq:3povms}
\end{equation}


The clicks from $\Pi_{0}$ are all inconclusive, i.e we gain no information
from $\Pi_{0}.$ Defining individual failure rates $q_{1}=\langle\psi_{1}|\Pi_{0}|\psi_{1}\rangle$
and $q_{2}=\langle\psi_{2}|\Pi_{0}|\psi_{2}\rangle$ as the failure
probabilities, the task becomes that of minimizing the overall failure
rate, 
\begin{equation}
Q=\eta_{1}q_{1}+\eta_{2}q_{2}.\label{eq:Q}
\end{equation}


Equivalently optimizing the success rate 

\[
P_{E}=\eta_{1}p_{1}+\eta_{2}p_{2},
\]
such that $P_{E}+Q=1.$, 

Let us now explicitly determine the POVM operators to be used in the
optimization of $Q$, see Figure (\ref{UD}). First define the states
to be in a two dimensional plane, 

\begin{eqnarray*}
|\psi_{1}\rangle & = & \cos\theta|0\rangle+\sin\theta|1\rangle,\\
|\psi_{2}\rangle & = & \cos\theta|0\rangle-\sin\theta|1\rangle.
\end{eqnarray*}


The detectors must be orthogonal with the states for which they should
not identify, i.e $\Pi_{i}|\psi_{j}\rangle=0$, 

\begin{eqnarray*}
\Pi_{1} & = & c_{1}|\psi_{2}^{\perp}\rangle\langle\psi_{2}^{\perp}|,\\
\Pi_{2} & = & c_{2}|\psi_{1}^{\perp}\rangle\langle\psi_{1}^{\perp}|,
\end{eqnarray*}


where $|\psi_{2}^{\perp}\rangle=\sin\theta|0\rangle+\cos\theta|1\rangle$
and $|\psi_{1}^{\perp}\rangle=-\sin\theta|0\rangle+\cos\theta|1\rangle$.

The coefficients $c_{i}\geq0$ are yet to be determined based on the
optimum strategies. 

Using the definition of success probabilities $p_{i}=\langle\psi_{i}|\Pi_{i}|\psi_{i}\rangle$
the constants $c_{i}$ can be replaced, 

\begin{eqnarray}
\Pi_{1} & = & \frac{p_{1}}{|\langle\psi_{1}|\psi_{2}^{\perp}\rangle|^{2}}|\psi_{2}^{\perp}\rangle\langle\psi_{2}^{\perp}|,\nonumber \\
\Pi_{2} & = & \frac{p_{2}}{|\langle\psi_{2}|\psi_{1}^{\perp}\rangle|^{2}}|\psi_{1}^{\perp}\rangle\langle\psi_{1}^{\perp}|.\label{eq:Pi1Pi2}
\end{eqnarray}


\begin{figure}
\begin{centering}
\includegraphics[width=8.5cm,height=8.5cm]{UD}
\par\end{centering}

\protect\caption[\hspace{1cm}UD Detectors]{ POVM setup that unambiguously discriminates between $\protect\ket{\psi_{1}}$
and $\protect\ket{\psi_{2}}$ optimally. The detector $D_{1}=\Pi_{1}$
is setup along $\protect\ket{\psi_{2}^{\perp}}$, detector $D_{2}=\Pi_{2}$
is setup along $\protect\ket{\psi_{1}^{\perp}}$ and the failure operator
is setup symmetrically between $\protect\ket{\psi_{1}}$ and $\protect\ket{\psi_{2}}$
for $\eta_{1}=\eta_{2}=\frac{1}{2}$. When a click in the $D_{i}$
detector occurs we know for certain that $\protect\ket{\psi_{i}}$
was prepared $\left(i=1,2\right)$ as the input state since it is
the only one that has a component along this direction. A click in
the $D_{0}$ detector is considered inconclusive as both states have
a component along this direction}


\label{UD} direction
\end{figure}


To determine the failure operator, insert (\ref{eq:Pi1Pi2}) into
(\ref{eq:3povms}): 

\begin{equation}
\Pi_{0}=I-\Pi_{1}-\Pi_{2}=I-\frac{p_{1}}{|\langle\psi_{1}|\psi_{2}^{\perp}\rangle|^{2}}|\psi_{2}^{\perp}\rangle\langle\psi_{2}^{\perp}|-\frac{p_{2}}{|\langle\psi_{2}|\psi_{1}^{\perp}\rangle|^{2}}|\psi_{1}^{\perp}\rangle\langle\psi_{1}^{\perp}|.
\end{equation}


After writing everything explicitly, the positivity constraint of
the eigenvalues of $\Pi_{0}$ gives the condition

\begin{equation}
q_{1}q_{2}\geq|\langle\psi_{1}|\psi_{2}\rangle|^{2},\label{eq:qConstraint}
\end{equation}
 where we used $q_{i}=1-p_{i}.$

Using the condition (\ref{eq:qConstraint}) and taking the equality
sign, the total failure rate in (\ref{eq:Q}) can be expressed in
terms of a single constraint. Define the overlap $s\equiv\langle\psi_{1}|\psi_{2}\rangle$
and replacing $q_{1}=s^{2}/q_{2}$ into (\ref{eq:Q}), $Q=\frac{\eta_{1}s^{2}}{q_{2}}+\eta_{2}q_{2},$
the optimization follows

\[
0=\frac{\partial Q}{\partial q_{2}}=-\frac{\eta_{1}s^{2}}{q_{2}^{2}}+\eta_{2}.
\]


This leads to individual failure rates $q_{1}=\sqrt{\frac{\eta_{2}}{\eta_{1}}}s$
and $q_{2}=\sqrt{\frac{\eta_{1}}{\eta_{2}}}s$ . Inserting them back
into Equation (\ref{eq:Q}) gives the optimal $Q$ which it will be
defined as $Q_{0},$

\begin{equation}
Q_{0}=2\sqrt{\eta_{1}\eta_{2}}s.
\end{equation}


Let us now check the conditions where this result holds. The individual
error rates must be smaller or equal to one, $q_{i}\leq1.$ Hence
$q_{1}=\sqrt{\frac{1-\eta_{1}}{\eta_{1}}}s\leq1$ gives the lower
bound on the a-prior probabilities, $\eta_{1}\geq\frac{s^{2}}{1+s^{2}}.$
Similarly the condition that $q_{2}\leq1$ gives the upper bound on
the priors $\eta_{1}\leq\frac{1}{1+s^{2}}.$ Putting the two conditions
together the POVM regime is valid in the range: 

\begin{equation}
\frac{s^{2}}{1+s^{2}}\leq\eta_{1}\leq\frac{1}{1+s^{2}}.
\end{equation}


Outside of this range it is interesting to see that the measurement
strategy merges into the projective measurement. 

If one of the incoming states is prepared with a much higher probability,
say $\eta_{1}\gg\eta_{2}$, we design an experiment where we have
only two detection operators. One of them, $D_{0}$, the failure operator,
simply projects onto state $|\psi_{2}\rangle,$ the detector $D_{1}$
projects onto $|\psi_{2}^{\perp}\rangle,$ thus it never clicks for
$|\psi_{2}\rangle,$ so that a click on $D_{1}$ is associated with
the state $|\psi_{1}\rangle.$ A click along $D_{2}$ is failure.
The setup for the detectors which produce failure rate $Q_{1}$ is
shown in Figure (1.1.2). The total failure rate is:

\begin{equation}
Q_{1}=\eta_{1}|\langle\psi_{1}|\psi_{2}\rangle|^{2}+\eta_{2}.
\end{equation}


\begin{figure}
\begin{centering}
\includegraphics[width=10cm,height=10cm]{Q_1}
\par\end{centering}

\protect\caption[\hspace{1cm}von Neumann UD for $\protect\ket{\psi_{1}}$]{ A von Neumann measurement that discriminates $\protect\ket{\psi_{1}}$
unambiguously. The failure detector $\Pi_{0}=P_{2}$ is set up along
the $\protect\ket{\psi_{2}}$ direction and the second detector $\Pi_{1}=P_{2}^{\perp}$
is set up orthogonal to $\protect\ket{\psi_{2}}$ therefore never
clicks for $\protect\ket{\psi_{2}}.$ When a click in the $\Pi_{0}$
detector occurs we learn nothing as both states have an overlap along
$P_{1}.$ }


\label{Q_1} 
\end{figure}


Similarly for $\eta_{2}\gg\eta_{1}$, the corresponding setup with
detectors yielding $Q_{2}$ is shown in Figure (1.1.3)

\begin{equation}
Q_{2}=\eta_{1}+\eta_{2}|\langle\psi_{1}|\psi_{2}\rangle|^{2}.
\end{equation}


\begin{figure}
\begin{centering}
\includegraphics[width=10cm,height=10cm]{Q_2}
\par\end{centering}

\protect\caption[\hspace{1cm}von Neumann UD for $\protect\ket{\psi_{2}}$]{ A von Neumann measurement that discriminates $\protect\ket{\psi_{2}}$
unambiguously. The failure detector $\Pi_{0}=P_{1}$ is set up along
the $\protect\ket{\psi_{1}}$ direction and the second detector $\Pi_{2}=P_{1}^{\perp}$
is set up orthogonal to $\protect\ket{\psi_{1}}$ therefore never
clicks for $\protect\ket{\psi_{1}}.$ When a click in the $\Pi_{0}$
detector occurs, we learn nothing as both states have an overlap along
$P_{2}.$ }


\label{Q_2} 
\end{figure}


Putting the pieces together, the minimum value of $Q$ for the three
different regimes can be written as:

\begin{equation}
Q=\begin{cases}
2\sqrt{\eta_{1}\eta_{2}}s & \text{if }\frac{s^{2}}{1+s^{2}}\leq\eta_{1}\leq\frac{1}{1+s^{2}},\\
\eta_{1}|\langle\psi_{1}|\psi_{2}\rangle|^{2}+\eta_{2}\text{ if } & \eta_{1}>\frac{1}{1+s^{2}},\\
\eta_{1}+\eta_{2}|\langle\psi_{1}|\psi_{2}\rangle|^{2}\text{ if } & \eta_{1}<\frac{s^{2}}{1+s^{2}}.
\end{cases}
\end{equation}


It is very interesting that the POVM gives the minimum $Q$ when it
is valid. Outside the boundaries it merges with the von Neumann projective
measurement. 


\subsection{Unambiguous Discrimination: Two pure states via Neumark's Theorem}

Theoretically the problem of minimizing the average failure rate for
two pure states has been solved in the previous section. However to
be able to implement those schemes we resort to Neumark's theorem
which states that any POVM operator can be realized by generalized
measurements \cite{cite-keyneumark}. The system where the incoming
states live is embedded in a larger Hilbert space called ancilla.
Then a unitary operator entangles the degrees of freedom of the system
with those of the ancilla. After this interaction projective measurements
are performed within this larger system in the ancilla. These measurements
will also transform the system states in the original Hilbert space
because of the entanglement. 

To show the power of Neumark's theorem we will re-derive the optimal
failure rate of two nonorthogonal states. The incoming states $\{|\psi_{1}\rangle_{s},|\psi_{2}\rangle_{s}\}$
which live in the state Hilbert space $H_{S}$ are embedded with the
ancilla $|i\rangle_{a}$ which live in the ancilla Hilbert space $H_{A}.$
Now the system and the ancilla live in the larger Hilbert space $H=H_{S}\varotimes H_{A}.$
The incoming states in this larger Hilbert space can be written in
the product form $\{|\psi_{1}\rangle_{s}|i\rangle_{a},\ |\psi_{2}\rangle_{s}|i\rangle_{a}\},$
where $\ket i_{a}$ is the initial state of the ancilla. The unitary
operator does the following:

\begin{eqnarray}
U|\psi_{1}\rangle_{s}|i\rangle_{a} & = & \sqrt{p_{1}}|\psi'_{1}\rangle_{s}|1\rangle_{a}+\sqrt{q_{1}}|\phi\rangle_{s}|0\rangle_{a},\nonumber \\
U|\psi_{2}\rangle_{s}|i\rangle_{a} & = & \sqrt{p_{2}}|\psi'_{2}\rangle_{s}|2\rangle_{a}+\sqrt{q_{2}}|\phi\rangle_{s}|0\rangle_{a},\label{eq:neumark}
\end{eqnarray}
where $p_{i}$ is the probability of successfully identifying the
state $|\psi_{i}\rangle_{s}$, $q_{i}$ is the probability of failing
to identify $|\psi_{i}\rangle_{s},$ and $p_{i}+q_{i}=1.$ The unitary
operator aims to take the two incoming states and make them orthogonal.
When there is a click on the ancilla $|1\rangle_{a}$ the input states
have been separated and output states $|\psi'_{i}\rangle_{s}$ are
orthogonal and therefore fully distinguishable. If there is a click
along the ancilla $|0\rangle_{a}$ the incoming states have been collapsed
into a single state which carries no information about the system.
That is why the choice on the setup of having the failed state $|\phi\rangle_{s}$
be the same, there should be absolutely no information left in the
failed state, otherwise it is not optimal. 

Taking the inner product of the two equations in (\ref{eq:neumark})
gives the constraint to the optimization

\begin{equation}
s=\sqrt{q_{1}q_{2}},
\end{equation}
where $s$ was defined to be the overlap of the input states $s\equiv\langle\psi_{1}|\psi_{2}\rangle.$
In just one line Neumark's setup has produced the constrain and the
rest of the derivation, optimizing (\ref{eq:Q}), is the same as in
the POVM section and we do not need to repeat here. Implementation
methods have been derived and we will show an example in Chapter $4$. 


\section{Minimum Error Discrimination}

In the Minimum Error (ME) strategy one is not allowed to abstain from
identifying an incoming state, i.e for every incoming state the observer
must say which state he was given. Since it was shown that perfect
discrimination is not possible the detectors inevitably will make
errors. A click in a detector can only identify a state with some
probability of success and misidentify the state with some probability
of error. 


\subsection{Minimum Error: Two mixed states via POVM }

Given an ensemble of two mixed states $\{\rho_{1},\rho_{2}\}$ prepared
with different a priori probabilities $\{\eta_{1},\eta_{2}\}$ the
task is to minimize the rate for which the detectors misidentify a
state. The minimum error problem for two pure or mixed states was
first solved by Helstrom \cite{Helstrom1969}. We show an alternative
derivation to ME of two pure states developed by Herzog \cite{Herzog2004}
and Fuchs \cite{Fuchs1996}. When the detector $\Pi_{i}$ clicks for
state $\rho_{j}$ it is an error, $r_{i}=Tr(\rho_{j}\Pi_{i})$, a
clink for state $\rho_{i}$ is success $p_{i}=Tr(\rho_{i}\Pi_{i})$.
Thus for two states we want to minimize the following expression. 

\begin{equation}
P_{E}=\eta_{1}Tr(\rho_{1}\Pi_{2})+\eta_{2}Tr(\rho_{2}\Pi_{1}).\label{eq:P_E}
\end{equation}


Using the relation $\eta_{1}+\eta_{2}=1$ and $\Pi_{1}+\Pi_{2}=I$,
Equation (\ref{eq:P_E}) can be rewritten as:

\begin{eqnarray*}
P_{E} & = & \eta_{1}Tr(\rho_{1}(I-\Pi_{1}))+\eta_{2}Tr(\rho_{2}\Pi_{1}),\\
 & = & \eta_{1}+Tr[(\eta_{2}\rho_{2}-\eta_{1}\rho_{1})\Pi_{1},\\
 & = & \eta_{2}-Tr[(\eta_{2}\rho_{2}-\eta_{1}\rho_{1})\Pi_{2}.
\end{eqnarray*}


Let $\Lambda=\eta_{2}\rho_{2}-\eta_{1}\rho_{1}$
\begin{equation}
P_{E}=\eta_{1}+Tr(\Lambda\Pi_{1})=\eta_{2}-Tr(\Lambda\Pi_{2}).
\end{equation}


To minimize $P_{E},$ $\Pi_{1}$ should project onto the eigenvectors
of the negative eigenvalues of $\Lambda,$ on the other hand $\Pi_{2}$
should project onto the positive eigenvectors. Let us write $\Lambda$
into its spectral decomposition. 

\begin{equation}
\Lambda=\eta_{2}\rho_{2}-\eta_{1}\rho_{1}=\sum_{i=1}^{d}\lambda_{i}|\lambda_{i}\rangle\langle\lambda_{i}|.
\end{equation}


To implement the projection of the POVM operators onto the positive
(or negative) eigenvectors the eigenvalues $\lambda_{i}$ can be split
into three categories without any loss of generality: negative, positive
and zero:

\begin{eqnarray}
\lambda_{i} & < & 0\text{ for }1\leq i<i_{o},\nonumber \\
\lambda_{i} & > & 0\text{ for \ensuremath{i_{o}\leq i<d}},\nonumber \\
\lambda_{i} & = & 0\text{ for \ensuremath{d\leq i<d_{s}}. }
\end{eqnarray}


Then from the spectral decomposition we can rewrite $(2.2.6)$ in
terms of the optimal POVM. 

\begin{equation}
P_{E}=\eta_{1}+\sum_{i=1}^{i_{o}-1}\lambda_{i}\langle\lambda_{i}|\Pi_{1}|\lambda_{i}\rangle=\eta_{2}-\sum_{i=i_{o}}^{d_{s}}\lambda_{i}\langle\lambda_{i}|\Pi_{2}|\lambda_{i}\rangle,
\end{equation}
where $\Pi_{1}=\sum_{i=1}^{i_{o}-1}\lambda_{i}|\lambda_{i}\rangle\langle\lambda_{i}|$
and $\Pi_{2}=\sum_{i=i_{o}}^{d_{s}}\lambda_{i}|\lambda_{i}\rangle\langle\lambda_{i}|.$

The POVMs need to satisfy the condition $0\leq\langle\lambda_{i}|\Pi_{j}|\lambda_{i}\rangle\leq1$
which comes from the definition of the normalized probabilities $r_{i}=Tr(\rho_{i}\Pi_{j}).$
These POVMs are basically von Neumann projectors onto the corresponding
eigenvectors. If we now replace the detection operators by the optimal
detectors the minimum error can be expressed just in terms of the
eigenvalues of $\Lambda.$ 

\begin{eqnarray}
P_{E} & = & \eta_{1}-\sum_{i=1}^{i_{o}-1}|\lambda_{i}|=\eta_{2}-\sum_{i=1}^{d_{s}}|\lambda_{i}|,\nonumber \\
 & = & \frac{1}{2}[1-\sum_{i=1}^{d_{s}}|\lambda_{i}|]=\frac{1}{2}[1-Tr|\Lambda|],\nonumber \\
 & = & \frac{1}{2}[1-Tr|\eta_{2}\rho_{2}-\eta_{1}\rho_{1}|]
\end{eqnarray}


When the states to be discriminated are pure, $\{|\psi_{1}\rangle,|\psi_{2}\rangle\},$
the minimum error can be reduced to 

\begin{equation}
P_{E}=\frac{1}{2}[1-\sqrt{1-4\eta_{1}\eta_{2}|\langle\psi_{1}|\psi_{2}\rangle|^{2}}].
\end{equation}


\begin{figure}
\begin{centering}
\includegraphics[width=8.5cm,height=8.5cm]{ME}\protect\caption[\hspace{1cm}Min Error]{ A von Neumann measurement which minimizes the error rate of two
pure states prepared with equal priors. The detectors are placed symmetrically
along the states $\left\{ \protect\ket{\psi_{1}},\protect\ket{\psi_{2}}\right\} $
for $\eta_{1}=\eta_{2}=\frac{1}{2}$. }

\par\end{centering}

\label{POVM_ME} 
\end{figure}



\subsection{Minimum Error: Two pure states via Neumark's theorem }

Just as we did in the UD case, we will solve the ME problem of discriminating
two pure states via the Neumark setup because of it lends itself into
an optical implementation. Although in this case the solution is not
as straightforward. The incoming states $\{|\psi_{1}\rangle_{s},|\psi_{2}\rangle_{s}\}$
which live in the state Hilbert space $H_{S}$ are embedded with the
ancilla $|i\rangle_{a}$ which live in the ancilla Hilbert space $H_{A}.$
Now the system and the ancilla live in the larger Hilbert space $H=H_{S}\varotimes H_{A}.$
The incoming states in this larger Hilbert space can be written in
the product form $\{|\psi_{1}\rangle_{s}|i\rangle_{a},\ |\psi_{2}\rangle_{s}|i\rangle_{a}\}.$
The unitary operator does the following:

\begin{eqnarray}
U|\psi_{1}\rangle_{s}|i\rangle_{a} & = & \sqrt{p_{1}}|\psi_{1}\rangle|1\rangle+\sqrt{r_{1}}|\psi_{2}\rangle|2\rangle,\\
U|\psi_{2}\rangle_{s}|i\rangle_{a} & = & \sqrt{p_{2}}|\psi_{2}\rangle|2\rangle+\sqrt{r_{2}}|\psi_{1}\rangle|1\rangle,\label{eq:ME neumark}
\end{eqnarray}
where $p_{i}$ is the probability of having successfully identified
the state $\ket{\psi_{i}}$ and $r_{i}$ is the probability of misidentifying
the state $\ket{\psi_{i}}$ for $\ket{\psi_{j}}$. 

Taking the inner product of the two equations in (\ref{eq:ME neumark})
gives the constraint:

\begin{equation}
s=\sqrt{p_{1}r_{2}}+\sqrt{p_{2}r_{1}}.\label{eq:ME constraint}
\end{equation}
 The quantity we are looking to minimize in the average error rate:

\begin{equation}
P_{E}=\eta_{1}r_{1}+\eta_{2}r_{2},\label{eq:ME}
\end{equation}
 subject to the constraint in (\ref{eq:ME constraint}). Adding the
constraint to \ref{eq:ME} with one Lagrange multiplier and using
$p_{i}+r_{i}=1$ 

\begin{equation}
F_{E}=\eta_{1}r_{1}+\eta_{2}r_{2}+\lambda\left[s-\sqrt{(1-r_{1})r_{2}}-\sqrt{(1-r_{2})r_{1}}\right].
\end{equation}


Differentiating with respect to $r_{i}$, then setting the resulting
equations equal to zero yields

\[
\frac{\partial F_{E}}{\partial r_{1}}=\eta_{1}+\frac{1}{2}\left[\sqrt{\frac{r_{2}}{1-r_{1}}}-\sqrt{\frac{1-r_{2}}{r_{1}}}\right]=0,
\]


\[
\frac{\partial F_{E}}{\partial r_{2}}=\eta_{2}+\frac{1}{2}\left[-\sqrt{\frac{r_{1}}{1-r_{2}}}+\sqrt{\frac{1-r_{1}}{r_{2}}}\right]=0.
\]


Rearranging the above two equations so that the left hand side is
only a function of $r_{i}$ and the right hand sides turn out to be
equivalent, 

\begin{equation}
\frac{2\eta_{1}}{\lambda}\sqrt{r_{1}(1-r_{1})}=\sqrt{r_{1}r_{2}}-\sqrt{(1-r_{1})(1-r_{2})},\label{eq:r12}
\end{equation}


\begin{equation}
\frac{2\eta_{2}}{\lambda}\sqrt{r_{2}(1-r_{2})}=\sqrt{r_{1}r_{2}}-\sqrt{(1-r_{1})(1-r_{2})}.\label{eq:r1r2}
\end{equation}


The right hand sides of Eq.(\ref{eq:r12}) and (\ref{eq:r1r2}) can
be set to a constant $\frac{2\eta_{i}}{\lambda}\sqrt{r_{i}(1-r_{i})}\equiv C$,
which can later be determined from the unitarity constraint \ref{eq:ME constraint}, 

\begin{eqnarray}
r_{i} & = & \frac{1}{2}\left(1\pm\sqrt{1-\frac{\lambda^{2}C^{2}}{\eta_{i}^{2}}}\right)=\frac{1}{2}\left(1-\sqrt{1-\frac{\delta^{2}}{\eta_{i}^{2}}}\right),\label{eq:r_i-1}\\
r_{i} & = & \frac{1}{2}\left[1-A_{i}\right],
\end{eqnarray}


where $A_{i}\equiv\sqrt{1-\frac{\delta^{2}}{\eta_{i}^{2}}}$ and $\delta^{2}\equiv\lambda^{2}C^{2}$.
The smaller $r_{i}$ is picked (lower sign in \ref{eq:r_i-1} ) as
this represents error rate, which is to be minimized. Now replace
$r_{i}$ into the constraint (\ref{eq:ME constraint}) and solve for
$\delta$:

\begin{eqnarray*}
s & = & \sqrt{(1-r_{1})r_{2}}+\sqrt{(1-r_{2})r_{1}},\\
2s & = & \sqrt{(1+A_{1})(1-A_{2})}+\sqrt{(1-A_{1})(1+A_{2})},\\
2s^{2} & = & 1-A_{1}A_{2}+\sqrt{(1-A_{1}^{2})(1-A_{2}^{2})},\\
2s^{2} & = & 1-A_{1}A_{2}+\frac{\delta^{2}}{\eta_{1}\eta_{2}},\\
(2s^{2}-1 & -\frac{\delta^{2}}{\eta_{1}\eta_{2}})^{2}= & 1-\frac{\delta^{2}}{\eta_{1}^{2}}-\frac{\delta^{2}}{\eta_{2}^{2}}+\frac{\delta^{4}}{\eta_{1}^{2}\eta_{2}^{2}}.
\end{eqnarray*}


After some tedious but trivial algebra:

\begin{equation}
\delta^{2}=\frac{4s^{2}(1-s^{2})\eta_{1}^{2}\eta_{2}^{2}}{1-4\eta_{1}\eta_{2}s^{2}}.\label{eq:delta}
\end{equation}


Now substitute the value of $\delta$ from (\ref{eq:delta}) into
(\ref{eq:r_i-1}) to get the explicit form of the individual error
rates,

\begin{equation}
r_{i}=\frac{1}{2}\left[1-\frac{1-2\eta_{i}s^{2}}{\sqrt{1-4\eta_{1}\eta_{2}s^{2}}}\right]
\end{equation}


Inserting $r_{1}$ and $r_{2}$ into (\ref{eq:P_E}) Helstrom bound
is retrieved \cite{Helstrom1969}

\begin{eqnarray}
P_{E} & = & \frac{1}{2}\left[1-\frac{\eta_{1}-2\eta_{1}\eta_{2}s^{2}}{\sqrt{1-4\eta_{1}\eta_{2}s^{2}}}-\frac{\eta_{2}-2\eta_{1}\eta_{2}s^{2}}{\sqrt{1-4\eta_{1}\eta_{2}s^{2}}}\right],\nonumber \\
P_{E} & = & \frac{1}{2}\left[1-\sqrt{1-4\eta_{1}\eta_{2}s^{2}}\right].
\end{eqnarray}


As we mentioned above the advantage of solving the ME problem via
Neumark is that we now have explicit expressions for the individual
error rates, $r_{1}$ and $r_{2}.$ In the Implementation chapter,
it is shown that the unitary operator which carries out this operation
can be written in terms of $r_{i}$ and then be decomposed into beam
splitters and phase shifters using optical interferometers. 


\chapter{Optimal discrimination of a certain class of mixed states with a
fixed rate of inconclusive outcome (FRIO)}

In this chapter we will derive the optimal strategy with a Fixed Rate
of Inconclusive Outcomes ($FRIO$) that optimally interpolates between
the two well known limits, Helstrom bound for minimum error and IDP
for unambiguous discrimination. In particular, as the main finding
of our paper, we will show that the optimal distribution of the fixed
rate of inconclusive outcomes, $Q$, among the 2-dimensional subspaces
spanned by the pair of Jordan basis vectors is highly non-trivial
and an interesting threshold-like structure emerges: As we start increasing
$Q$ from $Q=0$ , first only one subspace receives the entire inconclusive
rate. Then, as we increase $Q$ further, at a certain threshold a
second subspace starts sharing the inconclusive rate. If we increase
$Q$ further, at another threshold a third subspace also starts sharing
$Q$ , and so on, until above a last threshold all subspaces share
the available inconclusive rate.


\section{Review of the FRIO solution for two pure states}

We first present a brief review of the method developed in \cite{Bagan2012}
for the two pure state optimal FRIO problem since the rest of the
paper relies heavily on this method. We derive the maximum probability
of success or, equivalently, the minimum probability of error in identifying
the states, when a certain fixed rate of inconclusive outcomes is
allowed. By varying the inconclusive rate, the scheme optimally interpolates
between Unambiguous and Minimum Error discrimination (UD and ME).

In all of these scenarios (UD, ME or FRIO) one is given a system which
is promised to be prepared in one of two known pure states, $|\psi_{1}\rangle$
or $|\psi_{2}\rangle$, but we don't know which. The pure states are
prepared with prior probabilities $\eta_{1}$ and $\eta_{2}$, respectively,
such that $\eta_{1}+\eta_{2}=1$. It is well known that two pure states
can be discriminated both unambiguously and with minimum error. In
Section (2.1) we showed the solution of the optimal average inconclusive
rate, $Q_{{\rm c}}$ for UD:
\begin{equation}
Q_{{\rm c}}=\left\{ \begin{array}{l}
\eta_{1}+\eta_{2}\cos^{2}\theta,\mbox{if \ensuremath{{\displaystyle \eta_{1}<\frac{\cos^{2}\theta}{1+\cos^{2}\theta}\equiv\eta_{1}^{(l)}}},}\\[0.7em]
\eta_{2}+\eta_{1}\cos^{2}\theta,\mbox{if \ensuremath{\eta_{1}>{\displaystyle \frac{1}{1+\cos^{2}\theta}\equiv\eta_{1}^{(r)}}},}\\[0.7em]
2\sqrt{\eta_{1}\eta_{2}}\cos\theta\equiv Q_{0},\mbox{if \ensuremath{\eta_{1}^{(l)}\le\eta_{1}\le\eta_{1}^{(r)}}}\ ,
\end{array}\right.\label{Qmax}
\end{equation}
where $|\langle\psi_{1}|\psi_{2}\rangle|\equiv\cos\theta$ is the
overlap of the input states.

In Section (2.2) we also showed the optimal average error rate for
ME: 
\begin{equation}
P_{{\rm E}}^{ME}=\frac{1}{2}\left(1-\sqrt{1-4\eta_{1}\eta_{2}\cos^{2}\theta}\;\right).\label{PE}
\end{equation}


It has long been suggested \cite{Chefles1998} that the above state
discrimination points are part of a more general scheme. One which
interpolates between optimal ME and UD. The FRIO strategy achieves
that goal by minimizing the error rate while allowing for some rate
of inconclusive results. Hence the strategy has three measurement
outcomes, one that identifies with the first state, one that identifies
with the second state and one that does not identify with a state
at all, corresponding to the inconclusive outcome. The authors in
\cite{Bagan2012} solve the problem via the POVM method. Three POVM
elements are needed such that:

\begin{equation}
\Pi_{1}+\Pi_{2}+\Pi_{0}=I\ ,\label{POVM}
\end{equation}


A click in $\Pi_{1}$ is identified with state $\ket{\psi_{1}},$
a click in $\Pi_{2}$ is identified with the second state $\ket{\psi_{2}}$
and any clicks in the operator $\Pi_{0}$ corresponds to inconclusive
outcomes. However the operators $\Pi_{i}$ can also click for $\ket{\psi_{j}}.$
We wish to minimize the average error rate,

\begin{eqnarray*}
P_{E} & = & \eta_{1}Tr\left[\sandwich{\psi_{1}}{\Pi_{2}}{\psi_{1}}\right]+\eta_{2}Tr\left[\sandwich{\psi_{2}}{\Pi_{1}}{\psi_{2}}\right],\\
 & = & \eta_{1}tr\left[\Pi_{2}\ket{\psi_{1}}\bra{\psi_{1}}\right]+\eta_{2}tr\left[\Pi_{1}\ket{\psi_{2}}\bra{\psi_{2}}\right],\\
 & = & \eta_{1}tr\left[\Pi_{2}\rho_{1}\right]+\eta_{2}tr\left[\Pi_{1}\rho_{2}\right],
\end{eqnarray*}
where $\rho_{1}=\ket{\psi_{1}}\bra{\psi_{1}}$ and $\rho_{2}=\ket{\psi_{2}}\bra{\psi_{2}}$
are the corresponding pure state density matrices (Equivalently we
wish to maximize the average success rate $P_{s}=\eta_{1}tr\left[\Pi_{1}\rho_{1}\right]+\eta_{2}tr\left[\Pi_{2}\rho_{2}\right]$),
for a fixed rate of inconclusive results,

\begin{equation}
Q=\eta_{1}tr\left[\Pi_{0}\rho_{1}\right]+\eta_{2}tr\left[\Pi_{0}\rho_{2}\right]\ .\label{Q}
\end{equation}


The solution to the problem involves a neat trick which transforms
the three element POVM defined in Eq.(\ref{POVM}) into a two element
POVM, namely,

\begin{eqnarray}
\Pi_{1}+\Pi_{2} & = & I-\Pi_{0},\nonumber \\
\Omega^{-1/2}\left(\Pi_{1}+\Pi_{2}\right)\Omega^{-1/2} & = & \Omega^{-1/2}\left(I-\Pi_{0}\right)\Omega^{-1/2},\nonumber \\
\tilde{\Pi}_{1}+\tilde{\Pi}_{2} & = & I,
\end{eqnarray}
where $\Omega\equiv I-\Pi_{0}$ and $\tilde{\Pi}_{i}\equiv\Omega^{-1/2}\Pi_{i}\,\Omega^{-1/2}.$
Should be noted that $\Omega^{-1/2}=\left(I-\Pi_{0}\right)^{-1/2}$
exists unless $\Pi_{0}$ has a unit value, in which case the problem
is treated separately. It was important to notice that for optimal
FRIO, $\Pi_{0}$ must be rank one operator. That means that $\Pi_{0}$
maps both incoming non-orthogonal states onto a single state which
is then discarded. On the other hand the other two POVM elements map
the input states onto two different states. 

The FRIO problem has essentially been transformed into a new parametrized
optimization scheme with two POVM elements, $\tilde{\Pi}_{1}$ and
$\tilde{\Pi}_{2}$. The error probability in the new parametrized
form, $P_{E}=(1-Q)\tilde{P}_{E}$, becomes 

\begin{eqnarray}
\tilde{P}_{e} & = & Tr(\tilde{\eta}_{1}\tilde{\rho}_{1}\tilde{\Pi}_{2})+Tr(\tilde{\eta}_{2}\tilde{\rho}_{2}\tilde{\Pi}_{1}),\label{tildePe}
\end{eqnarray}
where the normalized states $\tilde{\rho}_{i}$ and normalized a priori
probabilities $\tilde{\eta}_{i}$ are 

\begin{equation}
\tilde{\rho}_{i}=\frac{\Omega^{1/2}\rho_{i}\Omega^{1/2}}{Tr(\Omega\rho_{i}))},\qquad\tilde{\eta}_{i}=\frac{\eta_{i}Tr(\Omega\rho_{i})}{1-Q},\label{tildestates}
\end{equation}


Equation (\ref{tildePe}) and $\tilde{\Pi}_{1}+\tilde{\Pi}_{2}=I$
define a ME discrimination problem for the transformed states and
\emph{priors} given in Eq.~(\ref{tildestates}). The optimal solution
to this ME discrimination problem immediately follows by using the
tilde quantities in (\ref{PE}), with $|\tilde{\psi}_{i}\rangle=\Omega^{1/2}|\psi_{i}\rangle/\sqrt{\langle\psi_{i}|\Omega|\psi_{i}\rangle}$
being the properly normalized transformed states.

We can immediately write down the solution in parametrized form

\[
\tilde{P}_{{\rm E}}^{ME}=\frac{1}{2}\left(1-\sqrt{1-4\tilde{\eta}_{1}\tilde{\eta}_{2}\left|\braket{\tilde{\psi}_{1}}{\tilde{\psi}_{2}}\right|^{2}}\;\right)
\]


Writing the input states as, $|\psi_{i}\rangle=c_{i}|0\rangle+s_{i}|1\rangle$,
where $c_{i}\equiv\cos\theta_{i}$, $s_{i}\equiv\sin\theta_{i}$,
we obtain the transformed states and priors from Eq.~(\ref{tildestates}).
Since the optimal~$\Pi_{0}$ is a positive rank one operator it can
be written as $\Pi_{0}=\xi|0\rangle\langle0|$, where $\xi$ is its
eigenvalue, $0\leq\xi\leq1$, and the eigenstate belonging to $\xi$
is $|0\rangle$ and the orthogonal state is $|1\rangle$. In this
basis $\Omega=(1-\xi)|0\rangle\langle0|+|1\rangle\langle1|$. The
tilde error rate now becomes:



\begin{equation}
\tilde{P}_{e}^{{\rm ME}}=\frac{1}{2}\left\{ 1-\sqrt{1-4\eta_{1}\eta_{2}(\cos\theta-\xi c_{1}c_{2})^{2}/(1-Q)^{2}}\right\} ,\label{tildePe3}
\end{equation}


where $\theta_{1}-\theta_{2}\equiv\theta$. It follows from~(\ref{Q})
that 
\begin{equation}
\xi=\frac{Q}{\eta_{1}c_{1}^{2}+\eta_{2}c_{2}^{2}}.\label{xi}
\end{equation}
Hence Eq.~(\ref{tildePe3}) depends only on one parameter, say~$\theta_{1}$,
which determines the orientation of $\Pi_{0}$ relative to that of
the two pure states. The minimization over $\theta_{1}$ simplifies
considerably, using Eq.~(\ref{xi}) and defining $c_{1}\,\eta_{1}^{1/2}(\eta_{1}c_{1}^{2}+\eta_{2}c_{2}^{2})^{-1/2}\equiv\cos\varphi$,
and~$c_{2}\,\eta_{2}^{1/2}(\eta_{1}c_{1}^{2}+\eta_{2}c_{2}^{2})^{-1/2}\equiv\sin\varphi$.
The resulting expression is minimum for~$\varphi=\pi/4$, yielding
\begin{equation}
P_{e}^{{\rm min}}\!=\!\frac{1}{2}\!\left\{ 1-Q-\sqrt{(1-Q)^{2}-\left(Q_{0}-Q\right)^{2}}\right\} \ ,\label{PeSol1}
\end{equation}


for all $Q\leq Q_{0}\equiv2\sqrt{\eta_{1}\eta_{2}}s$. This is the
optimal error rate for an intermediate range of the prior probabilities,
a rather nice looking formula for a somewhat complicated problem.
We can check that is reproduces the Helstrom bound for zero failure
rate $Q=0,$ $P_{E}=\frac{1}{2}\left[1-\sqrt{1-Q_{0}^{2}}\right]=\frac{1}{2}\left[1-\sqrt{1-2\eta_{2}\eta_{2}s^{2}}\right]$
and the IDP bound for zero error rate $0=\frac{1}{2}\!\left\{ 1-Q-\sqrt{(1-Q)^{2}-\left(Q_{0}-Q\right)^{2}}\right\} \Rightarrow$
$Q=Q_{0}\equiv2\sqrt{\eta_{1}\eta_{2}}s.$ 

For the validity of (\ref{PeSol1}), $\xi\le1$ must hold. The definitions
of $\cos\varphi$ and $\sin\varphi$ after Eq.~(\ref{xi}) give ${\sqrt{\eta}_{2}c_{2}=\sqrt{\eta}_{1}c_{1}}$
for $\varphi=\pi/4$ which, in turn, leads to $\eta_{1}c_{1}^{2}=\eta_{2}c_{2}^{2}=\eta_{1}\eta_{2}\,{\sin^{2}\theta/(1-Q_{0})}$,
and~Eq.~(\ref{xi}) yields $\xi=(1-Q_{0})Q/(2\eta_{1}\eta_{2}\sin^{2}\theta)$.
Setting $\xi=1$ defines the boundary $Q_{b}$, between the projective
and POVM regimes, 
\begin{equation}
Q_{{\rm b}}\equiv{2\eta_{1}\eta_{2}\sin^{2}\theta/(1-Q_{0})}.\label{Qb}
\end{equation}
Hence~$\xi\leq1$ if $Q\leq Q_{{\rm b}}$ and $\xi=1$ if $Q>Q_{{\rm b}}$.

In Fig. \ref{Fig1} we plot $Q_{{\rm c}}$ and~$Q_{{\rm b}}$ vs.~$\eta_{1}$
together for a fixed overlap, $\cos\theta=0.5$ ($\theta=\pi/3$).
The two curves intersect at $\eta_{1}=\eta_{1}^{(l)}$ and $\eta_{1}=\eta_{1}^{(r)}$,
the same points as in Eq.~(\ref{Qmax}). The interval $0\leq\eta_{1}\leq1$
is thus divided into three regions. In regions~I and~III, we have
$Q_{{\rm b}}<Q_{{\rm c}}$ and the solution~(\ref{PeSol1}) is valid
for $0\leq Q<Q_{{\rm b}}$ only. In Region II, $\eta_{1}^{(l)}\leq\eta_{1}\leq\eta_{1}^{(r)}$,
we have $Q_{{\rm c}}=Q_{0}<Q_{{\rm b}}$ and the solution (\ref{PeSol1})
is valid for the entire $0\leq Q\leq Q_{{\rm c}}$ range.

%[floatfix]


In the shaded parts of regions I and III one has $Q_{{\rm b}}\leq Q\leq Q_{{\rm c}}$
and, necessarily, $\xi=1$. Hence,~$\Pi_{0}=|0\rangle\langle0|$
and $\Omega=|1\rangle\langle1|$ are projectors. Therefore,~$\Omega^{-1/2}$
does not exist in these areas and the case needs special consideration.

The calculation of the error probability is most easily performed
by realizing that $\Pi_{1}$ and $\Pi_{2}$ become degenerate, both
must be proportional to $\Pi_{d}=|1\rangle\langle1|$. The three-element
POVM becomes a standard two element projective measurement, $\{\Pi_{d}=|1\rangle\langle1|,\ \Pi_{0}=|0\rangle\langle0|\}$.
We identify a click in~$\Pi_{d}$ with $\rho_{1}$ ($\rho_{2}$)
if $\eta_{1}\ge\eta_{2}$ ($\eta_{2}\ge\eta_{1}$), so $P_{e(s)}=\eta_{2}s_{2}^{2},\quad P_{s(e)}=\eta_{1}s_{1}^{2}$,
with $Q=1-P_{e}-P_{s}$. These equations completely determine the
solution. There is nothing to optimize here, so we drop the superscript
${\rm min}$ in what follows. $\theta_{1}-\theta_{2}=\theta$ immediately
gives $Q(P_{e})$ as 
\begin{equation}
Q\!=\!1\!-\!P_{e}\!-\eta_{1(2)}\!\!\left(\!\sqrt{\!\frac{P_{e}}{\eta_{2(1)}}}\cos\theta\!\pm\!\sqrt{1\!-\!\frac{P_{e}}{\eta_{2(1)}}}\,\sin\theta\!\right)^{\!2}\!.\label{PeSol2}
\end{equation}
Inverting this equation gives $P_{e}(Q)$ yields 
\begin{equation}
P_{e}=\eta_{2}\frac{2\eta_{1}\cos^{2}\theta(1-Q-Q_{2})-(\eta_{1}-\eta_{2})(Q-Q_{2})-2\eta_{1}\eta_{2}\sin\theta\cos\theta\sqrt{Q(1-Q)-\eta_{1}\eta_{2}\sin^{2}\theta}}{1-4\eta_{1}\eta_{2}\sin^{2}\theta}\ ,\label{PeSol2Exp}
\end{equation}
 but the resulting expression is not particularly insightful. However,
we note that for $P_{e}=0$ (UD limit) one has~$Q=Q_{2}$, given
by the second line in Eq.~(\ref{Qmax}), and for $Q=Q_{{\rm b}}$,
$P_{e}$ reduces to (\ref{PeSol1}), as it should.


\section{FRIO discrimination of two Rank 2 mixed states}

In our work we extend the FRIO discrimination scheme to a particular
case of mixed states. We solve the FRIO problem for two mixed states
which exhibit a Jordan structure. The two states, with their respective
\emph{prior} probabilities $\eta_{1}$ and $\eta_{2}$, can be written
in the spectral decomposition form as, 
\begin{eqnarray}
\rho_{1} & = & \sum_{i=1}^{N}r_{i}\vert r_{i}\rangle\langle r_{i}\vert,\nonumber \\
\rho_{2} & = & \sum_{i=1}^{N}s_{i}\vert s_{i}\rangle\langle s_{i}\vert\ .\label{rho1and2}
\end{eqnarray}


In the Jordan structure these states satisfy the following conditions:

\begin{eqnarray}
\langle r_{i}\vert r_{j}\rangle & = & \delta_{ij}\nonumber \\
\langle s_{i}\vert s_{j}\rangle & = & \delta_{ij}\nonumber \\
\langle r_{i}\vert s_{j}\rangle & = & \delta_{ij}\cos\theta_{i}\label{eq:jordan}
\end{eqnarray}


Due to the Jordan structure, instead of one $2N$ dimensional problem
we have $N$ mutually orthogonal 2-dimensional subspaces. The $i^{th}$
subspace is spanned by $\vert r_{i}\rangle$ and $\vert s_{i}\rangle$
with \emph{prior} probabilities $\eta_{1}r_{i}$ and $\eta_{2}s_{i}$,
respectively. Thus the discrimination of the two mixed states $\rho_{1}$
and $\rho_{2}$ can be reduced into that of pure state discrimination
in each subspace, by discriminating $\vert r_{i}\rangle$ and $\vert s_{i}\rangle$
in each subspace.

In this section we solve the case where $N=2$, there is 2-dimensional
subspaces for each density operator. The density operator in Eq. (\ref{rho1and2})
can be expressed as

\begin{eqnarray}
\rho_{1} & = & r_{1}\ket{r_{1}}\bra{r_{1}}+r_{2}\ket{r_{2}}\bra{r_{2}},\nonumber \\
\rho_{2} & = & s_{1}\ket{s_{1}}\bra{s_{1}}+s_{2}\ket{s_{2}}\bra{s_{2}}.
\end{eqnarray}


The overall error rate is

\begin{eqnarray}
P_{E} & = & \eta_{1}tr\left(\Pi_{2}\rho_{1}\right)+\eta_{2}tr\left(\Pi_{1}\rho_{2}\right),\nonumber \\
 & = & \eta_{1}\left(r_{1}tr\left(\Pi_{s,1}\ket{r_{1}}\bra{r_{1}}\right)+r_{2}tr\left(\Pi_{s,2}\ket{r_{2}}\bra{r_{2}}\right)\right)+\label{eq:SubspaceErr}\\
 &  & \eta_{2}\left(s_{1}tr\left(\Pi_{r,1}\ket{s_{1}}\bra{s_{1}}\right)+s_{2}tr\left(\Pi_{r,2}\ket{s_{2}}\bra{s_{2}}\right)\right)
\end{eqnarray}
In this case the first subspace is spanned by $\{\vert r_{1}\rangle,\vert s_{2}\rangle\}$
and the second subspace by $\{\vert r_{2}\rangle,\vert s_{2}\rangle\}$.
The task becomes that of performing FRIO discrimination of $\{\vert r_{i}\rangle$
and $\vert s_{i}\rangle\}$ within subspace $i$. The error rate in
each subspace is:

\begin{eqnarray}
P_{e,1} & = & \eta_{1}r_{1}tr\left(\Pi_{s,1}\ket{r_{1}}\bra{r_{1}}\right)+\eta_{2}s_{1}tr\left(\Pi_{r,1}\ket{s_{1}}\bra{s_{1}}\right)\nonumber \\
P_{e,1} & = & \eta_{1}r_{2}tr\left(\Pi_{s,2}\ket{r_{2}}\bra{r_{2}}\right)+\eta_{2}s_{2}tr\left(\Pi_{r,2}\ket{s_{2}}\bra{s_{2}}\right)
\end{eqnarray}


The prior probability of $\vert r_{i}\rangle$ is $\eta_{1}r_{i}$
while the prior probability of $\vert s_{i}\rangle$ is $\eta_{2}s_{i}$.
We define their normalized probabilities as 
\begin{eqnarray}
\eta_{1,i} & \equiv & \frac{\eta_{1}r_{i}}{\eta_{1}r_{i}+\eta_{2}s_{i}},\nonumber \\
\eta_{2,i} & \equiv & \frac{\eta_{2}s_{i}}{\eta_{1}r_{i}+\eta_{2}s_{i}}\ ,\label{etaij}
\end{eqnarray}
such that $\eta_{1,i}+\eta_{2,i}=1$. The error rate in each subspace
becomes

\begin{eqnarray}
\tilde{P}_{e,1} & = & \eta_{1,1}tr\left(\Pi_{s,1}\ket{r_{1}}\bra{r_{1}}\right)+\eta_{2,1}tr\left(\Pi_{r,1}\ket{s_{1}}\bra{s_{1}}\right)\nonumber \\
\tilde{P}_{e,2} & = & \eta_{1,2}tr\left(\Pi_{s,2}\ket{r_{2}}\bra{r_{2}}\right)+\eta_{2,2}tr\left(\Pi_{r,2}\ket{s_{2}}\bra{s_{2}}\right)
\end{eqnarray}
where $\tilde{P}_{e,i}=\frac{P_{e,i}}{\left(\eta_{1}r_{i}+\eta_{2}s_{i}\right)}.$

We note that this reduces the problem to the FRIO discrimination of
two pure states in subspace $i$, with prior probabilities given above.
It follows immediately that the solution is given by (\ref{PeSol1})
in the POVM regime of $Q_{i}$, $Q_{i}\leq Q_{c,i},Q_{th,i}$, and
(\ref{PeSol2}) in the projective regime of $Q_{i}$, $Q_{th,i}<Q_{i}\leq Q_{c,i}$,
again with the above substitutions.

In the following we will focus mainly on the POVM regime where the
solution in each subspace is given explicitly by Eq. (\ref{PeSol1}),
\begin{eqnarray}
P_{e,1} & = & \frac{1}{2}(1-Q_{1}-\sqrt{(1-Q_{1})^{2}-(Q_{0,1}-Q_{1})^{2}})\ ,\label{Pei2}\\
P_{e,2} & = & \frac{1}{2}(1-Q_{2}-\sqrt{(1-Q_{2})^{2}-(Q_{0,2}-Q_{2})^{2}})
\end{eqnarray}


Where we introduced a fixed rate of inconclusive outcomes for each
subspace $i$, $Q_{i}$, such that $0\leq Q_{i}\leq Q_{c,i}$ where
$Q_{c,i}$ is given by Eq. (\ref{Qmax}) with the obvious substitutions
$\eta_{1}\rightarrow\eta_{1,i}$, $\eta_{2}\rightarrow\eta_{2,i}$
and $\cos\theta\rightarrow\cos\theta_{i}=\langle r_{i}\vert s_{i}\rangle$
$\Rightarrow$ $Q_{0,i}=2\sqrt{\eta_{1,i}\eta_{2,i}}\langle r_{i}|s_{i}\rangle$.
$Q_{0}$ was introduced in Eq. (\ref{Qmax}) for the single subspace
(two pure states) case, $Q_{0,i}$ is its generalization for the case
of two (or many) subspaces. We introduce the weight $\omega_{i}$
of subspace $i$ as 

\begin{equation}
\eta_{1}r_{i}+\eta_{2}s_{i}=\omega_{i}\ ,\label{omegai}
\end{equation}
where, obviously, 
\begin{equation}
\omega_{1}+\omega_{2}=1\ .\label{weights}
\end{equation}


The total error rate in Eq. (\ref{eq:SubspaceErr}) can be expressed
as weighted sum of the error rates of the individual subspaces

\begin{eqnarray}
P_{e} & = & \omega_{1}P_{e,1}+\omega_{2}P_{e,2}\ ,=\frac{\omega_{1}}{2}\left[\left(1-Q_{1}\right)-\sqrt{\left(1-Q_{1}\right)^{2}-\left(Q_{0,1}-Q_{1}\right)^{2}}\right]+\nonumber \\
 &  & \frac{\omega_{2}}{2}\left[\left(1-Q_{2}\right)-\sqrt{\left(1-Q_{2}\right)^{2}-\left(Q_{0,2}-Q_{2}\right)^{2}}\right]\label{eq:PeTotal}
\end{eqnarray}


The task it to determine the optimal distribution of $Q$ among the
two subspaces, the distribution that minimizes the error rate for
a fixed amount of inconclusive results. We can write the total inconclusive
rate as a weighted of the inconclusive rates of the individual subspaces,

\begin{equation}
Q=\omega_{1}Q_{1}+\omega_{2}Q_{2}\ .\label{Qtot2}
\end{equation}


Since the total failure rate $Q$ is fixed, then only one of the $Q_{i}s$
is an independent variable. Thus the total error rate can be expressed
in terms of only one variable and be optimized in that variable. Inserting
$Q_{2}=\left(Q-\omega_{1}Q_{1}\right)/\omega_{2}$ into Eq. (\ref{eq:PeTotal})
it becomes a function of the independent variable $Q_{1}$ and the
optimization with respect to this variable is straightforward:

\begin{eqnarray*}
P_{e} & = & \frac{\omega_{1}}{2}\left[\left(1-Q_{1}\right)-\sqrt{\left(1-Q_{1}\right)^{2}-\left(Q_{0,1}-Q_{1}\right)^{2}}\right]+\\
 &  & \frac{\omega_{2}}{2}\left[\left(1-\frac{Q}{\omega_{2}}+\frac{\omega_{1}Q_{1}}{\omega_{2}}\right)-\sqrt{\left(1-\frac{Q}{\omega_{2}}+\frac{\omega_{1}Q_{1}}{\omega_{2}}\right)^{2}-\left(Q_{0,2}-\frac{Q}{\omega_{2}}+\frac{\omega_{1}Q_{1}}{\omega_{2}}\right)^{2}}\right].
\end{eqnarray*}


Simply setting the derivative $\frac{\partial P_{e}}{\partial Q_{1}}=0$
and solving for $Q_{1},$ 

\begin{eqnarray*}
0=\frac{\partial P_{e}}{\partial Q_{1}} & = & \frac{1}{2}\left[-\omega_{1}-\frac{\omega_{1}(1-Q_{0,1})}{\sqrt{\left(1-Q_{1}\right)^{2}-\left(Q_{0,1}-Q_{1}\right)^{2}}}\right]+\\
 &  & \frac{1}{2}\left[\omega_{1}-\frac{\omega_{1}(1-Q_{0,2})}{\sqrt{\left(1-\frac{Q}{\omega_{2}}+\frac{\omega_{1}Q_{1}}{\omega_{2}}\right)^{2}-\left(Q_{0,2}-\frac{Q}{\omega_{2}}+\frac{\omega_{1}Q_{1}}{\omega_{2}}\right)^{2}}}\right]\\
\\
\left(1-Q_{0,2}\right)^{2}\left[\left(1-Q_{1}\right)^{2}-\left(Q_{0,1}-Q_{1}\right)^{2}\right] & = & \left(1-Q_{0,2}\right)^{2}\left[\left(1-\frac{Q}{\omega_{2}}+\frac{\omega_{1}Q_{1}}{\omega_{2}}\right)^{2}-\left(Q_{0,2}-\frac{Q}{\omega_{2}}+\frac{\omega_{1}Q_{1}}{\omega_{2}}\right)^{2}\right]
\end{eqnarray*}


\medskip{}


In order to express the optimal failure rates in compact form it will
be useful to introduce at this point the following convention. Without
loss of generality in what follows we assume the hierarchy 
\begin{equation}
Q_{0,1}\geq Q_{0,2}\ .\label{hierarchy2}
\end{equation}
We also introduce the notation 
\begin{equation}
Q_{th}^{(1)}\equiv0\ \ \ \ Q_{th}^{(2)}\equiv\frac{\omega_{1}(Q_{0,1}-Q_{0,2})}{1-Q_{0,2}}\ .\label{Qth12}
\end{equation}
Then result of the optimization can be written as 

\begin{equation}
Q_{1}^{opt}=\left\{ \begin{array}{ll}
\frac{Q}{\omega_{1}} & \mbox{if \ensuremath{Q_{th}^{(1)}\leq Q\leq Q_{th}^{(2)}}},\\
\frac{1-Q_{0,1}}{1-Q_{0}}(Q-Q_{th}^{(2)})+\frac{Q_{th}^{(2)}}{\omega_{1}} & \mbox{if \ensuremath{Q_{th}^{(2)}<Q\leq Q_{0}}},
\end{array}\right.\label{eq:Q1opt}
\end{equation}


and 
\begin{eqnarray}
Q_{2}^{opt}=\left\{ \begin{array}{ll}
0 & \mbox{if \ensuremath{0\leq Q\leq Q_{th}^{(2)}}},\\
\frac{1-Q_{0,2}}{1-Q_{0}}(Q-Q_{th}^{(2)}) & \mbox{if \ensuremath{Q_{th}^{(2)}<Q\leq Q_{0}}}.
\end{array}\right.\label{Q2opt}
\end{eqnarray}


The threshold structure is the interesting feature of this problem.
In the region $0\leq Q\leq Q_{th}^{(2)}$ only one of the subspaces
accommodates the fixed failure rate $Q$, it is the subspace with
the larger $Q_{0,i}$. The other subspace allows for no inconclusive
rate at all, $Q=0$, and operates in the Minimum Error regime. Above
this threshold $\ensuremath{Q_{th}^{(2)}<Q\leq Q_{0}}$, both subspaces
share the failure rate but at different values. If $\omega_{1}Q_{0,1}>\omega_{2}Q_{0,2}$,
the first subspace always accommodates more inconclusive rate than
the second, otherwise above some value of the total $Q$ the second
subspace will accommodate more inconclusive rate than the first.

The situation is depicted in Fig. \ref{Fig2}, for some specific values
of the parameters. 
\begin{figure}[ht]
\centering $\begin{array}{c}
\includegraphics[height=4.5cm]{Fig2a.png}\\
\mbox{(a)}\\
\includegraphics[height=4.5cm]{Fig2b.png}\\
\mbox{(b)}
\end{array}$ \protect\caption[\hspace{1cm}$\omega_{1}Q_{{\rm 1}}^{{\rm opt}}$ vs. $Q$ and $\omega_{2}Q_{{\rm 2}}^{{\rm opt}}$
vs.~$Q$ .]{ $\omega_{1}Q_{{\rm 1}}^{{\rm opt}}$ vs. $Q$ (solid line) and $\omega_{2}Q_{{\rm 2}}^{{\rm opt}}$
vs.~$Q$ (dashed line). For the figure we used $\eta_{1}=\eta_{2}=1/2$
and the following parameter values: (a) $\theta_{1}=\pi/4$, $\theta_{2}=2\pi/7$,
$r_{1}=3/4$, $r_{2}=1/4$, $s_{1}=3/4$ and $s_{2}=1/4$; (b) $\cos\theta_{1}=1/4\sqrt{3}$,
$\cos\theta_{2}=1/4$, $r_{1}=3/4$, $r_{2}=1/4$, $s_{1}=3/4$ and
$s_{2}=1/4$.}
\label{Fig2} 
\end{figure}


\bigskip{}


To get the expression of the total error rate as a function of FRIO,
insert (\ref{eq:Q1opt}) and (\ref{Q2opt}) into (\ref{eq:PeTotal}), 

\[
P_{E}=\left\{ \begin{array}{ll}
\frac{1}{2}\!\left\{ \left(1-Q\right)-\sqrt{(\omega_{1}-Q)^{2}-\left(\omega_{1}Q_{0,1}-Q\right)^{2}}-\sqrt{(\omega_{2})^{2}-\left(\omega_{2}Q_{0,2}\right)^{2}}\right\}  & \mbox{ if \ensuremath{Q_{th}^{(1)}\leq Q\leq Q_{th}^{(2)}}}\ ,\\
\frac{1}{2}\!\left\{ \left(1-Q\right)-\sqrt{(1-Q)^{2}-\left(Q_{0}-Q\right)^{2}}\right\}  & \mbox{ if \ensuremath{Q_{th}^{(2)}<Q\leq Q_{0}}}\ ,
\end{array}\right.
\]


We will show that this is valid in all regions of the parameter $Q$.
For $Q=0$ it reduces to the optimal Minimum Error expression for
two subspaces \cite{Bergou2006}, as it should. On the other hand
for $P_{e}=0$ it reduces to the optimal Unambiguous Discrimination
of two subspaces \cite{Herzog2005,Bergou2006a} We close this section
by displaying $P_{e,i}$ vs. $Q$ in Fig. \ref{Fig3}, for some specific
values of the parameters.

\begin{figure}[ht!]
\centering $\begin{array}{c}
\includegraphics[height=4.5cm]{Fig3a.png}\\
\mbox{(a)}\\
\includegraphics[height=4.5cm]{Fig3b.png}\\
\mbox{(b)}\\
%\includegraphics[height=4.5cm]{2stateintersectionerrorzoomed-1.png}
\end{array}$ % \centering % \includegraphics[height=4.5 cm]{2 states error-1.png} 
\protect\caption[\hspace{1cm}$\omega_{1}P_{e,{\rm 1}}^{{\rm opt}}$ vs. $Q$ and $\omega_{2}P_{e,{\rm 2}}^{{\rm opt}}$
vs.~$Q$ . ]{$\omega_{1}P_{e,{\rm 1}}^{{\rm opt}}$ vs. $Q$ (solid line) and
$\omega_{2}P_{e,{\rm 2}}^{{\rm opt}}$ vs.~$Q$ (dashed line). For
the figure we used the same parameter values as in Fig. \ref{Fig2}.
The insert in (b) shows that the solid and dashed lines intersect
for a very small value of $Q$.}
\label{Fig3} 
\end{figure}


\bigskip{}



\section{FRIO discrimination of two Rank $N$ mixed states, POVM regime}

In this section we present the more general solution to the two rank
$N$ density matrices, where $N$ is some arbitrary but fixed integer.
The two density matrices exhibit the Jordan basis as described in
(\ref{rho1and2}) and (\ref{eq:jordan}). Solving the problem is very
similar to the method for two rank 2 mixed states in the preceding
section. 

The definitions and properties presented in Eqs. (\ref{eq:jordan})--(\ref{omegai})
remain in effect but the part starting with Eq. (\ref{weights}) has
to be modified accordingly.The weights of the subspaces, introduced
in (\ref{omegai}) now satisfy 
\begin{equation}
\sum_{i=1}^{N}\omega_{i}=1\ .\label{Nweights}
\end{equation}


The total inconclusive rate can again be written as a weighted sum
of the inconclusive rates of the individual subspaces, 
\begin{equation}
Q=\sum_{i=1}^{N}\omega_{i}Q_{i}\ .\label{NQtot}
\end{equation}
$Q$ is fixed, with the fixed value satisfying $0\leq Q\leq Q_{0}$,
where now 
\begin{equation}
Q_{0}\equiv\sum_{i=1}^{N}\omega_{i}Q_{0,i}\ ,\label{NQ0}
\end{equation}
 is the maximal inconclusive rate that the $N$ subspaces can accommodate. 

Similarly, the total error rate is a weighted sum of the error rates
of the individual subspaces, 
\begin{equation}
P_{e}=\sum_{i=1}^{N}\omega_{i}P_{e,i}\ .\label{NPe}
\end{equation}


The remaining task is to determine the optimal distribution of $Q$
between the $N$ subspaces, the distribution that minimizes the total
error rate $P_{e}$, under the constraint that $Q$ in Eq. (\ref{NQtot})
is fixed, i.e., to determine the optimal values of $Q_{i}$ as a function
of the fixed $Q$.

In order to perform the optimization we employ the Lagrange multiplier
method because it leads to symmetric and easily tractable equations.
Adding the Lagrange multiplier $\lambda$ times the constraint, $Q-\sum_{i=1}^{N}Q_{i}=0$,
to (\ref{NPe}) yields the function 
\begin{equation}
F=\sum_{i=1}^{N}\omega_{i}P_{e,i}+\lambda(Q-\sum_{i=1}^{N}\omega_{i}Q_{i})\ ,\label{constrainedF}
\end{equation}
where $P_{e,i}$ is inserted from Eq. (\ref{Pei2}), so it is also
a function of $Q_{i}$. Next we vary $F$ treating the variables $Q_{1},Q_{2},....,Q_{N}$
as independent. Solving the resulting equations together with the
constraint (\ref{NQtot}) determines the value of the Lagrange multiplier
$\lambda$ which in return optimizes \ref{NPe}. 

Before we present the results it will prove useful to introduce a
hierarchy of the subspaces. So, in what follows we will assume 
\begin{equation}
Q_{0,1}\geq Q_{0,2}\geq\ldots\geq Q_{0,N}\ ,\label{hierarchy}
\end{equation}
which generalizes the ordering used in the case of two subspaces in
the previous section.

Then the optimal $Q_{i}$ can be written as 
\begin{eqnarray}
Q_{i}^{opt}=\left\{ \begin{array}{ll}
\frac{1-Q_{0,i}}{\sum_{i=1}^{k}\omega_{i}-\sum_{i=1}^{k}\omega_{i}Q_{0,i}}Q+\frac{Q_{0,i}\sum_{i=1}^{k}\omega_{i}-\sum_{i=1}^{k}\omega_{i}Q_{0,i}}{\sum_{i=1}^{k}\omega_{i}-\sum_{i=1}^{k}\omega_{i}Q_{0,i}} & \ \ \ \\
\mbox{if \ensuremath{Q_{th}^{(k)}\leq Q\leq Q_{th}^{(k+1)}} and \ensuremath{i\leq k}}\ ,\\
0\\
\mbox{if \ensuremath{i>k}}\ .
\end{array}\right.\label{Qiopt}
\end{eqnarray}
 Here $k=1,2,\ldots,N$ and we introduced the notation 
\begin{equation}
Q_{th}^{(k)}=\frac{\sum_{i=1}^{k}\omega_{i}Q_{0,i}-Q_{0,k}\sum_{i=1}^{k}\omega_{i}}{1-Q_{0,k}}\ .
\end{equation}
and also $Q_{th}^{(N+1)}=Q_{0}=Q_{max}$, cf. (\ref{NQ0}). Obviously,
for $k=1,2$ these results reproduce the results for two subspaces,
Eqs. (\ref{Qth12})--(\ref{Q2opt}).

Inserting the optimal failure rates into the subspace-error rates
$P_{e,i}$, (\ref{Pei2}), gives the optimal error rates for the subspaces,
$P_{e,i}^{opt}$. Then using these optimal subspace-error rates in
(\ref{NPe}) gives the total optimal error rate $P_{E}=\sum_{i=1}^{N}P_{e,i}^{opt}$,
\begin{eqnarray}
P_{E}=\left\{ \begin{array}{ll}
\frac{1}{2}\left[1-Q-\sqrt{\left(\sum_{i=1}^{k}\omega_{i}-Q\right)^{2}-\left(\sum_{i=1}^{k}\omega_{i}Q_{0,i}-Q\right)^{2}}-\sum_{i=k+1}^{N}\sqrt{(\omega_{i})^{2}-\left(\omega_{i}Q_{0,i}\right)^{2}}\right] & \mbox{ if \ensuremath{Q_{th}^{(k)}\leq Q\leq Q_{th}^{(k+1)}}}\\
{} & \mbox{ and \ensuremath{k<N}}\ ,\\
\frac{1}{2}\!\left[1-Q-\sqrt{(1-Q)^{2}-\left(Q_{0}-Q\right)^{2}}\right] & \mbox{ if \ensuremath{Q_{th}^{(N)}<Q\leq Q_{0}}}\ ,
\end{array}\right.\label{eq:PEN}\\
\end{eqnarray}
which is valid in all regions of the parameter $Q$. For $N=2$, (\ref{eq:PEN})
reduces to the two-subspaces solution, (\ref{PE2}). For the maximum
allowable inconclusive rate, $Q=Q_{0}$, the second line in Eq. (\ref{eq:PEN})
holds and it reduces to $P_{E}=0$, corresponding to optimal Unambiguous
Discrimination of the subspaces , while for $Q=0$ the first line
holds and it reduces to the Minimum Error expression for $N$ subspaces
, as expected.

Again, the most interesting aspect of the optimal solution is that
a structure with multiple thresholds emerges. For $Q_{th}^{(1)}=0\leq Q<Q_{th}^{(2)}$
the total available inconclusive rate is accommodated by the first
subspace only and all others operate at the Minimum Error level. According
to the hierarchy introduced in Eq. (\ref{hierarchy}), the first subspace
is the one with the largest $Q_{0,i}$. Then between $Q_{th}^{(2)}\leq Q<Q_{th}^{(3)}$
the second subspace, the one with the second largest $Q_{0,i}$ will
also participate in sharing the available inconclusive rate, while
the remaining $N-2$ subspaces continue to operate at the minimum
error level. In general, in the interval $Q_{th}^{(k)}\leq Q<Q_{th}^{(k+1)}$
the first $k$ subspaces share the available inconclusive rate and
the remaining $N-k$ subspaces remain at the minimum error level.
Finally, in the range $Q_{th}^{(N)}\leq Q\leq Q_{0}=Q_{max}$ all
$N$ subspaces participate in sharing the available inconclusive rate.

It is easy to show that the expressions are continuous at the threshold,
i.e. the expressions valid below the threshold and the ones valid
above the threshold tend to the same values at the threshold, although
their slopes are, in general, different below and above the threshold.
Furthermore, if $\omega_{i}Q_{0,i}>\omega_{i+1}Q_{0,i+1}$, the $i^{th}$
subspace always accommodates more inconclusive rate than the $i+1^{st}$
for all $i=1,2,\ldots,N$, otherwise above some value of the total
$Q$ the $i+1^{st}$ subspace will accommodate more inconclusive rate
than the $i^{th}$ subspace, the $Q_{i}^{opt}(Q)$ curves will intersect
(see part (b) of Fig. \ref{Fig2} for an example).

We illustrate these results on the example of $N=3$. In Fig. \ref{Fig4},
we plot the optimal failure rates $\omega_{i}Q_{i}^{{\rm opt}}$ and
in Fig. \ref{Fig5}, we plot the optimal error rates $\omega_{i}P_{e,i}^{{\rm opt}}$
for the three subspaces as a function of the total failure rate $Q$
for some specific values of the parameters. 
\begin{figure}[ht]
\centering $\begin{array}{c}
\includegraphics[height=4cm]{Fig4.png}\end{array}$\protect\caption[\hspace{1cm}$\omega_{i}Q_{i}^{opt}$ vs. $Q$ ]{ Optimal subspace failure rates $\omega_{i}Q_{i}^{opt}$ vs. $Q$
from Eq. (\ref{Qiopt}), for three subspaces ($i=1,2,3$). $\omega_{1}Q_{1}^{opt}$:
solid line. $\omega_{2}Q_{2}^{opt}$: dashed line. $\omega_{3}Q_{3}^{opt}$:
dotted line. For the figure we used $\eta_{1}=\eta_{2}=1/2$ and the
following parameter values: $\theta_{1}=\pi/4$, $\theta_{2}=\pi/3$,
$\theta_{3}=\pi/3$, $r_{1}=5/8$, $r_{2}=1/4$, $r_{3}=1/8$, $s_{1}=3/8$,
$s_{2}=1/4$ and $s_{3}=3/8$.}
\label{Fig4}
\end{figure}


\begin{figure}[ht]
\centering $\begin{array}{c}
\includegraphics[height=4cm]{Fig5.png}\end{array}$\protect\caption[\hspace{1cm}$\omega_{i}P_{e,i}^{opt}$ vs. $Q$ ]{Optimal subspace error rates $\omega_{i}P_{e,i}^{opt}$ vs. $Q$
from Eq. (\ref{Pei2}) with (\ref{Qiopt}), for three subspaces ($i=1,2,3$).
$\omega_{1}P_{e,1}^{opt}$: solid line. $\omega_{2}P_{e,2}^{opt}$:
dashed line. $\omega_{3}P_{e,3}^{opt}$: dotted line. For the plots
we used the same parameter values as for Fig. \ref{Fig4}.}
\label{Fig5} 
\end{figure}


The results presented so far are valid if the parameters are such
that in all subspaces we are in the POVM regime, i.e., $Q_{i}$ is
in the unshaded region (region II) of Fig. 1 for all $i$. When the
parameters are such that in some subspaces we are in the projective
regime, i.e., $Q_{i}$ falls in the shaded regions of Fig. 1 (regions
I and III) for some $i$ we have to modify the treatment to account
for the fact that the error expression for the corresponding subspace,
$P_{e,i}$, is no longer given by Eq. (\ref{Pei2}) but by (\ref{PeSol2Exp}).
We will study this case in the next section.


\section{Projective regime}

We have seen for the single subspace case that the POVM solution is
valid if the inconclusive rate is smaller than a boundary value, $Q\leq Q_{b}$,
where $Q_{b}$ is given by Eq. (\ref{Qb}). With an obvious generalization,
the POVM solution holds in subspace $i$ if in that subspace $Q_{i}\leq Q_{b,i}$
holds where the subspace boundary value is given by 
\begin{equation}
Q_{{\rm b,i}}\equiv{2\eta_{1,i}\eta_{2,i}\sin^{2}\theta_{i}/(1-Q_{0,i})}.\label{Qbi}
\end{equation}
%In Fig. \ref{Fig6} we plot $Q_{\rm c,i}$ and~$Q_{\rm b,i}$ vs.~$\eta_{1}$ together for a fixed overlap, %$\cos\theta = 0.5$ ($\theta = \pi/3$). %\begin{figure}[ht]%\textbf{$Q_{i}$ vs. $\eta_{1,i}$}%\centering%$%%\begin{array}{c}%\includegraphics[height=4 cm]{Figure2.png} \\%\end{array}%%$%%\caption{$Q_i$ vs. $\eta_{1,i}$. Dashed line: $Q_{b,i}$. Solid line: $Q_{i}^{max}=Q_{c,i}$. The two curves %intersect at $\eta_{1,i}^{(l)}$ and $\eta_{1,i}^{(r)}$.  For the plot we chose $\theta_{i} = \pi /3$.}%\label{Fig6}%\end{figure}

In the region $Q_{b,i}\leq Q_{i}\leq Q_{c,i}$ the optimal measurement
is a standard projective quantum measurement (SQM). The curves $Q_{b,i}$
and $Q_{c,i}$ intersect at $\eta_{1,i}=\eta_{1,i}^{(l)}$ and $\eta_{1,i}=\eta_{1,i}^{(r)}$,
the same points as in Eq.~(\ref{Qmax}). The interval $0\leq\eta_{1,i}\leq1$
is thus divided into three regions. In regions~I and~III, we have
$Q_{{\rm b,i}}<Q_{{\rm c,i}}$ and the solution~(\ref{PeSol1}) is
valid for $0\leq Q_{i}<Q_{{\rm b}}$ only. In Region II, $\eta_{1,i}^{(l)}\leq\eta_{1,i}\leq\eta_{1,i}^{(r)}$,
we have $Q_{{\rm c,i}}=Q_{0,i}<Q_{{\rm b,i}}$ and the solution (\ref{PeSol1})
is valid for the entire $0\leq Q_{i}\leq Q_{{\rm c,i}}$ range.

Thus, Fig. \ref{Fig1} is valid in every subspace, with the obvious
change of axis labels to $Q_{i}$ and $\eta_{1,i}$. So, $Q_{i}>Q_{b,i}$
occurs in regions I and III and in the shaded areas the optimal FRIO
measurement is an SQM while in the unshaded area it is a POVM. We
now illustrate the case when the FRIO measurement is a POVM in one
and an SQM in the other subspace on an example. %We consider two subspaces with $\eta_1 = \eta_2$ and the other parameters are listed in Table %\ref{table1}.%\begin{table}[h!]%\begin{center}%\caption{Alice's measurement outcomes and Bob's subsequent operations.}%\vspace{4mm}%\begin{tabular}{||c||c|c|c|c|c|c|c||}%\hline%Subspace $i$ & $r_{i}$ & $s_{i}$ & $\theta_{i}$ & $\omega_{i}$ & $Q_{0,i} $ & $Q_{b,i}$ & $Q_{c,i}$ \\ %\hline \hline%1 & $\frac{9}{10}$ & $\frac{1}{10}$ & $\frac{\pi}{16}$ & $\frac{1}{2}$ &$0.5885$ & $0.01665$ & %$0.96575$ \\ \hline %2 & $\frac{1}{10}$ &$\frac{9}{10}$  &$\frac{3\pi}{7}$ &$\frac{1}{2}$ &$0.1335$ & $0.19745$ & $01335$ \\ %\hline%3 &$\frac{3}{8}$  & $\frac{5}{8}$  &$\frac{3\pi}{7}$ &$\frac{1}{2}$ &$Q^{>}_3 = 29/64 \approx .45$ \\ \hline%\end{tabular}%\%\%\label{table1}%\end{center} %\end{table}

%For subspace 1 these parameters give $\eta_{1,l}=1-\eta_{1,r}=0.4903$ and since $\eta_{1,1}=0.9 > %\eta_{1,r}$ the optimum measuerement is a POVM for $0 \leq Q \leq Q_{b,1}=0.01665$ and an SQM for %$0.01665 \leq Q \leq 0.96575$. Subspace 2 is in the POVM regime for all values of $Q$. 

The optimal distribution of the total available inconclusive rate
$Q$ between the two subspaces, $Q_{1}^{opt}$ and $Q_{2}^{opt}$
such that their sum satisfies $Q_{1}^{opt}+Q_{2}^{opt}=Q$, can be
found by optimizing the total error rate with respect to the failure
rate of the subspaces. We now have to use the error expression (\ref{PeSol2Exp})
in subspace 1 for $Q>Q_{b,1}$. This leads to a numerical optimization
problem, the result of which is shown in Fig. \ref{Fig6}. %\subsection{Second elimination}

\begin{figure}[ht]
\centering $\begin{array}{c}
\includegraphics[height=4cm]{Fig6.png}\end{array}$\protect\caption[\hspace{1cm}$\omega_{i}Q_{i}^{opt}$ vs. $Q$]{Optimal subspace failure rates $\omega_{i}Q_{i}^{opt}$ vs. $Q$
from Eq. (\ref{Qiopt}), for two subspaces ($i=1,2,3$). $\omega_{1}Q_{1}^{opt}$:
solid upper line. $\omega_{2}Q_{2}^{opt}$: solid lower line. The
dashed lines indicate the behavior of the corresponding quantities
if the POVM solution were valid for subspace 1. For the figure we
used $\eta_{1}=\eta_{2}=1/2$ and the following parameter values:
$\theta_{1}=\pi/16$, $\theta_{2}=3\pi/7$, $r_{1}=9/10$, $r_{2}=1/10$,
$s_{1}=1/10$ and $s_{2}=9/10$. }
\label{Fig6} 
\end{figure}


The solution again exhibits a threshold structure. The dashed lines
in the figure indicate how the optimal $Q_{i}$'s would behave if
the POVM solution were valid for subspace 1 instead of the SQM. It
is apparent that the SQM shifts the threshold toward a higher value
of $Q$ and above the threshold the dependence on $Q$ is nonlinear,
while for the POVM regime it is always linear.

The optimal inconclusive rate for subspace $i$, $Q_{i}^{opt}$, displayed
in Fig \ref{Fig6}, is then inserted into Eq. (\ref{PeSol2Exp}) for
$i=1$ and (\ref{Pei2}) for $i=2$. This yields the optimal error
rate for subspace $i$, $P_{e,i}^{opt}$. The results are displayed
in Fig. \ref{Fig7}.

\begin{figure}[ht]
\centering $\begin{array}{c}
\includegraphics[height=4cm]{Fig7.png}\end{array}$\protect\caption[\hspace{1cm}$P_{e,i}^{opt}$ vs. $Q$ ]{Optimal subspace error rates $P_{e,i}^{opt}$ vs. $Q$ from Eq. (\ref{Qiopt}),
for two subspaces ($i=1,2$). $P_{e,1}^{opt}$: solid upper line.
$P_{e,2}^{opt}$: solid lower line. The dashed lines indicate the
corresponding quantities if the POVM solution were valid in subspace
1. For the plots we used the same parameter values as for Fig. \ref{Fig6}.}
\label{Fig7} 
\end{figure}


The optimal error rates also exhibit a threshold structure. Relative
to the POVM regime, the SQM shifts the threshold to a higher value
of $Q$ and the overall error rate also increases.


\section{Summary and conclusion}

We have found analytic solutions for the optimal discrimination measurement
strategy when a fixed rate of inconclusive outcomes, $Q$, is allowed
(FRIO strategy), for a class of mixed states that exhibit a Jordan
Basis structure. Thus our work extends the previously introduced FRIO
strategy from pure states \cite{Bagan2012} to mixed states. In this
strategy the probability of making an error in identifying the state,
$P_{e}$, is minimized for a fixed $Q$ and the solution optimally
interpolates between the minimum error ($Q=0$) and unambiguous discrimination
($P_{e}=0$) limits. We found several surprising and unexpected conclusions.
The first is that the form of the optimal error rate remains formally
the same over all subspaces as in the case of two pure states, which
is a consequence of the Jordan structure of the mixed states. The
second is a more striking feature, the emergence of a threshold structure:
as we increase the allowed inconclusive rate $Q$, starting from $Q=0$,
at first only one subspace accommodates all of the available $Q$.
Above a certain threshold a second subspace starts sharing the available
$Q$, above yet another higher threshold a third subspace starts participating,
etc., until above a final threshold all of the subspaces participate.
It is interesting to note that in this last regime the optimal error
expression the second line in Eq. (\ref{eq:PEN}) is formally the
same as the result for two pure states. This is a novel type of behavior
and allows for experimental tests of our findings. Applications could
be considered in cryptography where a key is shared over different
lines to enhance security without sacrificing overall error rate.


\chapter{Quantum Cloning}

One of the reasons we need to develop optimum state discrimination
measurement schemes is due to the no cloning theorem of Wootters,
Zurek \cite{Wootters1982} and Dieks \cite{Dieks1982}. If one could
copy non-orthogonal quantum states then by making a very large number
of copies, it would be possible to distinguish the states. However
cloning machines which optimize some criteria with a limited degree
of success have been developed. Those cloning machines fall under
two categories: universal and state dependent. Universal cloning machines,
which make copies of a completely unknown quantum state, were developed
first by Buzek and Hillery \cite{Buzek1996}. This scheme makes approximate
copies of an unknown quantum state while optimizing the local fidelity
which is the square overlap of the approximate clones and the original
state it is supposed to clone. The other category is state dependent
cloning machines. In this scheme the observer has full knowledge of
the prepared states but does not know which is the state he is given.
There are two subcategories within this scheme: approximate and exact
cloning. Approximate state-dependent cloning machines deterministically
generate approximate clones from a finite set of non-orthogonal quantum
states while optimizing the local or global fidelity (the average
square overlap between full set of approximate clones and the states
to be cloned). Hillery and Buzek \cite{Hillery1997} are the pioneers
of this subcategory of cloning machines as well. In exact state-dependent
cloning machines, the other subcategory of quantum cloning machines,
the task is to probabilistically make exact copies of the incoming
non-orthogonal quantum states. This comes at the expense of allowing
for failure results where the scheme fails to produce a copy altogether.
Duan and Guo \cite{Duan1998} were first to develop probabilistic
exact cloning machines for the two state input where the states are
prepared with equal a priori probabilities. We recently extended this
method for the more general case where the a priori probabilities
of the incoming states are different {[}{]}. This extension not only
solves the full problem but gives new insight into the nature of quantum
cloning. The symmetry of the equal priors case completely solves the
problem and no further optimization can be done. This symmetry however
hides the true nature of the exact cloning machines which show up
in the unequal priors case. This can be shown through a two step process:
exact cloning then optimal UD on the clones. First procedure makes
exact clones of the incoming two states. The exact clones are then
sent to an optimal UD machine where the average failure rate is minimized.
To combine the two step process the inconclusive rate from the cloning
process is added to the inconclusive rate, weighed with the new a-priori
probabilities, from the optimal UD. When the input states are prepared
with equal a-priors the total amount of the inconclusive rate reaches
the IDP limit. Hence cloning then performing optimal UD is equivalent
to simply performing the optimal UD first, then prepare the clones.
However this is not true for when the priors of the input states are
different. After the two step process the total inconclusive rate
is higher then the IDP limit. This suggests that during the cloning
process some information is being leaked due to the asymmetry of the
failure rate operators. When performing exact cloning, clones are
produced but no measurement has been made, hence we do not know which
states are being cloned. We simply know whether the procedure was
successful or it failed. When it fails, the states are discarded.
This is where the information leakage comes in. The state which is
prepared most often shall have a higher rate of failure. This does
not happen in the equal priors case because the failure rate are symmetric. 


\section{No-Cloning Theorem}

Some of the schemes described in this dissertation related to discriminate
quantum states would not be necessary if one could make copies of
the non-orthogonal quantum states as can be done with classical states.
If this were possible then the receiver, Bob, after receiving the
state $|\psi_{1}\rangle$ or $|\psi_{2}\rangle$ from the preparer,
Alice, makes $n$ number of copies. After a large set of copies the
states become nearly orthogonal and almost fully distinguishable.
The average inconclusive rate of failing to distinguish the $n$ copies
of $|\psi_{1}\rangle$ or $|\psi_{2}\rangle$ is $Q_{o}=2\sqrt{\eta_{1}\eta_{2}}s^{n}.$
For a large $n$ the inconclusive rate is very small and Bob can discriminate
nearly all incoming states. 

Thus while in classical information it is possible to make exact copies
of information, as this dissertation is printed on this paper, multiple
times by a printer. The no-cloning theorem forbids the receiver doing
the same with quantum states. More specifically it is non-orthogonal
quantum states which cannot be copied, as classical states are a special
case of quantum states, that of orthogonal states. 

Let us now show a proof by contradiction of why such a quantum cloning
machine cannot exist. Suppose there is such a cloning machine with
an input and an output port. Inside the machine there are two slots:
slot $S$ for the system state $|\psi_{i}\rangle$ to be copied, and
slot $A$ for the ancilla state for where the input state is to be
copied. Let the ancilla be in some blank space $|0\rangle,$ then
the initial state of the copying machine would be: $|\psi_{i}\rangle|0\rangle.$
A unitary operator would copy the state $|\psi_{i}\rangle$ into $|0\rangle:$ 

\begin{equation}
U|\psi_{i}\rangle|0\rangle=|\psi_{i}\rangle|\psi_{i}\rangle
\end{equation}


Let there be two possible input states to be copied, $\{|\psi_{1}\rangle,|\psi_{2}\rangle\}$
and we are interested in a quantum cloning machine which produces
$|\psi_{1}\rangle|\psi_{1}\rangle$ when $|\psi_{1}\rangle$ is sent
and $|\psi_{2}\rangle|\psi_{2}\rangle$ when $|\psi_{2}\rangle$ is
sent. The unitary operator would do the following. 

\begin{eqnarray}
U|\psi_{1}\rangle|0\rangle & = & |\psi_{1}\rangle|\psi_{1}\rangle\nonumber \\
U|\psi_{2}\rangle|0\rangle & = & |\psi_{2}\rangle|\psi_{2}\rangle
\end{eqnarray}


The inner product of these equations gives $\langle\psi_{2}|\psi_{1}\rangle\langle0|0\rangle=|\langle\psi_{2}|\psi_{1}\rangle|^{2}\Rightarrow s=s^{2}.$
This condition can be satisfied only if $s=0$, states are orthogonal,
or $s=1,$ the two states are the same. But we said that the two states
are distinct and non-orthogonal. Thus one cannot design a unitary
device which makes perfect clones of an unknown quantum system deterministically.
Here we only proved that non-orthogonal pure states cannot be copied
through a unitary process. Other proofs exist which show that this
holds for mixed states and also for other non-unitary processes. 

Since such a machine cannot be designed the next logical step is to
build a quantum machine which produces clones similar to the input
states while allowing for some fidelity or inconclusive results. We
derive some previous results considering such quantum cloning machines
and also provide new results for optimal exact cloning with some inconclusive
rate allowed. In a follow up section we interpolate between the deterministic
cloning scheme and exact cloning by relaxing some of the conditions. 


\section{Exact cloning with failure rate}

In probabilistic cloning we are concerned with making exact copies
of the given quantum state. It is indeed possible to make exact copies
but only probabilistically. This is similar to the Unambiguous Discrimination
where one discriminates between a given set of non-orthogonal quantum
states unambiguously while allowing for a failure rate. 

We approach probabilistic cloning via the Neumark formulation. The
system is embedded in a larger Hilbert space where the extra degrees
of freedom are customarily called the ancilla. Then a unitary transformation
entangles the system degrees of freedom with those of the ancilla.
The input states $\{|\psi_{1}^{M}\rangle_{s},|\psi_{2}^{M}\rangle_{s}\}$
which live in the state Hilbert space $S$ are embedded with the ancilla
$|i\rangle_{a}$ which live in the $N-M$ dimensional Hilbert space
$A.$ Now the system and the ancilla live in the larger Hilbert space
$H=S\varotimes A.$ The incoming states in this larger Hilbert space
can be written in the product form $\{|\psi_{1}^{N}\rangle_{s}|i\rangle_{a},|\psi_{2}^{N}\rangle_{s}|i\rangle_{a}\}.$
The unitary should do the following: 

\begin{eqnarray}
U|\psi_{1}^{M}\rangle|i\rangle^{N-M} & = & \sqrt{p_{1}}|\psi_{1}^{N}\rangle|\alpha_{1}\rangle+\sqrt{q_{1}}|\Phi_{1}\rangle,\label{eq:clone1}\\
U|\psi_{2}^{M}\rangle|i\rangle^{N-M} & = & \sqrt{p_{2}}|\psi_{2}^{N}\rangle|\alpha_{2}\rangle+\sqrt{q_{2}}|\Phi_{2}\rangle,\label{eq:clone2}
\end{eqnarray}


Where $p_{i}$ is the rate of having successfully produced a perfect
clone, $q_{i}$ is the rate of having failed to do so. The inner product
of each of the above equation with its own transpose gives the normalized
probabilities $p_{i}+q_{i}=1$. $|\psi_{i}\rangle$ are the input
states we wish to clone and their corresponding ancillas are $|\alpha_{i}\rangle$.
Getting a click in $|\Phi_{i}\rangle$ means we have failed to clone
and discard the state. 

Taking the inner product of the transpose of equation (\ref{eq:clone1})
with (\ref{eq:clone2}) we get the constraint of success and failure
rate in terms of the overlap of the input states. 

\begin{equation}
s^{M}=\sqrt{p_{1}p_{2}}s^{N}\alpha+\sqrt{q_{1}q_{2}}\phi
\end{equation}


where: 
\[
s=\langle\psi_{1}|\psi_{2}\rangle,\quad s'=\langle\Psi_{1}|\Psi_{2}\rangle,\quad\alpha=\langle\alpha_{1}|\alpha_{2}\rangle,\quad\phi=\langle\Phi_{1}|\Phi_{2}\rangle
\]
In the above setup the ancilla states corresponding to successfully
making the clones are distinct. The failure states are also distinct.
That is the most general case. In order for the success rates to be
optimal we take the ancilla states to be the same. Looking at the
constraint we absorb $\alpha$ into $s$, meaning there is more copies
which would come at the expense of a lower $p_{i}$ . More explicitly
this can be proved for the equal priors case shown below. We will
now prove that the failure states should also be the same. If $|\Phi_{1}\rangle$
and $|\Phi_{2}\rangle$ are different that means that there is still
information left in the failure states and we can still perform Unambiguous
State discrimination and probabilistically determine whether we received
$|\psi_{1}\rangle$ or $|\psi_{2}\rangle$ . The optimal strategy
is one which leaves no information at all in the failure states, the
overlap of the failure states can be set to one $\langle\Phi_{2}|\Phi_{1}\rangle=1.$
Any click from the failure state is simply discarded as failure. The
revised Neumark setup reduces to: 

\begin{eqnarray}
U|\psi_{1}^{M}\rangle|i\rangle & = & \sqrt{p_{1}}|\psi_{1}^{N}\rangle\ket{\alpha}+\sqrt{q_{1}}|\Phi\rangle\ket 0,\nonumber \\
U|\psi_{2}^{M}\rangle|i\rangle & = & \sqrt{p_{2}}|\psi_{2}^{N}\rangle|\alpha\rangle+\sqrt{q_{2}}|\Phi\rangle\ket 0,
\end{eqnarray}


The constraint simplifies into:

\begin{equation}
s^{M}=\sqrt{p_{1}p_{2}}s^{N}+\sqrt{q_{1}q_{2}}.\label{eq:clone overlap}
\end{equation}


This is the constraint on the parameters to optimize the average failure
rate $Q=\eta_{1}q_{1}+\eta_{2}q_{2}.$ The optimization is straightforward
for the symmetric case where the input states are prepared with equal
priors. The general case, states prepared with different a priori
probabilities, leads to a sixth order equation the solution of which
isn't very useful. A geometric picture however emerges which is more
insightful. 


\subsection{Equal priors. }

When the input states are prepared with equal prior probabilities,
$\eta_{1}=\eta_{2}=\frac{1}{2},$ the problem is quite trivial. It
was first solved by Duan and Guo \cite{Duan1998}. For equal priors
the success and failure rate reduce to: $p_{1}=p_{2}=p$, $q_{1}=q_{2}=q$.
The constraint in (\ref{eq:clone overlap}) reduces to:

\begin{equation}
s^{M}=ps^{N}+q,
\end{equation}


using the unitarity condition $p+q=1,$ the problem can be fully solved:

\begin{eqnarray}
s^{M} & = & ps^{N}+(1-p),\nonumber \\
p & = & \frac{1-s^{M}}{1-s^{N}}
\end{eqnarray}


and the failure rate is $q=1-p=\frac{s^{M}-s^{N}}{1-s^{N}}.$ 

Thus the optimization of the probabilistic exact cloning is fully
solved from the constraint derived from the Neumark method and no
further optimization is needed. In the limit of producing infinitely
many clones, $N\rightarrow\infty$, the failure rate reduces to $q=s^{M},$
which is also the IDP result for unambiguous state discrimination.


\subsection{Unequal priors I}

There are a number of reasons why one might want to solve the general
problem with arbitrary priori probabilities. (i)~The solution to
the equal priors problem is obtained using only symmetry arguments,
with no need for optimization. (ii)~A general solution would check
the robustness of the equal priors case against variations of the
prior probabilities around $1/2$. This gives control over errors
that are unavoidable for any physical realization. (iii)~One could
consider a discrimination protocol consisting of optimal cloning followed
by optimal Unambiguous Discrimination (UD) of the produced clones,
which we will call discrimination by cloning. Surprisingly this is
optimal for equal prior probabilities and for any number of clones
(see below). This suggests that the equal priors case is very special
and can provide a deceptive view of cloning. (iv)~In the limit of
infinitely many clones, the optimal strategy prepares the clones according
to the outcomes of UD of the input states. This is a particular case
of a measure and prepare protocol, which we will call cloning by discrimination.
Since the UD measurement varies over the range of prior probabilities
(a 3-outcome generalized measurement vs a 2-outcome projective measurement),
this hints at the possibility of a similar situation for optimal cloning
that can only be decided by solving the general problem.

Our solution shows that discrimination by cloning as outlined in (iii)
is sub-optimal for unequal prior probabilities (unless one state is
never sent). This indicates that the equal prior case is not representative
of state dependent cloning. Additionally, contrary to the suggestions
in~(iv) above, our solution leads to a failure probability that is
a smooth function of the priors. However, the strategy converges to
cloning by discrimination as~$N\to\infty$, implying a discontinuous
second derivative of the total inconclusive rate with respect to $\eta_{i}$
and revealing a phenomenon similar to a second order phase transition.

We can imagine a state dependent probabilistic cloner as a machine
with an input port, an output port and two flags that herald the success
or failure of cloning. The input $|\psi_{i}^{M}\rangle=|\psi_{i}\rangle^{\otimes M}$,
$i=1,2$ ($M$ identical copies of either $|\psi_{1}\rangle$ or $|\psi_{2}\rangle$)
is fed through the input port for processing. In case of success $N$
perfect clones~$|\psi_{i}^{N}\rangle=|\psi_{i}\rangle^{\otimes N}$
are delivered through the output port with conditioned probability
$p_{i}$. Otherwise, the output is in a refuse state. Conditioned
on the input state being $|\psi_{i}^{M}\rangle$, the failure probability
is~$q_{i}=1-p_{i}$.

For cloning, optimality is usually addressed from a Bayesian viewpoint
that assumes the states to be cloned are given with some prior probabilities
$\eta_{1}$ and $\eta_{2}$, $\eta_{1}+\eta_{2}=1$. Then a natural
cost function for our probabilistic machines is given by the average
failure probability 
\begin{equation}
Q=\eta_{1}q_{1}+\eta_{2}q_{2}.\label{obj fun}
\end{equation}
Accordingly, the optimal cloner minimizes the cost function %Accordingly, the optimal cloner is one that minimizes the cost function $Q$.
Our aim is to find the optimal cloner and the minimum average failure
probability $Q_{{\rm min}}$ for arbitrary priors $\eta_{1}$ and
$\eta_{2}$.

%The cloning process can be thought of as a generalized measurement and can be described by two operators~\mbox{$A_{\rm succ}$, $A_{\rm fail}$}, so that~$A^\dagger{}_{\kern-.3em\rm succ}A_{\rm succ}+A^\dagger{}_{\kern-.2em\rm fail}A_{\rm fail}=\openone$. %However, Neumark's theorem~\cite{Bergou} provides an alternative approach  that turns out to be more convenient for our analysis. 

In our formulation, similar to that in~\cite{Duan1998}, the Hilbert
space ${\mathscr{H}}^{\otimes M}$ of the original $M$ copies is
supplemented by an ancillary space~${\mathscr{H}}^{\otimes(N-M)}\otimes{\mathscr{H}}_{F}$
that accommodates both the additional $N-M$ clones as well as the
success/failure flags. Then, a unitary transformation~$U$ (time
evolution) from ${\mathscr{H}}^{\otimes M}\otimes{\mathscr{H}}^{\otimes(N-M)}\otimes{\mathscr{H}}_{F}$
onto ${\mathscr{H}}^{\otimes N}\otimes{\mathscr{H}}_{F}$ is defined
through~\cite{Duan1998} 
\begin{equation}
U|\psi_{i}^{M}\rangle|0\rangle=\sqrt{p_{i}}|\psi_{i}^{N}\rangle|\alpha_{i}\rangle+\sqrt{q}_{i}|\Phi\rangle,\quad i=1,2.\label{Ui}
\end{equation}
Here the ancillas are initialized in a reference state~$\ket 0$.
The states of the flag associated with successful cloning~$\ket{\alpha_{i}}$
are constrained to be orthogonal to the refuse state~$\ket{\Phi}$
for certainty in the outcomes of the projective measurement on the
flag space $\left\{ \mathscr{H}_{F}\right\} $. Although for optimal
cloning $|\alpha_{1}\rangle=|\alpha_{2}\rangle$, we need to consider
a more general setup where these two states are different to include
the cloning-by-discrimination protocol where UD is used to identify
the input state and then the clones are prepared accordingly~\footnote{Likewise, we could consider a more general setup with two refuse states
$|\Phi_{1}\rangle$ and $|\Phi_{2}\rangle$ in Eqs.~(\ref{Ui}).
This is necessarily sub-optimal since we could probabilistically determine
whether we received $\ket{\psi_{1}}$ or $\ket{\psi_{2}}$ by applying
UD to the refuse states $\ket{\Phi_{i}}$. Sometimes we would be certain
of the input state, when we can always prepare $n$ copies of the
state, thereby increasing the overall success rate of the cloning
strategy. }. For UD the success flag states must be distinguishable, so $\langle\alpha_{1}|\alpha_{2}\rangle=0$.
Taking the inner product of each equation with itself shows that our
probabilities are normalized: $p_{i}+q_{i}=1$. Similarly, by taking
the product of the two equations in~(\ref{Ui}), we find the unitarity
constraint 
\begin{equation}
s^{M}=\sqrt{p_{1}p_{2}}\,s^{N}\alpha+\sqrt{q_{1}q_{2}},\label{unit cond}
\end{equation}
where the overlaps $s=\braket{\psi_{1}}{\psi_{2}},\ 0\le s\le1$ and
$\alpha=\langle\alpha_{1}|\alpha_{2}\rangle$ can be chosen to be
real valued without any loss of generality. . We note that for optimal
cloning one has~$\alpha=1$, whereas~$\alpha=0$ for cloning by
discrimination. If Eq.~(\ref{unit cond}) is satisfied, it is not
hard to prove that~$U$ has a unitary extension on the whole space. 


Before attempting to minimize $Q$, we need to gain geometric insight
into the meaning of the unitary constraint. The following points turn
out to be important: (a)~For fixed $s$, $N$ and $M$ Eq.~(\ref{unit cond})
defines a class of smooth curves on the unit square $0\le q_{i}\le1$
(e.g., solid, dashed or dotted curves in Fig.~\ref{fig:1}). (b)~All
these curves meet at their endpoints, $(1,s^{2M})$ and $(s^{2M},1)$.
(c)~At the endpoints the curves become tangent to the vertical and
horizontal lines~$q_{1}=1$ and~$q_{2}=1$ respectively, provided~$\alpha\not=0$.
%This is due to the square root $\sqrt{p_1p_2}$ in Eq.~(\ref{unit cond}).%A more detailed analysis shows that f(d)~For~$\alpha=0$
the curve %defined by Eq.~(\ref{unit cond}) is an arc of the hyperbola
$q_{1}q_{2}=s^{2M}$ (dashed line in Fig.~\ref{fig:1}). (e)~Each
of these curves and the segments joining their end points with the
vertex~$(1,1)$ are the boundary of the sets (any of the gray regions
in Fig.~\ref{fig:1}) 
\begin{equation}
S_{\alpha}=\{(q_{1},q_{2}):\sqrt{p_{1}p_{2}}\,s^{N}\alpha+\sqrt{q_{1}q_{2}}-s^{M}\ge0\}.\label{S_alpha}
\end{equation}
They satisfy $S_{\alpha}\subset S_{\alpha'}$ if $\alpha<\alpha'$.
(f)~Moreover, the sets~$S_{\alpha}$ are convex if $\alpha\ge0$.
In particular $S_{1}$ is convex. %For $\alpha\ge0$ the set $S_\alpha$ is convex, as follows from the observation that~$(xy)^{1/2}$ is a concave function of its two (non-negative) arguments~$x$ and~$y$. 

At this point a geometrical picture of the optimization problem emerges
(See Fig.~\ref{fig:1}). Eq.~(\ref{obj fun}) defines a straight
segment on the square $0\le q_{i}\le1$ with a normal vector in the
first quadrant parallel to $(\eta_{1},\eta_{2})$. For fixed prior
probabilities, the average failure probability~$Q$ is proportional
to the distance from this segment to the origin~$(0,0)$. Since $S_{1}$
is convex and the stretch of its boundary given by Eq.~(\ref{unit cond})
with $\alpha=1$ is smooth, a unique point $(q_{1},q_{2})$ of tangency
with the segment~(\ref{obj fun}) exists for any value of the priors
and finite $N$. It gives $Q_{{\rm min}}$ and defines the optimal
cloning strategy. %(See Fig.~\ref{fig:1}). 

We note in passing that the inclusion hierarchy of the sets $S_{\alpha}$
provides a simple geometrical proof that $\alpha=1$, i.e., $|\alpha_{1}\rangle=|\alpha_{2}\rangle$,
is indeed the optimal choice. On the other hand, we recall that for
cloning by discrimination we have $\langle\alpha_{1}|\alpha_{2}\rangle=\alpha=0$.
From points~(b) and~(c) above, it follows that for any finite $N$
and arbitrary priors $\eta_{1}$ and $\eta_{2}$ this protocol is
strictly suboptimal, i.e., $Q_{{\rm min}}<Q_{{\rm UD}}$, where the
subscript UD is a reminder that the failure rate of cloning by discrimination
is that of UD. One could say that optimal cloning is incompatible
with discerning the identity of the input states for any finite number
of clones. However, optimal cloning and UD become one and the same
in the limit $N\to\infty$, where $s^{N}\to0$ and the curve~(\ref{unit cond})
collapses to the hyperbola $q_{1}q_{2}=s^{2M}$, as it does for $\alpha=0$.
We will come back to this point below. A more quantitative analysis
requires finding a convenient parametrization of the curve~(\ref{unit cond}).
To this end, simpler and more manageable expressions are derived if
the symmetry under $q_{1}\leftrightarrow q_{2}$ is preserved. We
write $\sqrt{q_{i}}=\sin\theta_{i}$ for $0\leq\theta_{i}\leq\pi/2$.
By further introducing the variables $x=\cos(\theta_{1}+\theta_{2})$
and $y=\cos(\theta_{1}-\theta_{2})$ we manage to linearize the constraint~(\ref{unit cond}),
which now reads as $2s^{M}=(1+s^{N})y-(1-s^{N})x$. A natural parametrization
for this straight line is given by 
\begin{equation}
x=\frac{1-(1+s^{N})t}{s^{N-M}},\qquad y=\frac{1-(1-s^{N})t}{s^{N-M}},\label{x =000026 y}
\end{equation}
where again we have taken the most symmetrical choice. Because of
the symmetry of this procedure, the parameters $x$ and $y$ are invariant
under $q_{1}\leftrightarrow q_{2}$ (equivalently, under $\theta_{1}\leftrightarrow\theta_{2}$).
Thus, the two mirror halves of the curve~(\ref{unit cond}) under
this transformation are mapped into the same straight line~(\ref{x =000026 y}).
By expressing $q_{i}$ as a function of~$t$ only half of the original
curve is recovered. The other half is trivially obtained by applying~$q_{1}\leftrightarrow q_{2}$.

The allowed domain of $t$ in Eq.~(\ref{x =000026 y}) follows from
that of~$x$ and~$y$, readily seen from their definition to be
the region $|x|\le y\le1$. Hence, we have 
\begin{equation}
\frac{1-s^{n-m}}{1-s^{n}}\le t\le1.\label{range t}
\end{equation}
After putting the various pieces together one can easily get rid of
the trigonometric functions and express Eq.~(\ref{unit cond}) in
parametric form as 
\begin{equation}
q_{i}=\frac{1-xy-(-1)^{i}\sqrt{1-x^{2}}\sqrt{1-y^{2}}}{2},\quad i=1,2.\label{par sqrt}
\end{equation}
Fig.~\ref{fig:2} shows examples of the unitary curve~(\ref{unit cond})
for (a)~$n=2$ and (b)~$n=5$. In both cases $m=1$. For larger
$n$ the curves closely approximate the hyperbolae $q_{1}q_{2}=s^{2m}$
(dashed lines) for small and moderate values of $s$, while for $s$
close to one the hyperbolas remain closer to the vertex~$(1,1)$,
but still retain the same end points. As mentioned previously, in
the limit $n\to\infty$ all curves become hyperbolic. 


Now we can return to the minimization of the average failure probability
$Q$. Despite the apparent simplicity of the problem, finding the
minimum $Q$ as an explicit function of $\eta_{1}$ or $\eta_{2}$
involves solving a quartic equation without a simple form~ Instead,
we will derive the parametric equation of the curve $(\eta_{1},Q_{{\rm min}})$.
This, along with our complete description of the unitary curve~,
provides a full account of the solution.

Without any loss of generality we may assume that~$\eta_{1}\le\eta_{2}$,
or equivalently, that~$0\le\eta_{1}\le1/2$. Then the slope of the
vector normal to the straight line~(\ref{obj fun}) is less or equal
to one and thus it can only become tangent to the lower half of the
unitary curve~(\ref{unit cond}) (see Fig.~\ref{fig:2}). The slope
of this lower half increases monotonically as we move away from the
line~$q_{1}=q_{2}$, where it has the value~$-1$, and vanishes
before we reach the line~$q_{1}=1$. This follows from the properties
(a)--(f) above and can be checked using Eq.~(\ref{par sqrt}). The
values of $t$ at which the slope is $-1$ and $0$ are respectively
\begin{equation}
t_{-1}=\frac{1-s^{n-m}}{1-s^{n}},\quad t_{0}=\frac{1-s^{2(n-m)}}{1-s^{2n}},\label{t's}
\end{equation}
where we note that $t_{-1}$ is the lower value of the range of~$t$
in Eq.~(\ref{range t}). For any point $(q_{1}(t),q_{2}(t))$ with
$t\in[t_{-1},t_{0}]$ there is a line $Q=\eta_{1}q_{1}+\eta_{2}q_{2}$
that is tangent to it, starting with $\eta_{1}=\eta_{2}=1/2$ for
$t=t_{-1}$ up to $\eta_{1}=0$, $\eta_{2}=1$ for $t=t_{0}$.

This observation enables us to derive the desired parametric expression
for the optimality curve~$(\eta_{1},Q_{{\rm min}})$ as follows:
for a given $t$ in the range above, a necessary condition for tangency
is %
\mbox{%
$\eta_{1}q'_{1}+\eta_{2}q'_{2}=0$%
}, where $q'_{i}=dq_{i}/dt$. In this equation we can solve for $\eta_{1}$
(or $\eta_{2}$) using that~$\eta_{1}+\eta_{2}=1$. By substituting
$q_{1}$ and~$q_{2}$ in Eq.~(\ref{obj fun}) with~(\ref{par sqrt})
we enforce contact with the unitarity curve and obtain the expression
of $Q_{{\rm min}}$. The final result can be cast as: 
\begin{equation}
\eta_{1}=\frac{q'_{2}}{q'_{2}-q'_{1}},\;\;Q_{{\rm min}}=\frac{q'_{2}q_{1}-q'_{1}q_{2}}{q'_{2}-q'_{1}},\;\;t_{-1}\le t\le t_{0},\label{main}
\end{equation}
where $t_{-1}$, $t_{0}$ and $q_{i}$ are given in Eqs.~(\ref{t's})
and~(\ref{par sqrt}). The expressions for the derivatives $q'_{i}$
are %most easily derived from the trigonometric form~(\ref{par trig}) to be
\begin{equation}
q'_{i}=\frac{\sqrt{q_{i}(1-q_{i})}}{s^{n-m}}\left\{ \frac{1+s^{n}}{\sqrt{1-x^{2}}}-(-1)^{i}\frac{1-s^{n}}{\sqrt{1-y^{2}}}\right\} .
\end{equation}
Fig.~\ref{fig:3} shows plots of the curves $(\eta_{1},Q_{{\rm min}})$
for $m=1$ input copies and (a) $n=2$ or (b) $n=5$ clones, as in
the previous figure. We see that $Q_{{\rm min}}$ is an increasing
function of $\eta_{1}$ in the given range $[0,1/2]$. The values
of~$Q_{{\rm min}}$ at the end points of this range follow by substituting
$t_{0}$ and $t_{-1}$, Eq.~(\ref{t's}), into Eq.~(\ref{par sqrt}).
They are given by 
\begin{equation}
Q_{0}=q_{2}(t_{0})=\frac{s^{2m}-s^{2n}}{1-s^{2n}},\quad Q_{-1}=\frac{s^{m}-s^{n}}{1-s^{n}},\label{Q's}
\end{equation}
where $Q_{{\rm min}}=Q_{-1}$ holds for equal priors and $Q_{{\rm min}}=Q_{0}$
for $\eta_{1}\to0$ (i.e., $\eta_{2}\to1$). 

The dashed lines in Fig.~\ref{fig:3}~(b) are the well known piecewise
unambiguous discrimination solution~\cite{Bergou2010}: 
\begin{equation}
Q_{{\rm UD}}=\left\{ \begin{array}{ll}
\eta_{1}+s^{2m}\eta_{2},\quad & {\displaystyle 0\le\eta_{1}\le\frac{s^{2m}}{1+s^{2m}};}\\[0.5em]
2\sqrt{\eta_{1}\eta_{2}}\,s^{m}, & {\displaystyle \frac{s^{2m}}{1+s^{2m}}\le\eta_{1}\le\frac{1}{2}.}
\end{array}\right.\label{UD-1}
\end{equation}
It is apparent from these plots that the optimal cloning protocol
performs strictly better than cloning by discrimination, as was proved
above. However, as the number of produced clones becomes larger the
difference in performance reduces. In Fig.~\ref{fig:3}~(b), for
only $n=5$, a difference is hardly noticeable for $s\le0.5$. For
larger overlaps it takes larger values of $n$ to get the same level
of agreement. As discussed above, in the limit $n\to\infty$ there
is perfect agreement for any $s<1$.

The complete UD solution in Eq.~(\ref{UD-1}) emerges naturally from
our geometrical approach in a straightforward manner: First, we recall
that in this case the right hand side of Eq.~(\ref{unit cond}) becomes
$q_{1}q_{2}=s^{2m}$ (dashed lines in Figs.~\ref{fig:1} and~\ref{fig:2}).
The maximum slopes of these curves are at their end points and all
have the value~$-s^{2m}$. This implies that the boundary of $S_{0}$
has a cusp at $(1,s^{2m})$. It follows that a unique point of tangency
with the line~(\ref{obj fun}) exists for $s^{2m}<\eta_{1}/\eta_{2}\le1$
(recall that we are assuming~$\eta_{1}\le1/2$). This condition gives
the $\eta_{1}$ interval for that solution. The tangency condition,
$(q_{2},q_{1})\propto(\eta_{1},\eta_{2})$, quickly leads us to the
optimal failure rate in the second line of Eq.~(\ref{UD-1}). For
$s^{2m}>\eta_{1}/\eta_{2}\ge0$ tangency is not possible, and the
optimal line~(\ref{obj fun}) merely touches the cusp on the boundary
of~$S_{0}$, so the expression of $Q$ becomes the first line of
Eq.~(\ref{UD-1}). In geometrical terms, the straight line~(\ref{obj fun})
pivots on the end point as $\eta_{1}$ varies between $0$ and $s^{2m}/(1+s^{2m})$.

For the second case in Eq.~(\ref{UD-1}), one has $q_{1},p_{1}\in(0,1)$
and there are three orthogonal flag states in Eqs.~(\ref{Ui}), namely,
the two success states $|\alpha_{1}\rangle$, $|\alpha_{2}\rangle$,
and the failure state~$|\Phi\rangle$. This $3$-outcome measurement
can be represented by a $3$-element positive operator valued measure
(POVM) on ${\mathscr{H}}^{\otimes m}$. For the first line in Eq.~(\ref{UD-1}),
$p_{1}=1-q_{1}=0$, which leads to a $2$-outcome projective measurement,
as only one success flag state ($|\alpha_{2}\rangle$) is needed in
Eqs.~(\ref{Ui}).

This two-paragraph derivation of Eq.~(\ref{UD-1}) proves that the
convergence of the optimal cloning failure probability~$Q_{{\rm min}}$
to that of cloning by discrimination, with rate $Q_{{\rm UD}}$ in
Eq.~(\ref{UD-1}), follows from the convergence of the general unitarity
curve in Eq.~(\ref{unit cond}) to the hyperbola $q_{1}q_{2}=s^{2m}$,
i.e., from $\lim_{\alpha\to0}S_{\alpha}=S_{0}$. Interestingly enough,
such convergence entails a phenomenon analogous to a second order
phase transition. Our geometrical approach shows that the average
failure probability $Q_{{\rm min}}(\eta_{1})$ is an infinitely differentiable
function of~$\eta_{1}$ for finite $n$. However, as $n$ goes to
infinity (or at $\alpha=0$, for the sake of this discussion) the
limiting function $Q_{{\rm UD}}(\eta_{1})$ has a discontinuous second
derivative. Moreover, the symmetry $q_{1}\leftrightarrow q_{2}$ breaks
in the phase corresponding to the first line in Eq.~(\ref{UD-1}).
A~similar phenomenon arises in UD of more than two pure states~\cite{Bergou2012}
.

It has been argued above that cloning by discrimination is strictly
suboptimal (unless $n\to\infty$). One could likewise wonder if discrimination
by cloning can be optimal. On heuristic grounds, one should not expect
this to be so, as cloning involves a measurement and some information
can be drawn from the observed outcome. However, the equal-prior and
the $\eta_{1}\to0$ cases provide remarkable exceptions. For both
we may write the total failure rate as $Q_{{\rm C}}+(1-Q_{{\rm C}})Q_{{\rm UD}}$,
where C stands for cloning. For $\eta_{1}=\eta_{2}=1/2$, Eq.~(\ref{Q's})
implies $Q_{{\rm C}}=Q_{-1}$, in which case the produced $n$-clone
states are equally likely. The UD of these states fails with probability
$s^{n}$, as follows from Eq.~(\ref{UD-1}) applied to $n$ copies.
The total failure rate is then $s^{m}$, which is the optimal UD failure
rate of the original input states, Eq.~(\ref{UD-1}). If $\eta_{1}\to0$
then only $|\psi_{2}^{n}\rangle$ is produced with non-vanishing probability
and $Q_{{\rm C}}=Q_{0}$. Failure in the second step (UD) is given
by the top line in Eq.~(\ref{UD-1}) applied to $n$ copies. The
total failure rate is $s^{2m}$, also achieving optimality.

Using our main result in Eqs.~(\ref{main}), and~(\ref{par sqrt})
one can check that these are the only cases where discrimination by
cloning is optimal. These are also the only cases where no information
gain can be drawn from the cloning measurement. This hints at how
special these cases are and justifies the need of the derived solution
for arbitrary priors to have a full account of two-state cloning.


\subsection{Unequal priors II}

In this section we show a different geometric/numeric solution using
the Lagrange multipliers method with the constraint given in Equation
(\ref{eq:clone overlap}), 

\begin{equation}
s=\sqrt{(1-q_{1})(1-q_{2})}s^{2}+\sqrt{q_{1}q_{2}},\label{eq:1 to 2 cloning constraint}
\end{equation}
where we set $M=1,$ $N=2$ for notation simplicity. This corresponds
to one to two cloning but can be easily generalized for $M$ to $N$
cloning, $M\geq N$ . The function to be maximized is:

\begin{equation}
F_{S}=\eta_{1}q_{1}+\eta_{2}q_{2}+\lambda\left[s-\sqrt{\left(1-q_{1}\right)\left(1-q_{2}\right)}s^{2}-\sqrt{q_{1}q_{2}}\right],
\end{equation}
where $\lambda$ is the Lagrange multiplier to be determined which
optimizes the failure rate $Q=\eta_{1}q_{1}+\eta_{2}q_{2}.$ Set $\partial F/\partial q_{i}=0$,
solve for $q_{i}$,

\begin{eqnarray}
\frac{2\eta_{1}}{\lambda} & = & \sqrt{\frac{q_{2}}{q_{1}}}-\sqrt{\frac{1-q_{2}}{1-q_{1}}}s^{2},\label{eq:lagr1}\\
\frac{2\eta_{2}}{\lambda} & = & \sqrt{\frac{q_{1}}{q_{2}}}-\sqrt{\frac{1-q_{1}}{1-q_{2}}}s^{2}.\label{eq:lagr2}
\end{eqnarray}


Let $A\equiv\sqrt{\frac{q_{2}(1-q_{1})}{q_{1}(1-q_{2})}},$ 

\begin{eqnarray}
\sqrt{\frac{q_{1}}{q_{2}}} & = & \frac{\lambda}{2\eta_{1}}\left[1-\frac{s^{2}}{A}\right],\\
\sqrt{\frac{q_{2}}{q_{1}}} & = & \frac{\lambda}{2\eta_{2}}\left[1-As^{2}\right],
\end{eqnarray}
Multiplying the above two equations, setting $\delta=\frac{4\eta\eta_{2}}{\lambda^{2}}$
and $C=\frac{s^{4}-\delta+1}{s^{2}}$ results in a quadratic equation:

\begin{eqnarray}
\delta-1 & = & s^{2}\left[s^{2}-A-\frac{1}{A}\right],\nonumber \\
0 & = & A^{2}-CA+1.\label{eq:QuadratinA1}
\end{eqnarray}
It is the quadratic equation in (\ref{eq:QuadratinA1}) with the combination
of a second emerging quadratic equation we will use to obtain the
value of $\lambda.$ 

Another quadratic equation emerges using the two equations in (\ref{eq:lagr1})
and (\ref{eq:lagr2}). First let $\alpha\equiv\frac{\lambda}{2\eta_{1}}[1-\frac{s^{2}}{A}]$
and $\frac{1}{\alpha}=\frac{\lambda}{2\eta_{2}}[1-As^{2}]$ the relationship
between the two failure rates becomes:

\begin{equation}
\sqrt{q_{1}}=\alpha\sqrt{q_{2}}.\label{eq:q12}
\end{equation}
Using the relationship in (\ref{eq:q12}) and the definition of $A$,
$q_{i}$ can be expressed explicitly in terms of the fixed constants:
$\{\eta_{1},\eta_{2},s\}$ and the parameter $\lambda$ which is yet
to be determined. The derivation starts from the definition of $A,$

\begin{eqnarray*}
A^{2} & = & \frac{q_{2}\left(1-q_{1}\right)}{q_{1}\left(1-q_{2}\right)},\\
\frac{q_{1}}{1-q_{1}}A^{2} & = & \frac{q_{2}}{1-q_{2}},\\
\frac{\alpha^{2}q_{2}}{1-\alpha^{2}q_{2}}A^{2} & = & \frac{q_{2}}{1-q_{2}}.
\end{eqnarray*}
 Solving for $q_{2}$ then using the relationship $q_{1}=\alpha^{2}q_{2}$
we get:

\begin{eqnarray}
q_{2} & = & \frac{1-\alpha^{2}A^{2}}{\alpha^{2}\left(1-A^{2}\right)},\\
q_{1} & = & \frac{1-\alpha^{2}A^{2}}{\left(1-A^{2}\right)}.
\end{eqnarray}
This is the expression of the individual failure rates which are yet
to be optimized subject to the constraint. Now $q_{1}$ and $q_{2}$
is replaced in the constraint given in (\ref{eq:1 to 2 cloning constraint})
and from there the optimal value of $\lambda$ can be obtained. 

Some prior calculations before replacing $q_{i}$ into the constraint
will simplify the overall algebra:

\[
1-q_{1}=\frac{A^{2}\left(\alpha^{2}-1\right)}{\left(1-A^{2}\right)},
\]


\[
1-q_{2}=\frac{\alpha^{2}-1}{\alpha^{2}\left(1-A^{2}\right)}.
\]


Now we are ready to replace $q_{i}$ and $1-q_{i}$ into the constraint
(\ref{eq:1 to 2 cloning constraint}):

\begin{eqnarray*}
s & = & \frac{A\left(\alpha^{2}-1\right)}{\alpha\left(1-A^{2}\right)}s^{2}+\frac{1-\alpha^{2}A^{2}}{\alpha\left(1-A^{2}\right)},\\
\left(1-A^{2}\right)s & = & \frac{1}{\alpha}\left(1-s^{2}A^{2}\right)-\alpha A^{2}\left(1-\frac{s^{2}}{A}\right),\\
\left(1-A^{2}\right)s & = & \frac{\lambda}{2\eta_{2}}\left(1-s^{2}A^{2}\right)^{2}-\frac{\lambda A^{2}}{2\eta_{1}}\left(1-\frac{s^{2}}{A}\right)^{2}.
\end{eqnarray*}
Here we replaced $\text{ \ensuremath{\alpha}=\ensuremath{\frac{\lambda}{2\eta_{1}}\left[1-\frac{s^{2}}{A}\right]} and \ensuremath{\frac{1}{\alpha}}=\ensuremath{\frac{\lambda}{2\eta_{2}}\left[1-As^{2}\right]}}.$
After some trivial algebra the second quadratic equation in $A$ emerges:

\begin{equation}
A^{2}-\frac{2s^{2}(\eta_{1}-\eta_{2})}{\eta_{1}s^{4}-\eta_{2}+2\eta_{1}\eta_{2}s/\lambda}A+\frac{\eta_{1}-\eta_{2}s^{4}+2\eta_{1}\eta_{2}s/\lambda}{\eta_{1}s^{4}-\eta_{2}+2\eta_{1}\eta_{2}s/\lambda}=0\label{eq: 2nd quadratic in A}
\end{equation}


The combination of Eq. (\ref{eq:QuadratinA1}) and Eq. (\ref{eq: 2nd quadratic in A})
should give the value of $\lambda$ which in turn gives explicit solution
to the minimum individual failure rates, $q_{i},$ and overall optimal
failure rate $Q=\eta_{1}q_{1}+\eta_{2}q_{2}.$ Analytically such a
solution is hard to achieve as one would have to solve a sixth order
equation. Simply by plotting the two quadratic equations as a function
of $\lambda$ the solution can be obtained at the intersection of
the two graphs. There will be multiple intersections, hence multiple
values of $\lambda.$ The one which gives the lowest value of the
overall failure rate is chosen. 

In our future work we would like to obtain a closed form solution
of $q_{i}.$ One approach could be by making some educated guess for
$\lambda.$




\section{Exact Cloning then Unambiguous Discrimination. }

It is interesting to see the connection between cloning and state
discrimination of non-orthogonal quantum states. To get a better understanding
we consider the two step process where we first clone then make a
measurement. The other way around, state discrimination first then
cloning is less interesting because once we have succeeded in discriminating
a state we can make as many copies as we wish by simply preparing
them with the knowledge we get from the discrimination step. Making
a clone first and then performing state discrimination gives some
interesting results. For the case when the incoming states are prepared
with equal priors we show that cloning first then performing UD on
the cloned states which come with some new a priori probability $p'$
the overall failure rate reaches the IDP limit. 

\medskip{}


The idea of the two step process is the following: 
\begin{enumerate}
\item Probabilistic Exact Cloning: Given an ensemble of $M$ quantum states
$\{|\psi_{1}\rangle,|\psi_{2}\rangle\}$ produce $N$ exact clones
while allowing for a rate of inconclusive outcomes. 
\item Unambiguous Discrimination: Perform optimal unambiguous discrimination
on the successfully cloned states only, throwing away the failed states. 
\end{enumerate}

\subsection*{Equal priors}
\begin{enumerate}
\item Probabilistic Exact Cloning
\end{enumerate}
We showed in Section (3.2.1) that for equal priors and a set of $M$
copies of two non-orthogonal states we could successfully produce
exact copies with a probability $P_{clone}=\frac{1-s^{M}}{1-s^{N}}.$
The average failure rate, failing to clone a state is $Q_{clone}=1-P_{clone}=\frac{s^{M}-s^{N}}{1-s^{N}}.$ 
\begin{enumerate}
\item Optimal Unambiguous Discrimination
\end{enumerate}
After the input states are sent through the deterministic exact cloning
machines, $N$ states of of the ensemble $\{|\psi_{1}\rangle,\thinspace|\psi_{2}\rangle\}$
come out through the output port. The cloning machine only makes copies
and does not say which state it has made a copy of. The clones are
now sent through an unambiguous discriminating machine to distinguish
the incoming states. Each of the states comes with a probability $P_{clone}=\frac{1-s^{M}}{1-s^{N}}.$ 

The incoming states $\{|\psi_{1}^{N}\rangle_{s},|\psi_{2}^{N}\rangle_{s}\}$
which live in the state Hilbert space $S$ are embedded with the ancilla
$|i\rangle_{a}$ which live in the ancilla Hilbert space $A.$ Now
the system and the ancilla live in the larger Hilbert space $H=S\varotimes A.$
The incoming states in this larger Hilbert space can be written in
the product form $\{|\psi_{1}^{N}\rangle_{s}|i\rangle_{a},|\psi_{2}^{N}\rangle_{s}|i\rangle_{a}\}$ 

\begin{eqnarray}
U|\psi_{1}\rangle^{\oplus N}\ket 0 & = & \sqrt{p}|\phi\rangle_{s}|1\rangle_{a}+\sqrt{q}|\Phi\rangle_{s}|0\rangle_{a}\nonumber \\
U|\psi_{1}\rangle^{\oplus N}\ket 0 & = & \sqrt{p}|\phi^{\perp}\rangle_{s}|2\rangle_{a}+\sqrt{q}|\Phi\rangle_{s}|0\rangle_{a}\label{eq:sep}\\
\nonumber 
\end{eqnarray}
Here $p$ is the probability of successfully discriminating the state
$|\psi_{i}^{N}\rangle_{s}$, $q$ is the probability of failing to
discriminate $|\psi_{i}^{N}\rangle_{s},$ $p+q=1.$ The unitary operator
takes the two incoming states and projects them onto a pair of orthogonal
states with some success and some failure probability. When there
is a click on the ancilla $|1\rangle_{a}$ the input states have been
separated and output states $|\psi'_{i}\rangle_{s}$ are orthogonal
and thus fully distinguishable. If there is a click along the ancilla
$|0\rangle_{a}$ the incoming states have been collapsed into a single
state which carries no information.

The inner product of the two equations in (\ref{eq:sep}) produces
the solution $s^{N}=q.$ In addition one has to take into consideration
the fact that the states come in with a priori probability of $\frac{1}{2}p=\frac{1}{2}\frac{1-s^{M}}{1-s^{N}}$.
The optimal inconclusive rate for discriminating the incoming pair
of states is$Q=\tilde{\eta}_{1}q_{1}+\tilde{\eta}_{2}q_{2}=\eta_{1}p_{1}q_{1}+\eta_{2}p_{2}q_{2}=\frac{1-s^{M}}{1-s^{N}}s^{N}$
, where $q_{1}=q_{2}=s^{N}$ and success rate is $p_{1}=p_{2}=\frac{s^{M}-s^{N}}{1-s^{N}}.$ 

The total inconclusive rate for the two step process, the failure
rate to clone plus failure rate to unambiguously discriminate, is 

\begin{eqnarray}
Q_{total} & = & Q_{clone}+\left(1-Q_{clone}\right)Q_{UD},\nonumber \\
 & = & \frac{s^{M}-s^{N}}{1-s^{N}}+\frac{1-s^{M}}{1-s^{N}}s^{N}=s^{M}.\label{eq:overlap}
\end{eqnarray}


The two step process reaches the IDP limit for optimal UD of $M$
non-orthogonal states. This is a special case and only occurs for
symmetric case when states are prepared with equal prior probabilities. 


\section{State Separation}

In Exact Cloning one prepares perfect clones of the input states while
allowing for some failure rate in which case no clones have been produced
and the states are discarded. In optimal unambiguous discrimination
(UD) the input states are made orthogonal and hence fully distinguishable.
It was shown by Chefles and Barnett \cite{Chefles1998a} that these
strategies are a special case of a more general scheme. Both have
two outcomes: failure and success. In each strategy the overlap of
the input states is decreased, in UD the overlap becomes zero, in
exact cloning it is the overlap of the input states raised to the
power of the desired number of the clones to be made, $s^{N}$. State
separation unifies the two schemes as it produces states with an overlap
$s'$ in the range $0\leq s'\leq s^{N}$ while allowing for a fixed
rate of inconclusive results. The authors showed the results for the
case when the states are prepared with equal a priori probabilities.
Complimentary of our recent work on probabilistic exact cloning \cite{yerokhin}
where a geometric picture emerges we use similar tools to solve the
more general state separation when the input states are prepared with
different a priori probabilities.

We approach state separation via the Neumark formulation. The system
is embedded in a larger Hilbert space where the extra degrees of freedom
are customarily called the ancilla. Then a unitary transformation
entangles the system degrees of freedom with those of the ancilla.
The input states $\{|\psi_{1}\rangle_{s},|\psi_{2}\rangle_{s}\}$
which live in the state Hilbert space $H_{S}$ are embedded with the
ancilla $|i\rangle_{a}$ which live in the Hilbert space $H_{A}.$
Now the system and the ancilla live in the larger Hilbert space $H=H_{S}\varotimes H_{A}.$
The incoming states in this larger Hilbert space can be written in
the product form $\{|\psi_{1}\rangle_{s}|i\rangle_{a},\thinspace|\psi_{2}\rangle_{s}|i\rangle_{a}\}.$
The unitary should do the following: 

\begin{eqnarray}
U|\psi_{1}\rangle|i\rangle & = & \sqrt{p_{1}}|\phi_{1}\rangle|\alpha\rangle+\sqrt{q_{1}}|\Phi_{o}\rangle|f\rangle,\nonumber \\
U|\psi_{2}\rangle|i\rangle & = & \sqrt{p_{2}}|\phi_{2}\rangle|\alpha\rangle+\sqrt{q_{2}}|\Phi_{o}\rangle|f\rangle,\label{eq:separation}
\end{eqnarray}
where $\ket{\alpha}$ and $\ket f$ are orthogonal. A projective measurement
along the ancilla $\ket{\alpha}$ means that the states have successfully
become more distinguishable with a success rate of $p_{i}$, otherwise
a measurement along the $\ket f$ space means that the process has
failed to produce more distinguishable states and the states are discarded
with a probability of $q_{i}.$ The separation of the input states
is shown in Figure. \ref{fig:state_separation}. 

The inner product of the two equations in \ref{eq:separation} gives
the unitarity constraint:

\begin{equation}
s=\sqrt{p_{1}p_{2}}s'+\sqrt{q_{1}q_{2}},\label{eq:separation constraint}
\end{equation}
where $s=|\braket{\psi_{1}}{\psi_{2}}|^{M}$ and $s'=|\braket{\phi_{1}}{\phi_{2}}|^{N}.$

For given $\eta_{1}$, $\eta_{2}$ and average failure probability
$Q$, we wish to find out the minimum value of the final overlap $s'$
as a function of the initial overlap$s$. We could also look at the
problem from a different angle: for a fixed value of the overlap of
the output states what is the minimum value of failure rate $Q$ to
achieve the desired separation. 

\begin{figure}
\begin{centering}
\includegraphics[width=8.5cm,height=8.5cm]{state_separation}
\par\end{centering}

\protect\caption[\hspace{1cm}State separation]{The input states $\left\{ \protect\ket{\psi_{1}},\protect\ket{\psi_{2}}\right\} $
are separated into a pair of more orthogonal states $\left\{ \protect\ket{\phi_{1}},\protect\ket{\phi_{2}}\right\} $
which are more distinguishable.  }


\label{fig:state_separation} 
\end{figure}



\subsection{State Separation: equal priors}

Chefles and Barnett \cite{Chefles1998a} solve the problem of equal
priors employing Kraus representation of quantum maps $\left\{ \hat{A},\hat{A}^{\dagger}\right\} .$
However the solution is more straightforward using the Neumark setup
in (\ref{eq:separation}). When the input states are prepared with
equal priors $\eta_{1}=\eta_{2},$ the solution is directly derived
from the constraint in (\ref{eq:separation constraint}) and no further
optimization is necessary:

\begin{eqnarray}
s & = & ps'+q,\nonumber \\
p & = & \frac{1-s}{1-s'}.\label{eq:separation-1}
\end{eqnarray}


We will now show applications of state separation to exact cloning
and unambiguous state discrimination. Another application to state
separation for equal priors is in hybrid cloning, see Section (3.6.1).
Let us begin by showing the connection to exact cloning with failure
rate. Suppose we are given a quantum system in either of the pure
states $\left\{ \ket{\psi_{1}},\ket{\psi_{2}}\right\} $, such that
the two states are non-orthogonal. The task is to produce two perfect
copies of the input state. Let us embed the quantum system with a
blank state $\ket i$ so the system becomes $\left\{ \ket{\psi_{1}}\ket i,\ket{\psi_{2}}\ket i\right\} $.
A perfect copying machine should produce $\left\{ \ket{\psi_{1}}\ket{\psi_{1}},\ket{\psi_{2}}\ket{\psi_{2}}\right\} $.
A modified Neumark setup from state separation in (\ref{eq:separation})
for cloning is:

\begin{eqnarray}
U|\psi_{1}\rangle|i\rangle & = & \sqrt{p}\ket{\psi_{1}}\ket{\psi_{1}}\ket{\alpha}+\sqrt{q}|\Phi_{o}\rangle|f\rangle,\nonumber \\
U|\psi_{2}\rangle|i\rangle & = & \sqrt{p}\ket{\psi_{1}}\ket{\psi_{1}}\ket{\alpha}+\sqrt{q}|\Phi_{o}\rangle|f\rangle,\label{eq:cloning}
\end{eqnarray}


The inner product gives the unitarity constraint which is enough to
fully solve the problem:

\begin{eqnarray}
s & = & ps^{2}+q\nonumber \\
p & = & \frac{1-s}{1-s^{2}}=\frac{1}{1+s}\label{eq:cloning-1}
\end{eqnarray}


We notice that the success probability of producing two perfect clones
with a rate of abstention (\ref{eq:cloning-1}) could be derived from
state separation success rate in Eq. (\ref{eq:separation-1}) by replacing
the overlap of output states $s'$ with the square overlap of input
states $s^{2}$. This shows that the Duan-Guo limit \cite{Duan1998}
is a special case of state separation. 

More generally, state separation can be modified to produce $N$ copies
of $\left\{ \ket{\psi_{1}},\ket{\psi_{2}}\right\} $ from $M$ initial
copies, where $N\geq M$. We derived the solution of $M$ to $N$
cloning in section (3.2.1). It could simply be derived from Eq. (\ref{eq:separation-1})
replacing the overlap of input states $s$ with $s^{M}$, the overlap
of $M$ states, and $s'$ by $s^{N},$ the overlap of the clones. 

State separation also reproduces the IDP limit in state discrimination
for the case when the states are prepared with arbitrary priors. Simply
setting the overlap of the output states to zero $s'=0$, so that
the states have been separated and are fully distinguishable, produces
the IDP limit $p=1-s$. 


\subsection{State Separation: unequal priors }

We now seek to generalize the results of state separation to the case
when the possible input states $\left\{ \ket{\psi_{1}},\ket{\psi_{2}}\right\} $
are prepared with different a priori probabilities. All the symmetries
enjoyed for equal priors break down and in order to obtain a fully
analytical solution one would have to solve a sixth order equation.
Instead we resort to solving the problem geometrically as the solution
turns out to be more insightful. The Neumark setup is shown in (\ref{eq:separation})
and the constraint in (\ref{eq:separation constraint}). 

We resort to the parametrization of the probabilities giving the curve
$(s,\min s')$ in parametric form, rather than attempting to give
min $s'$ as an explicit function of $s$, which would require solving
a high degree polynomial equation. We choose a change of variables
which linearizes the unitarity constraint (\ref{eq:separation constraint}):
\begin{equation}
p_{1}p_{1}=t^{2},\quad q_{1}q_{2}=z^{2}.\label{eb cha qs -> z =000026 t}
\end{equation}
 The condition becomes 
\begin{equation}
z=s-s't,\qquad0\le t,z\le1,\qquad0\le s'\le s.
\end{equation}
It is a straight line in the first quadrant of the plane $t$-$z$
with negative slope~$-s'$ and crossing the $z$-axis at $z=s$.
From the first equation in ~(\ref{eb cha qs -> z =000026 t}) we
have 
\[
t^{2}=(1-q_{1})(1-q_{2})=1+z^{2}-q_{1}-q_{2}.
\]
Solving for $q_{2}$ and substituting back in the second equation
in ~(\ref{eb cha qs -> z =000026 t}) we have 
\[
q_{1}(q_{1}-1+t^{2}-z^{2})+z^{2}=0.
\]
We now solve for $q_{1}$ and obtain 
\[
q_{1}=\frac{1+z^{2}-t^{2}\pm\sqrt{(1+z^{2}-t^{2})^{2}-4z^{2}}}{2}.
\]
Similarly, for $q_{2}$ we obtain 
\[
q_{2}=\frac{1+z^{2}-t^{2}\mp\sqrt{(1+z^{2}-t^{2})^{2}-4z^{2}}}{2}.
\]
Therefore, the condition $Q=\eta_{1}q_{1}+\eta_{2}q_{2}$ becomes
\[
2Q=1+z^{2}-t^{2}\pm(\eta_{1}-\eta_{2})\sqrt{(1+z^{2}-t^{2})^{2}-4z^{2}}.
\]
We now solve for $z^{2}$. After a bit of algebra we obtain
\begin{eqnarray*}
z^{2} & = & \frac{2\eta_{1}\eta_{2}(1+\tau)-1+Q+\sqrt{\left(1-4\eta_{1}\eta_{2}\right)\left[(1-Q)^{2}-4\eta_{1}\eta_{2}\tau\right]}}{2\eta_{1}\eta_{2}}\\
 & \equiv & \zeta(\tau)
\end{eqnarray*}
where $\tau\equiv t^{2}$. Since $z^{2}$ cannot be less than zero,
we picked up the plus sign for the root. Let us assume that $0\le\eta_{1}\le1/2$
to simplify the analysis. We need to locate the maximum of $z$. For
that, 
\[
\frac{dz}{dt}=\frac{d\sqrt{\zeta}}{d\tau}2t=\frac{d\zeta}{d\tau}\frac{t}{z}.
\]
The derivative $d\zeta/d\tau$ is immediate. We find that the maximum
is located at 
\[
t_{{\rm min}}=\left\{ \begin{array}{lll}
{\displaystyle \sqrt{\left(1-\frac{Q}{2\eta_{1}}\right)\left(1-\frac{Q}{2\eta_{2}}\right)},\quad} & {\rm if} & \quad0\le Q\le2\eta_{1}\\[2em]
0,\quad & {\rm if} & \quad2\eta_{1}<Q\le1.
\end{array}\right.
\]
The corresponding values of $z$ are 
\[
z_{{\rm min}}=\left\{ \begin{array}{lll}
{\displaystyle \frac{Q}{2\sqrt{\eta_{1}\eta_{2}}},\quad} & {\rm if} & \quad0\le Q\le2\eta_{1}\\[2em]
{\displaystyle \sqrt{\frac{Q-\eta_{1}}{\eta_{2}}},\quad} & {\rm if} & \quad2\eta_{1}<Q\le1.
\end{array}\right.
\]
There is a second point that we need to define. We first note that
for equal priors the curve is simply the hyperbola 
\[
z^{2}=t^{2}+2Q-1,
\]
which intersects the straight line 
\[
z=1-t
\]
at the point 
\[
\left(z,t\right)=\left(Q,1-Q\right).
\]
By trying this solution in $z^{2}=\zeta(t^{2})$ we note that it is
actually a general solution for any $\eta_{1}$, $\eta_{2}$. Moreover,
the straight line $z=1-t$ is tangent to~$z^{2}=\zeta(t^{2})$ at
$(Q,1-Q)$ for any values of $\eta_{1}$, $\eta_{2}$, as can be checked
by substituting in the formula $dz/dt=(t/z)(d\zeta/d\tau)$. Note
also that $z=1-t$ is the limiting line for the family $z=s-s't$.
Hence, an obvious parametrization for the curve $(s,s')$ is obtained
as follows: {\em i}.~define 
\[
s'(t)=-\frac{dz}{dt}=-\frac{t\,\zeta'(t^{2})}{\sqrt{\zeta(t^{2})}},\qquad t_{{\rm min}}\le t\le1-Q,
\]
and next {\em ii}.~define 
\[
s(t)=z+ts'(t)=\sqrt{\zeta(t^{2})}+ts'(t),\qquad t_{{\rm min}}\le t\le1-Q,
\]
where 
\[
\zeta'(\tau)=1-\frac{\sqrt{1-4\eta_{1}\eta_{2}}}{\sqrt{(1-Q)^{2}-4\eta_{1}\eta_{2}\tau}}.
\]


For $s<z_{{\rm min}}$ it is always possible to separate the initial
states, i.e., $|\psi_{1}\rangle$ and~$|\psi_{2}\rangle$ can be
made orthogonal. We note that the condition $s=z_{{\rm min}}$ is
equivalent to the unambiguous discrimination result 
\[
Q=2\sqrt{\eta_{1}\eta_{2}}s,\quad Q=\eta_{1}+\eta_{2}s^{2}.
\]


\begin{figure}
\includegraphics[width=8.5cm,height=8.5cm]{Separation1\lyxdot graph}

\protect\caption[\hspace{1cm}$s'$ vs. $s$]{The plot is for $\eta_{1}=0.1$. As $\eta_{1}$ approaches $1/2$
the curves approach a straight line. The difference is more noticeable
for very small values of $\eta_{1}$.}


\label{s' vs s}
\end{figure}



\section{Deterministic State Dependent Quantum Cloning}

In this section we derive the works of Chefles and Barnett \cite{Chefles1999}
in designing an approximate quantum cloning machine for two possible
input states while maximizing the global fidelity. Consider a set
of $K$ non-orthogonal quantum states with $M$ copies each $|\psi_{i}\rangle^{\otimes M}=|\psi_{i}\rangle|\psi_{i}\rangle...|\psi_{i}\rangle.$
The states are unknown and our task is to produce $N>M$ copies, as
best as we can. Introducing an ancilla state $|\chi\rangle$ which
is $N-M$ dimensional the goal is to transform the state $|\psi_{j}\rangle|\chi\rangle$
into the state which approximates the N exact copies of the input
state $|\psi_{j}^{N}\rangle.$

This is deterministic cloning, although imperfect, clones are generated
on demand. The authors choose the global fidelity rate to improve
the quality of the clones so they resemble the given copies as closely
as possible. This measure was introduced by Bruss et al \cite{Bruss1998}.
Thus given a set $K$ of non orthogonal states $\ket{\phi_{j}^{N}}=|\psi_{i}\rangle^{\otimes M},$
we wish to produce a set $K$ of $N$ clones $|\phi_{j}\rangle^{\otimes N}$
while optimizing the global fidelity:

\begin{equation}
F_{MN}=\sum_{j=1}^{K}\eta_{j}|\langle\psi_{j}^{N}|\phi_{j}^{N}\rangle|^{2}
\end{equation}


Other figures of merit can also be used to improve the quality of
the clones, such as local fidelity. The local fidelity is the average
fidelity of each of the individual clones of each of the N subsystems
measured against the input states $|\psi_{j}\rangle.$ The authors
choose the global fidelity due to its close connection to state discrimination.
We are also very interested in the connection between cloning and
state discrimination, particularly in the two step process where clones
are first produced then the clones are unambiguously discriminated. 

The global fidelity can be expressed differently if unitary operator
acts on the input states $U|\psi_{j}^{M}\rangle|\chi\rangle=|\phi_{j}^{N}\rangle.$ 

\begin{equation}
F_{MN}=\sum_{j=1}^{K}\eta_{j}|\langle\psi_{j}^{N}|U|\psi_{j}^{M}\rangle|\chi\rangle|^{2}
\end{equation}


The problem of maximizing the fidelity can be explicitly solved for
a set of two possible input states $K=2$, $\{|\psi_{1}\rangle,|\psi_{2}\rangle\}.$
It was originally solved by Bruss $et$ $al$ \cite{Bruss1998} for
the case when the the incoming states are prepared with equal a priori
probabilities. They noticed that the optimum clones $\{|\Phi_{1}\rangle,|\Phi_{2}\rangle\}$
lie in the subspace spanned by the input states to be cloned $\{|\psi_{1}\rangle,|\psi_{2}\rangle\}.$ 

A unitary produces $N$ copies $|\phi_{1}^{N}\rangle$ or $|\phi_{2}^{N}\rangle,$
to resemble the original states as best as possible. 

\begin{eqnarray}
U|\psi_{1}^{M}\rangle|i\rangle & = & |\phi_{1}^{N}\rangle\\
U|\psi_{2}^{M}\rangle|i\rangle & = & |\phi_{2}^{N}\rangle
\end{eqnarray}


The inner product of the above two equations gives a relationship
between the input and the output states

\begin{eqnarray}
|\langle\psi_{1}|\psi_{2}\rangle|^{M} & = & |\langle\phi_{1}|\phi_{2}\rangle|^{N},\\
s^{M} & = & s'^{N},\label{eq:3.4.6}
\end{eqnarray}


where $s^{M=}|\langle\psi_{1}|\psi_{2}\rangle|^{M}$ and $s'^{N}=|\langle\phi_{1}|\phi_{2}\rangle|$.

The input states can be expressed as:

\begin{eqnarray}
|\psi_{1}\rangle & = & \cos\theta|1\rangle+\sin\theta|0\rangle,\nonumber \\
|\psi_{2}\rangle & = & \cos\theta|1\rangle-\sin\theta|0\rangle,
\end{eqnarray}


similarly the clones yet to be optimized can be expressed as:

\begin{eqnarray}
|\phi_{1}\rangle & = & \cos\phi_{1}|1\rangle+\sin\phi_{1}|0\rangle,\nonumber \\
|\phi_{2}\rangle & = & \cos\phi_{2}|1\rangle-\sin\phi_{2}|0\rangle.
\end{eqnarray}


Using this general representation of input and output states and using
the overlap relation in \ref{eq:3.4.6} we see that the sum of the
output angles is fixed as $|\langle\psi_{1}|\psi_{2}\rangle|^{M}=\cos^{M}2\theta$
and $|\langle\phi_{1}|\phi_{2}\rangle|^{N}=\cos^{N}(\phi_{1}+\phi_{2})\Rightarrow$
$\cos^{M}2\theta=\cos^{N}(\phi_{1}+\phi_{2}).$ 

The global fidelity in terms of the angles becomes:

\begin{eqnarray}
F_{MN} & = & \eta_{1}|\left|\langle\psi_{1}|\phi_{1}\rangle\right|+\eta_{2}\left|\langle\psi_{2}|\phi_{2}\rangle\right|^{2},\\
 & = & \eta_{1}\left(\cos\theta\cos\phi_{1}+\sin\theta\sin\phi_{1}\right)+\eta_{2}\left(\cos\theta\cos\phi_{2}+\sin\theta\sin\phi_{2}\right),\nonumber \\
 & = & \eta_{1}\cos^{2}\left(\theta-\phi_{1}\right)+\eta_{2}\cos^{2}\left(\theta-\phi_{2}\right).
\end{eqnarray}


Rewriting the fidelity in terms of the sum and difference of the output
angles, 

\begin{eqnarray}
F_{MN} & = & \eta_{1}\cos^{2}\left(\theta-\frac{\phi_{1}+\phi_{2}}{2}-\frac{\phi_{1}-\phi_{2}}{2}\right)+\eta_{2}\cos^{2}\left(\theta-\frac{\phi_{1}+\phi_{2}}{2}+\frac{\phi_{1}-\phi_{2}}{2}\right),\nonumber \\
 & = & \eta_{1}\cos^{2}\left(\alpha-x\right)+\eta_{2}\cos^{2}\left(\alpha+x\right),\nonumber \\
 & = & \frac{1}{2}\left[\eta_{1}\left(\cos2(\alpha-x)+1\right)]+\frac{1}{2}[\eta_{2}\left(\cos2(\alpha+x)+1\right)\right],\nonumber \\
 & = & \frac{1}{2}\left[1+\eta_{1}(\cos2(\alpha-x)+\eta_{2}(\cos2(\alpha+x)\right],
\end{eqnarray}
 where $\alpha=\theta-\frac{\phi_{1}+\phi_{2}}{2}$ is fixed and $x=\frac{\phi_{1}-\phi_{2}}{2}$
is the only variable subject to optimization. Differentiating with
respect to $x$ we get

\begin{eqnarray}
\eta_{1}\sin(\alpha-x) & = & \eta_{2}\sin(\alpha-x)\nonumber \\
\eta_{1}\left[\sin2\alpha\cos2x-\cos2\alpha\cos2x\right] & = & \eta_{2}\left[\sin2\alpha\cos2x+\cos2\alpha\cos2x\right]\nonumber \\
(\eta_{1}-\eta_{2})\sin2\alpha\cos2x & = & \cos2\alpha\cos2x\nonumber \\
\left(\eta_{1}-\eta_{2}\right)\tan2\alpha & = & \tan2x\label{eq:tan2x}
\end{eqnarray}


This is the relationship that gives the optimal clones and $x$ should
be replaced in $F_{MN}$. To be able to use this relationship we re-express
$F_{MN}$ in a different way: 

\begin{eqnarray*}
F_{MN} & = & \frac{1}{2}\left[1+\eta_{1}\cos2(\alpha-x)+\eta_{2}\cos2(\alpha+x)\right],\\
 & = & \frac{1}{2}\left[\cos2\alpha\cos2x\left\{ 1+(\eta_{1}-\eta_{2})\tan2\alpha\tan2x\right\} \right]+\frac{1}{2},
\end{eqnarray*}
 we can rewrite (\ref{eq:tan2x}) as $(\eta_{1}-\eta_{2})\tan2\alpha=\frac{\sin2x}{\cos2x}$$\thinspace\cos2x=\frac{\sqrt{1-\cos^{2}2x}}{(\eta_{1}-\eta_{2})\tan2\alpha}=\frac{1}{\sqrt{1+(\eta_{1}-\eta_{2})^{2}\tan^{2}(2\alpha)}}.$
Finally the optimal fidelity can be expressed in terms of the a-priori
probabilities and the overlap of the input states only .

\begin{eqnarray}
F_{MN} & = & \frac{1}{2}\left[1+\cos2\alpha\cos2x\left\{ 1+\left(\eta_{1}-\eta_{2}\right)\tan2\alpha\tan2x\right\} \right],\nonumber \\
 & = & \frac{1}{2}\left[1+\frac{\cos2\alpha}{\sqrt{1+\left(\eta_{1}-\eta_{2}\right)^{2}\tan^{2}(2\alpha)}}\{1+\left(\eta_{1}-\eta_{2}\right)^{2}\tan^{2}2\alpha\right],\nonumber \\
 & = & \frac{1}{2}\left[1+\cos2\alpha\sqrt{1+\left(\eta_{1}-\eta_{2}\right)^{2}\tan^{2}2\alpha}\right],\nonumber \\
 & = & \frac{1}{2}\left[1+\sqrt{\cos^{2}2\alpha+\left(1-4\eta_{1}\eta_{2}\right)\sin^{2}2\alpha}\right],\nonumber \\
 & = & \frac{1}{2}\left[1+\sqrt{1-4\eta_{1}\eta_{2}\sin^{2}2\alpha}\right],\nonumber \\
 & = & \frac{1}{2}\left[1+\sqrt{1-4\eta_{1}\eta_{2}\sin^{2}\left(2\theta-\left(\phi_{1}+\phi_{2}\right)\right)}\right].\label{eq:fid}
\end{eqnarray}


In the asymptotic limit, producing infinitely many copies $N\rightarrow\infty$,
fidelity merges into the Helstrom bound in the discrimination of non-orthogonal
pure states. Using $\cos2\theta=s^{M}$, $\cos(\phi_{1}+\phi_{2})=s^{N}$
and expanding the $\sin$ term under the square root, 

\begin{eqnarray*}
\sin\left(2\theta-\left(\phi_{1}+\phi_{2}\right)\right) & = & \sin2\theta\cos\left(\phi_{1}+\phi_{2}\right)-\cos2\theta\sin\left(\phi_{1}+\phi_{2}\right)\\
 & = & \sqrt{1-\cos^{2}(2\theta)}\cos\left(\phi_{1}+\phi_{2}\right)-\cos2\theta\sin\left(\phi_{1}+\phi_{2}\right)\\
 & = & \sqrt{1-s^{2M}}s^{N}-s^{M}\sqrt{1-s^{2N}}\\
 & = & -s^{M}
\end{eqnarray*}


Substituting back into Eq. (\ref{eq:fid}) Helstrom bound emerges: 

\begin{equation}
F_{M\infty}=\frac{1}{2}[1+\sqrt{1-4\eta_{1}\eta_{2}\cos^{2}(2\theta)}]
\end{equation}


While the mathematics shows the convergence of Fidelity into optimal
minimum error state discrimination it is not clear as to why this
connection should exist at all. On the one hand fidelity optimizes
the average overlap between the clones and input states while ME state
discrimination minimizes the error rate of failing to distinguish
the incoming state. 

We will show the connection in the following two step process: first
measure and prepare then optimize the fidelity rate. 
\begin{itemize}
\item Step 1: Measure and prepare
\end{itemize}
Discriminate the incoming states $\left\{ \ket{\psi_{1}^{M}},\ket{\psi_{2}^{M}}\right\} $
with optimal ME then prepare states $\left\{ \ket{\psi_{1}^{N}},\ket{\psi_{2}^{N}}\right\} $
with the corresponding probabilities. 

\begin{eqnarray}
U|\psi_{1}^{M}\rangle|0\rangle & = & \sqrt{p_{1}}|\psi_{1}^{N}\rangle|1\rangle+\sqrt{r_{1}}|\psi_{2}^{N}\rangle|2\rangle,\\
U|\psi_{2}^{M}\rangle|0\rangle & = & \sqrt{r_{2}}|\psi_{1}^{N}\rangle|1\rangle+\sqrt{p_{2}}|\psi_{2}^{N}\rangle|2\rangle,
\end{eqnarray}


When state $\ket{\psi_{i}^{M}}$ is received we successfully prepare
the state $\ket{\psi_{i}^{N}}$ with probability $p_{i}$ and mistakenly
prepare the state $\ket{\psi_{j}^{N}}$ with probability $r_{i}$,
$i=1,2$.
\begin{itemize}
\item Step 2: Optimize the fidelity
\end{itemize}
The global fidelity for state $\ket{\psi_{1}^{N}}$ is

\begin{eqnarray*}
F_{1} & = & p_{1}|\braket{\psi_{1}}{\psi_{1}}|^{N}+r_{1}|\braket{\psi_{2}}{\psi_{1}}|^{2N},\\
 & = & p_{1}+r_{1}|\braket{\psi_{2}}{\psi_{1}}|^{2N}.
\end{eqnarray*}


Similarly for state $\ket{\psi_{2}^{N}}$ 

\[
F_{2}=p_{2}+r_{2}|\braket{\psi_{1}}{\psi_{2}}|^{2N}.
\]


The average fidelity for both states is:

\begin{eqnarray}
F_{MN} & = & \eta_{1}F_{1}+\eta_{2}F_{2}\nonumber \\
 & = & \eta_{1}\left(p_{1}+r_{1}|\braket{\psi_{2}}{\psi_{1}}|^{2N}\right)+\eta_{2}\left(p_{2}+r_{2}|\braket{\psi_{1}}{\psi_{2}}|^{2N}\right)\nonumber \\
 & = & \eta_{1}p_{1}+\eta_{2}p_{2}+\eta_{1}r_{1}s^{2N}+\eta_{2}r_{2}s^{2N}
\end{eqnarray}


It is now clear that in the asymptotic limit $N\rightarrow\infty$
fidelity reproduces the Helstrom bound $F_{MN}=\eta_{1}p_{1}+\eta_{2}p_{2}.$
However the relationship between optimal fidelity and optimal state
discrimination for a finite number of copies $N$ remains an open
question. 


\section{Hybrid Cloning: Interpolation between exact and approximate cloning }

In this section we seek to interpolate between probabilistic exact
cloning and approximate cloning machines using our results from state
separation. Exact cloning machines produce perfect clones while allowing
for some inconclusive outcomes. Approximate cloning machines produce
copies on demand which resemble the input states by maximizing the
fidelity. One can imagine a scheme where fidelity can be higher then
maximum fidelity in the approximate cloning machine while it allows
for a fixed rate of inconclusive outcomes, FRIO. This scheme should
reproduce exact cloning and approximate cloning machines by setting
FRIO to $Q_{o}$ and zero respectively. Chefles and Barnett \cite{Chefles1999}
solved the problem for the case when the input states are prepared
with equal a priori probabilities. We extend the solution to the more
general case when the states are prepared with different priors. Such
a solution is possible due to our recent work on making $N$ perfect
clones from $M$ copies of one of two known pure states with minimum
failure probability in the general case where the known states have
arbitrary priori probabilities.


\subsection{Equal priors}

The solution to the interpolation of cloning for equal a priori probabilities
has been derived by Chefles et al \cite{Chefles1999}. The authors
develop a scheme which, depending on the fidelity of the clones, can
interpolate between exact cloning with inconclusive results in one
extreme and optimal approximate cloning on the other extreme. In our
work this scheme has been generalized for the case when the input
states are prepared with different a priori probabilities. First we
show the derivation of the equal priors as it will help to better
understand the general case. 

For $\eta_{1}=\eta_{2}=1/2,$ the output states are symmetric, $\phi_{1}=\phi_{2}=\phi,$
and the optimal global fidelity, $F_{MN}$, in Eq.(\ref{eq:fid})
reduces to: 

\begin{eqnarray}
F_{MN} & = & \frac{1}{2}\left[1+\sqrt{1-\sin^{2}\left(2\theta-2\phi\right)}\right],\nonumber \\
 & = & \frac{1}{2}\left[1+\cos^{2}\left(2\theta-2\phi\right)\right].\\
\nonumber 
\end{eqnarray}
 

Duan and Guo \cite{Duan1998} showed that the maximum success probability
of obtaining $N$ exact clones from $M$ given copies of non-orthogonal
quantum states $\{|\psi_{1}\rangle,|\psi_{2}\rangle\}$, which are
prepared with equal a priori probabilities, is:

\begin{equation}
P_{MN}=\frac{1-s^{M}}{1-s^{N}},
\end{equation}
where $s$ is the overlap of the input states $s=\langle\psi_{1}|\psi_{2}\rangle.$
The success rate for 1 to 2 cloning, $M=1,N=2,$ reduces to:

\begin{equation}
P_{12}=\frac{1}{1+s}.
\end{equation}
The interpolation takes us from optimal exact cloning to maximum fidelity.
Given a set $K$ of two non-orthogonal quantum states, $\{|\psi_{1}\rangle,|\psi_{2}\rangle\}$
the goal is to make $N$ clones $\{|\phi_{1}\rangle,|\phi_{2}\rangle\}$,
which are similar to the input states but not perfect. The Neumark
setup is:

\begin{eqnarray}
U|\psi_{1}\rangle^{\otimes M}|i\rangle & = & \sqrt{p}|\phi_{1}\rangle^{\oplus N}|1\rangle+\sqrt{q}|f\rangle|0\rangle\label{eq:NeumarkClone1}\\
U|\psi_{2}\rangle^{\oplus M}|i\rangle & = & \sqrt{p}|\phi_{2}\rangle^{\oplus N}|1\rangle+\sqrt{q}|f\rangle|0\rangle\label{eq:NeumarkClone2}
\end{eqnarray}


The input states are prepared with equal a priori probabilities. A
click in the $|1\rangle$ direction means that we succeed in making
the clones and the probability of success is $p.$ A click in the
$|0\rangle$ direction means that we failed to create a clone with
a probability $q.$ The inner product or (\ref{eq:NeumarkClone1})
and (\ref{eq:NeumarkClone2}) gives the constraint: 

\begin{equation}
s^{M}=ps'^{N}+q
\end{equation}


Using the unitarity condition $p+q=1,$ the average rate of successfully
making a clone is:

\begin{equation}
p=\frac{1-s^{M}}{1-s'^{N}}
\end{equation}


$s'$ is the overlap of the clones $s'=\langle\phi_{1}|\phi_{2}\rangle$.
If the final states are orthogonal, $s'=0$ then the state separation
reaches the IDP limit and $P_{S}=P_{IDP}=1-|\langle\psi_{1}|\psi_{2}\rangle|^{M}.$ 

First we express the overlap of the output states in terms on the
success rates and the overlap of input states, $\cos2\theta=|\langle\psi_{1}|\psi_{2}\rangle|^{N}$

\begin{eqnarray}
|\langle\phi_{1}|\phi_{2}\rangle|^{N} & = & 1-\frac{1-|\langle\psi_{1}|\psi_{2}\rangle|^{M}}{P_{S}}\\
\cos^{N}(\phi_{1}+\phi_{2}) & = & 1-\frac{P_{IDP}}{P_{S}}\label{eq:seperation}
\end{eqnarray}
The exact clones live in an N dimensional space $|\psi_{1,2}^{N}\rangle=\cos\theta|1\rangle\pm\sin\theta|0\rangle.$
The approximate clones can be expressed as $|\phi_{1,2}\rangle=\cos\phi_{1}|1\rangle\pm\sin\phi_{1}|0\rangle$.

The fidelity rate for equal priors is:

\begin{equation}
F_{MN}=\frac{1}{2}\left[1+\cos(2\theta-\left(\phi_{1}+\phi_{2}\right)\right],
\end{equation}
 and we want to use the relationship in (\ref{eq:seperation}). Let
us expand the cosine term 

$\cos\left(2\theta-\left(\phi_{1}+\phi_{2}\right)\right)=\cos2\theta\cos\left(\phi_{1}+\phi_{2}\right)+\sin2\theta\sin\left(\phi_{1}+\phi_{2}\right).$

The fidelity becomes:

\begin{eqnarray*}
\\
F_{MN} & = & \frac{1}{2}\left[1+|\langle\psi_{1}^{N}|\psi_{2}^{N}\rangle|\left(1-\frac{P_{IDP}}{P_{S}}\right)+\frac{1}{P_{S}}(\left(1-|\langle\psi_{1}^{N}|\psi_{2}^{N}\rangle|^{2}\right)\left(P_{S}^{2}-\left(P_{S}-P_{IDP}\right)^{2}\right)^{1/2}\right]
\end{eqnarray*}
 As $N\rightarrow\infty,\thinspace|\langle\psi_{1}|\psi_{2}\rangle|^{N}\rightarrow0$
and $F_{MN}$ reduces to

\[
F_{MN}=\frac{1}{2}[1+\frac{1}{P_{S}}\sqrt{P_{S}^{2}-(P_{S}-P_{IDP})^{2}}].
\]


We can also express the fidelity in terms of fixed failure rate $Q=1-P_{S}$
which serves as the parameter by which we are interpolating and the
optimal failure rate $Q_{o}=\left|\langle\psi_{1}|\psi_{2}\rangle\right|$ 

\begin{eqnarray*}
F_{MN} & = & \frac{1}{2}\left[1+|\langle\psi_{1}^{N}|\psi_{2}^{N}\rangle|(1-\frac{1-Q_{o}}{1-Q})+\frac{1}{1-Q}(\left(1-|\langle\psi_{1}^{N}|\psi_{2}^{N}\rangle|^{2}\right)\left(\left(1-Q\right)^{2}-(Q-Q_{o})^{2}\right)^{1/2}\right],\\
 & = & \frac{1}{2\left(1-Q\right)}\left[(1-Q)+Q_{o}^{N}(Q_{o}-Q)+\sqrt{(1-Q_{o}^{2N})\left[(1-Q)^{2}-(Q-Q_{o})^{2}\right]}\right].
\end{eqnarray*}
In the limit $N\rightarrow\infty,\thinspace|\langle\psi_{1}|\psi_{2}\rangle|^{N}\rightarrow0$ 

\begin{eqnarray*}
F_{MN} & = & \frac{1}{2}\left[1+\frac{1}{1-Q}\sqrt{(1-Q)^{2}-(Q-Q_{o})^{2}}\right],\\
(1-Q)F_{MN} & = & \frac{1}{2}\left[(1-Q)+\sqrt{(1-Q)^{2}-(Q-Q_{o})^{2}}\right].
\end{eqnarray*}
$(1-Q)F_{MN}=P_{succes}$, the probability of successfully identifying
a state. 

\begin{eqnarray*}
P_{success} & = & \frac{1}{2}[(1-Q)+\sqrt{(1-Q)^{2}-(Q-Q_{o})^{2}}]
\end{eqnarray*}
(This is a different success rate then the $P_{S}$ defined above,
the $P_{S}$ was defined as the rate of successfully carrying out
a state separation. )

This formula describes the relationship between the discrimination
of states with a fixed rate of inconclusive outcome. When $Q=0$ it
reaches the Helstrom bound of minimum error and when $Q=Q_{o}$ it
reaches the IDP limit in UD. 


\subsection{General case}

We would like to generalize the above results for the case when the
incoming states are prepared with different prior probabilities. 
\begin{itemize}
\item Step 1: State Separation
\end{itemize}
Optimally separate the incoming states $\left\{ \ket{\psi_{1}^{M}},\ket{\psi_{2}^{M}}\right\} $
with a fixed rate of inconclusive results $q_{i}$, then prepare states
$\left\{ \ket{\psi_{1}^{N}},\ket{\psi_{2}^{N}}\right\} $ with the
corresponding success probabilities. 

\begin{eqnarray}
U|\psi_{1}^{M}\rangle|0\rangle & = & \sqrt{p_{1}}|\phi_{1}\rangle|1\rangle+\sqrt{q_{1}}|\Phi\rangle|2\rangle,\nonumber \\
U|\psi_{2}^{M}\rangle|0\rangle & = & \sqrt{p_{2}}|\phi_{2}\rangle|1\rangle+\sqrt{q_{2}}|\Phi\rangle|2\rangle,
\end{eqnarray}


The incoming states are separated with a success probability $p_{i}$
and failed to separate the states with a failure probability $q_{i}$.
The inner product of the two equations gives the unitarity constraint

\begin{equation}
s=\sqrt{p_{1}p_{2}}s'+\sqrt{q_{1}q_{2}}\label{eq:setaration constraint}
\end{equation}

\begin{itemize}
\item Step 2: Optimize Fidelity
\end{itemize}
The fidelity for state $\ket{\psi_{1}}$ is: $F_{1}=\left|\braket{\psi_{1}^{N}}{\phi_{1}}\right|^{2}$.
Similarly the fidelity for state $\ket{\psi_{2}}$is $\left|\braket{\psi_{2}^{N}}{\phi_{2}}\right|^{2}$.
The overall fidelity is

\[
F=\frac{\eta_{1}p_{1}F_{1}+\eta_{2}p_{2}F_{2}}{\eta_{1}p_{1}+\eta_{2}p_{2}}=\frac{\eta_{1}p_{1}F_{1}+\eta_{2}p_{2}F_{2}}{1-Q}=\tilde{\eta}_{1}F_{1}+\tilde{\eta}_{2}F_{2},
\]
where the normalized a priori probabilities are $\tilde{\eta}_{i}=\frac{\eta_{i}p_{i}}{1-Q}$.
The average fidelity is the same as calculated in (\ref{eq:fid})
with the new normalized probabilities: 

\begin{eqnarray}
F_{MN} & = & \frac{1}{2}\left[1+\sqrt{1-4\tilde{\eta}_{1}\tilde{\eta}_{2}\sin^{2}\left(2\theta-\left(\phi_{1}+\phi_{2}\right)\right)}\right],\nonumber \\
 & = & \frac{1}{2(1-Q)}\left[(1-Q)+\sqrt{\left(1-Q\right)^{2}-4\eta_{1}\eta_{2}p_{1}p_{2}\sin^{2}\left(2\theta-\left(\phi_{1}+\phi_{2}\right)\right)}\right],
\end{eqnarray}


It can be seen that in the limit $N\rightarrow\infty$, expanding
the $\sin$ term as we did in the previous section, the FRIO \cite{Bagan2012}
results are recovered. It again shows a close relationship between
fidelity and state discrimination. 

Solving the problem of hybrid cloning however requires one last optimization,
that of the second term under the square root

\begin{eqnarray*}
\Lambda & = & \sqrt{p_{1}p_{2}}\sin\left(2\theta-\left(\phi_{1}+\phi_{2}\right)\right),\\
 & = & \sqrt{p_{1}p_{2}}\sqrt{1-s^{2n}}s'-\sqrt{p_{1}p_{2}(1-s'^{2}})s^{n}\\
 & = & \sqrt{1-s^{2n}}\left(s-\sqrt{q_{1}q_{2}}\right)-s^{n}\sqrt{1-(q_{1}+q_{2})+q_{1}q_{2}-\left(s-\sqrt{q_{1}q_{2}}\right)^{2}},\\
 & = & \sqrt{1-s^{2n}}\left(s-u\right)-s^{n}\sqrt{1-s^{2}-2v+2sv}.
\end{eqnarray*}
Here $u\equiv\sqrt{q_{1}q_{2}},\hspace{0.5cm}v\equiv\frac{1}{2}\left(q_{1}+q_{2}\right)$
and we used the constraint from the unitarity in (\ref{eq:separation constraint})
to replace $\sqrt{p_{1}p_{2}}s'=s-\sqrt{q_{1}q_{2}}$. 


\chapter{Experimental realization to FRIO}

Choosing a physical system to realize quantum information processes,
which have otherwise been solved theoretically, is central challenge
to building a quantum computer. Some of the systems in use today are:
energy levels of ions, the orientation of nuclear spin, the presence
or absence of a photon in a cavity \cite{Cirac1995,Gershenfeld1997,Turchette1995,Domokos1995}
and dual rail representation of a qubit proposed by Milburn \cite{Milburn1989}
and later by Chuang and Yamamoto \cite{Chuang1996}. We will realize
the implementation of our works using the dual rail representation
of photons combined with a six-port, which is a linear device with
three input and three output ports. The six-port can be realized with
beamsplitters and phase shifters. First we will demonstrate the power
and simplicity of this system by working out the implementation of
UD following the work by Bergou $et$ $al.$ \cite{Bergou2009}. 

In our work \cite{shehu} we generalized the optical implementation
schemes to state discrimination which optimally interpolates between
UD and ME with a fixed rate of inconclusive results FRIO. Ever since
the interpolation scheme of a general measurement with FRIO was derived
by Bagan $et$ $al$ \cite{Bagan2012} there has been a quest for
a physical realization. The authors solved the problem using an operator
transformation technique that reformulated the intermediate problem
into a ME problem with an extra optimization parameter. Essentially
they reduced the problem from a three element POVM to two element
POVM similar to ME. Inspired by the work of Reck and Zeilinger \cite{Reck1994}
in which they prove that any discreet finite dimensional unitary operator
can be constructed in the lab as a multi-port interferometer using
beamsplitters and phase shifters we set out to solve the FRIO using
the Neumark setup as it lends itself into an optical implementation.
This gives us a closed form solution as in Bagan $et$ $al.$ In addition
it gives a three dimensional unitary operator where all the coefficients
are explicitly calculated in terms of a priori probabilities, overlap
of the input states and FRIO. Using the Reck $et$ $al.$ algorithm
the unitary is decomposed in terms of beam splitters with corresponding
coefficients of transmittance and reflectivity. The setup reduces
into the UD by setting the error rate to zero, in turn it reproduces
the work of Bergou $et\hspace{0.3cm}al$ \cite{Bergou2009}. At the
other extreme it produces the setup to ME for FRIO equal to zero. 


\section{Analytical Solution of Interpolation}

In this section we solve the interpolation with FRIO in two different
ways. In the first method, through a parametrization, the problem
is converted into a minimum error whose solution is well known. Then
there is one last optimization with respect to a FRIO. This method
generates the same solution as in Bagan $et$ $al$ in a few lines.
However to obtain an experimental realization we give an alternative
solution using Neumark's theorem. It is a generalized measurement
procedure in which the system is embedded in a larger Hilbert space
with extra degrees of freedom. A unitary transformation entangles
the system with the extra degree of freedom known as ancilla. After
this interaction has taken place, projective von Neumann measurements
are carried out on the ancilla. Our input states are qubits, which
can be expressed in general as unit length vectors in the two dimensional
basis spanned by $|1\rangle$ and $|2\rangle$. In the output of the
transformation, we associate the basis state $|1\rangle$ with $|\psi_{1}\rangle$,
$|2\rangle$ with $|\psi_{2}\rangle$, and $|0\rangle$ gives no information
about the system. The unitary transformation should do the following:

\begin{align}
U|\psi_{1}\rangle_{s}|0\rangle_{a} & =\sqrt{p_{1}}|1\rangle_{s}\ket 1_{a}+\sqrt{r_{1}}|2\rangle_{s}\ket 2_{a}+\sqrt{q_{1}}|0\rangle_{s}\ket 0_{a},\nonumber \\
U|\psi_{2}\rangle_{s}|0\rangle_{a} & =\sqrt{r_{2}}|1\rangle_{s}\ket 1_{a}+\sqrt{p_{2}}|2\rangle_{s}\ket 2_{a}+\sqrt{q_{2}}|0\rangle_{s}\ket 0_{a},\label{eq:frio constraint}
\end{align}
where: $p_{i}$ is the probability that state $i\thinspace(i=1,2)$
is correctly identified, $r_{i}$ is the probability that the detector
mistakenly identifies state $i$ for $j$, and $q_{i}$ is the failure
probability, the detector fails to identify the state at all. A click
in the ancilla $|0\rangle_{a}$ means the results are inconclusive
and we learn nothing from the measurement. From the unitarity conditions
we obtain the normalized probabilities $p_{i}+r_{i}+q_{i}=1$.

We wish to maximize the probability of success, $P_{s}=\eta_{1}p_{1}+\eta_{2}p_{2}$,
and minimize the error rate, $P_{e}=\eta_{1}r_{1}+\eta_{2}r_{2}$,
for a fixed failure rate $Q=\eta_{1}q_{1}+\eta_{2}q_{2}.$ Clearly
$P_{s}+P_{e}+Q=1$.

The inner product of the two equations in (\ref{eq:frio constraint})
gives the overlap of the input states in terms of $r_{i},\thinspace p_{i}$
and $q_{i}$, 
\begin{equation}
s=\sqrt{p_{1}r_{2}}+\sqrt{p_{2}r_{1}}+\sqrt{q_{1}q_{2}},\label{eq:general constraint}
\end{equation}
where $s\equiv\langle\psi_{1}|\psi_{2}\rangle$. This is a constraint
on the optimization of ME with a FRIO. First we show the solution
for the case when the input states are prepared with equal priors
for which the problem is fully solved from the constraint. It was
initially solved by Chefles and Barnett using a different approach
\cite{Chefles1998}. Then we solve the general case for different
priors and reproduce the results of Bagan $et\thinspace al.$ with
two different methods. 


\subsection{Equal priors. }

Let us first present the solution where the incoming states are given
with equal a-priori probabilities, $\eta_{1}=\eta_{2}=\frac{1}{2}$.
This implies equal error, success and failure rates: $r_{1}=r_{2}$
, $p_{1}=p_{2}$ and $q_{1}=q_{2}$. Thus the total error and failure
rates reduce to: $P_{E}=\eta_{1}r_{1}+\eta_{2}r_{2}=r$ and $Q=\eta_{1}q_{1}+\eta_{2}q_{2}=q.$ 

We can immediately solve the constraint in Equation (\ref{eq:general constraint})
by replacing $p=1-r-Q$, solving the quadratic equation for the error
rate in terms of the failure rate and overlap $s$, which is also
the overall failure rate in the IDP limit for the equal priors: $Q_{o}\equiv2\sqrt{\eta_{1}\eta_{2}}s=s$, 

\begin{eqnarray}
s & = & \sqrt{pr}+\sqrt{pr}+Q,\nonumber \\
Q_{o} & = & 2\sqrt{r(1-r-Q)}+Q,\nonumber \\
(Q_{o}-Q)^{2} & = & 4r(1-r-Q),\nonumber \\
\frac{1}{4}(Q_{o}-Q)^{2} & = & r(1-Q)-r^{2},\nonumber \\
0 & = & r^{2}-(1-Q)r+\frac{1}{4}(Q_{o}-Q)^{2}.\label{eq:quadratic IM}
\end{eqnarray}
Solving the quadratic equation and taking the smaller root, $i.e$
the smaller error rate:

\begin{eqnarray}
r=P_{E}=\frac{1}{2}[(1-Q)-\sqrt{(1-Q)^{2}-(Q_{o}-Q)^{2}}],\\
p=P_{S}=\frac{1}{2}[(1-Q)+\sqrt{(1-Q)^{2}-(Q_{o}-Q)^{2}}].
\end{eqnarray}


The equal priors case requires no further optimization. Simply solving
the quadratic equation in (\ref{eq:quadratic IM}) derived from the
constraint the optimal solution is carried out. By varying the failure
rate $Q$ from zero to $Q_{o}$ we recover the Helstrom and IDP bounds.
In the Helstrom bound \cite{Helstrom1969} one is not allowed to have
inconclusive results, hence setting failure rate to zero, $Q=0$ results
in 

\begin{equation}
P_{E}=\frac{1}{2}[1-\sqrt{1-Q_{o}^{2}}]
\end{equation}


In the IDP limit \cite{Ivanovic1987,Dieks1988,Peres1988} where one
is not allowed to make an error $r=0,$ while allowing for inconclusive
outcomes:

\begin{eqnarray*}
0 & = & \frac{1}{2}[(1-Q)-\sqrt{(1-Q)^{2}-(Q_{o}-Q)^{2}}],\\
Q & = & Q_{o},
\end{eqnarray*}
where $Q_{o}$ in the overlap of the input states for equal priors
$Q_{o}=s.$ 


\subsection{Arbitrary priors }

Because of the recent interest in this problem, we feel it is beneficial
to show two new and different approaches to its solution. The first
is more conceptual: a renormalization inspired by E. Bagan et al.
\cite{Bagan2012} allows us to rewrite the problem as a ME problem
with an implicit dependence on the last free parameter, the failure
rate of one state with relation to the other. This greatly simplifies
the problem as the solution to the first part is well known and the
second is a straight-forward derivative. The second solution employs
a Lagrange multiplier method that is algebraically difficult but useful
in its explicit results of individual error rates. This in turn is
useful in designing an implementation scheme where the reflective
and transmittance coefficients are expressed in terms of individual
error and success rate. 


\subsection{Transformation of the problem into the Helstrom form}

Through a renormalization our problem is converted into the well known
Helstrom form the solution of which is well known. First we define
the useful quantity $\omega\equiv s-\sqrt{q_{1}q_{2}}$ which will
serve as normalized overlap and the unitarity constraint from Eq.(\ref{eq:general constraint})
reduces to: 
\begin{equation}
\omega=\sqrt{p_{1}r_{2}}+\sqrt{p_{2}r_{1}}.
\end{equation}


Next we renormalize all probabilities in the problem: 
\begin{align}
 & \tilde{p}_{i}=\frac{p_{i}}{\alpha_{i}},\nonumber \\
 & \tilde{r_{i}}=\frac{r_{i}}{\alpha_{i}},\nonumber \\
 & \tilde{\omega}=\frac{\omega}{\alpha_{1}\alpha_{2}},\\
\nonumber 
\end{align}
where $\alpha_{i}=1-q_{i}$. Now the probabilities are normalized
$\widetilde{r}_{i}+\tilde{p}_{i}=1$, and the new normalized overlap
is in terms of $\tilde{r_{i}}$ and $\tilde{p}_{i},$

\begin{equation}
\tilde{\omega}=\sqrt{\tilde{p}_{1}\tilde{r}_{2}}+\sqrt{\tilde{p_{2}}\tilde{r}_{1}}
\end{equation}


Using the above transformation of $r_{i}$ the error rate can be expressed
as: 
\begin{equation}
\tilde{P}_{E}=\tilde{\eta}_{1}\tilde{r}_{1}+\tilde{\eta}_{2}\tilde{r}_{2},
\end{equation}
where $\tilde{P}_{E}=\frac{P_{E}}{\eta_{1}\alpha_{1}+\eta_{2}\alpha_{2}}=\frac{P_{E}}{1-Q},\tilde{\eta}_{i}=\frac{\eta_{i}\alpha_{i}}{\eta_{1}\alpha_{1}+\eta_{2}\alpha_{2}}=\frac{\eta_{i}\alpha_{i}}{1-Q}$
and $\tilde{\eta}_{1}+\tilde{\eta}_{2}=1$.

We have transformed the problem into a discrimination between two
pure states with overlap $\tilde{\omega}$ and no explicit failure
rate. Hence we can simply write down the expression for the minimum
error solution of two pure states (the Helstrom bound), and then replace
the normalized quantities with the original expressions: 
\begin{align}
\tilde{P}_{E} & =\frac{1}{2}[1-\sqrt{1-4\tilde{\eta}_{1}\tilde{\eta}_{2}\tilde{\omega}^{2}}],\nonumber \\
P_{E} & =\frac{1}{2}[(1-Q)-\sqrt{(1-Q)^{2}-4\eta_{1}\eta_{2}(s-\sqrt{q_{1}q_{2}})^{2}}].\label{eq:optimize P_e}
\end{align}


There is now one last optimization. Given a fixed rate of the average
of inconclusive outcomes, $Q,$ what are the individual failure rates
$q_{i}.$ To minimize Eq. (\ref{eq:optimize P_e}) we maximize the
square root term $\sqrt{(1-Q)^{2}-4\eta_{1}\eta_{2}(s-\sqrt{q_{1}q_{2}})^{2}},$
which in turn means to minimize $(s-\sqrt{q_{1}q_{2}})^{2}=(s^{2}+q_{1}q_{2}-2s\sqrt{q_{1}q_{2}}).$
The overlap term $s^{2}$ is fixed and we are left with $q_{1}q_{2}-2s\sqrt{q_{1}q_{2}.}$
Only one of the $q_{i}'s$ is an independent variable as we fix the
overall failure rate $Q=\eta_{1}q_{1}+\eta_{2}q_{2},$ 

\begin{eqnarray*}
\Theta & = & q_{1}q_{2}-2s\sqrt{q_{1}q_{2}.}\\
\Theta & = & \frac{q_{1}(Q_{0}-\eta_{1}q_{1}^{2})}{\eta_{2}}-2s\sqrt{\frac{q_{1}(Q_{0}-\eta_{1}q_{1}^{2})}{\eta_{2}}}\\
\Theta & = & \frac{\eta_{1}q_{1}Q_{0}-\eta_{1}^{2}q_{1}^{2}}{\eta_{1}\eta_{2}}-2s\sqrt{\frac{\eta_{1}q_{1}Q_{0}-\eta_{1}^{2}q_{1}^{2}}{\eta_{1}\eta_{2}}}\\
\Theta & = & \frac{\tilde{q}_{1}Q_{0}-\tilde{q}_{1}^{2}}{\eta_{1}\eta_{2}}-2s\sqrt{\frac{\tilde{q}_{1}Q_{0}-\tilde{q}_{1}^{2})}{\eta_{1}\eta_{2}}}
\end{eqnarray*}


where $\eta_{1}q_{1}=\tilde{q}.$ Let's optimize with respect to $\tilde{q}_{1}.$

\begin{equation}
0=\frac{\partial\Theta}{\partial\tilde{q}_{1}}=\frac{Q_{0}-2\tilde{q}_{1}}{\eta_{1}\eta_{2}}-2s\sqrt{\frac{Q_{0}-2\tilde{q}_{1}}{\eta_{1}\eta_{2}}}
\end{equation}


this leads to the optimality condition $Q_{0}=2\tilde{q}_{1}=2\eta_{1}q_{1}=2\eta_{2}q_{2},$
giving the minimal error rate in discriminating two pure states with
a fixed rate of failure as 
\begin{equation}
P_{E}=\frac{1}{2}[(1-Q)-\sqrt{(1-Q)^{2}-(Q_{o}-Q)^{2}}].\label{eq:frio}
\end{equation}
Here $Q_{o}=2\sqrt{\eta_{1}\eta_{2}}s$ is the failure rate in the
optimal unambiguous state discrimination, which our expression reaches
when we set $P_{E}=0$. On the other hand when the failure rate is
zero we can recover the Helstrom bound for two pure states $P_{E}=\frac{1}{2}[1-\sqrt{1-4\eta_{1}\eta_{2}s^{2}}].$ 


\section{Lagrange Multipliers Method}

While the above method gives a closed form solution of the average
error rate in terms of a FRIO it does not produce individual error
or success rates, i.e the error rates of mistaking state $|\psi_{i}\rangle$
for state $|\psi_{j}\rangle$ , which are needed for the implementation
in calculating the transmittance and reflection coefficients of the
beam splitters. To obtain these expressions we show another solution
to the interpolation using the Lagrange multipliers method with the
constraint in Eq. (\ref{eq:general constraint}). 

We want to minimize the average error rate $P_{E}=\eta_{1}r_{1}+\eta_{2}r_{2}$
subject to the constraint $s=\sqrt{(1-r_{1}-q_{1})r_{2}}+\sqrt{(1-r_{2}-q_{2})r_{1}}+\sqrt{q_{1}q_{2}},$
setting up the function with one Lagrange multiplier $\lambda:$ 

\begin{equation}
F=\eta_{1}r_{1}+\eta_{2}r_{2}+\lambda(s-\sqrt{(1-r_{1}-q_{1})r_{2}}-\sqrt{(1-r_{2}-q_{2})r_{1}}-\sqrt{q_{1}q_{2}}).
\end{equation}


Setting the derivative $dF_{(r_{1},r_{2},\lambda)}/dr_{i}$ to zero
then solving for $r_{i}(\lambda)$, we exploit the symmetry in the
resulting equations to solve for the individual error rates $r_{i}$
as a function of the failure rates $q_{i}$. Subsequent substitution
into the constraint gives us the optimal value of $\lambda$. Then
we can obtain the total minimum error by replacing the expressions
of $r_{i}$ into $P_{e}$ and minimizing $P_{e}$ under the additional
constraint that $\eta_{1}q_{1}+\eta_{2}q_{2}=Q$. This gives us the
optimal relationship between failure rates as $\eta_{1}q_{1}=\eta_{2}q_{2}$
and the total optimal error rate as $Q=2\eta_{1}q_{1}=2\eta_{2}q_{2}.$

Setting $dF/dr_{1}=0$ and re-arranging we get: 

\[
(2\eta_{1}/\lambda)\sqrt{(1-q_{1}-r_{1})r_{1}}=\sqrt{(1-q_{2}-r_{2})(1-q_{1}-r_{1})}-\sqrt{r_{1}r_{2}}.
\]


Similarly $dF/dr_{2}=0$ gives 
\begin{equation}
(2\eta_{2}/\lambda)\sqrt{(1-q_{2}-r_{2})r_{2}}=\sqrt{(1-q_{2}-r_{2})(1-q_{1}-r_{1})}-\sqrt{r_{1}r_{2}}.
\end{equation}


This step is algebraically challenging and requires the insight that
the resulting equations can each be separated into two expressions,
left hand side depending on only $r_{1}$ or $r_{2}$ and the right
hand sides are equivalent. Because both equations have the same multivariable
expression, we can set the left hand sides equal to a constant, $C,$
which is yet to be determined. 
\begin{equation}
(2\eta_{1}/\lambda)\sqrt{(1-q_{1}-r_{1})r_{1}}=(2\eta_{2}/\lambda)\sqrt{(1-q_{2}-r_{2})r_{2}}\equiv C.
\end{equation}
This greatly simplifies the problem, turning it into a quadratic equation. 

\begin{equation}
(2\eta_{i}/\lambda)\sqrt{(1-q_{i}-r_{i})r_{i}}=C.\label{eq:C}
\end{equation}
Let $\alpha_{i}\equiv1-q_{i}$ 
\begin{eqnarray*}
\sqrt{(\alpha_{1}-r_{i})r_{i}} & = & (\lambda C)/(2\eta_{i}),\\
r_{i}^{2}-\alpha_{i}r_{i}+\lambda^{2}C^{2}/4\eta_{i}^{2} & = & 0,\\
r_{i}(\pm) & = & 1/2\left(\alpha_{i}\pm\sqrt{\alpha_{i}^{2}-\frac{\lambda^{2}C^{2}}{\eta_{i}^{2}}}\right).
\end{eqnarray*}
$r_{i}$ is the error rate which we want to be minimized, thus we
take the smaller root $r_{i}(-).$ 

\begin{eqnarray}
r_{1} & = & 1/2\left(\alpha_{1}-\sqrt{\alpha_{1}^{2}-\frac{\delta}{\eta_{1}^{2}}}\right)=1/2\left(\alpha_{1}-A_{1}\right),\label{eq:r1(lambda)}\\
r_{2} & = & 1/2\left(\alpha_{2}-\sqrt{\alpha_{2}^{2}-\frac{\delta}{\eta_{2}^{2}}}\right)=1/2\left(\alpha_{2}-A_{2}\right),\label{eq:r2(lambda)}
\end{eqnarray}
 where $\delta\equiv\lambda^{2}C^{2}$ and $A_{i}\equiv\sqrt{\alpha_{i}^{2}-(\frac{\lambda^{2}C^{2}}{\eta_{i}^{2}})}.$ 

Insert the expression of $r_{i}$ from (\ref{eq:r1(lambda)}) and
(\ref{eq:r2(lambda)}) into the constraint from (\ref{eq:general constraint}).
First let us rewrite the constraint so it simplifies the algebra later: 

\[
\omega=(1-r_{1}-q_{1})r_{2}+(1-r_{2}-q_{2})r_{1}+\sqrt{(1-r_{1}-q_{1})(1-r_{2}-q_{2})r_{1}r_{2}}
\]


where $\omega\equiv(s-\sqrt{q_{1}q_{2}})^{2}$. We use the definition
in (\ref{eq:C}) to reduce the square root term

$\sqrt{(1-r_{1}-q_{1})(1-r_{2}-q_{2})r_{1}r_{2}}=\frac{\lambda^{2}C^{2}}{4\eta_{1}\eta_{2}},$
giving

\[
(s-\sqrt{q_{1}q_{2}})^{2}=(1-r_{1}-q_{1})r_{2}+(1-r_{2}-q_{2})r_{1}+\frac{\lambda^{2}C^{2}}{4\eta_{1}\eta_{2}}.
\]
Using $\alpha_{i}=1-q_{i},$ the above expression becomes:

\begin{eqnarray*}
\omega & = & (\alpha_{1}-q_{1})r_{2}+(\alpha_{2}-q_{2})r_{1}+\frac{\delta}{4\eta_{1}\eta_{2}}\\
 & = & \alpha_{1}r_{2}-\alpha_{2}r_{1}-2r_{1}r_{2}+\frac{\delta}{4\eta_{1}\eta_{2}}\\
 & = & \frac{\alpha_{1}}{2}\left(\alpha_{2}-A_{2}\right)+\frac{\alpha_{2}}{2}\left(\alpha_{1}-A_{1}\right)-\frac{1}{2}\left(\alpha_{1}-A_{1}\right)\left(\alpha_{2}-A_{2}\right)+\frac{\delta}{4\eta_{1}\eta_{2}}\\
 & = & \alpha_{1}\alpha_{2}-A_{1}A_{2}+\frac{\delta}{4\eta_{1}\eta_{2}}.
\end{eqnarray*}
Replacing $A_{i}$ by their respective value

\begin{eqnarray*}
\omega & = & \frac{1}{2}\left[\alpha_{1}\alpha_{2}-\sqrt{\alpha_{1}^{2}-\frac{\delta}{\eta_{1}^{2}}}\sqrt{\alpha_{2}^{2}-\frac{\delta}{\eta_{2}^{2}}}+\delta/\eta_{1}\eta_{2}\right],\\
\sqrt{\alpha_{1}^{2}-\frac{\delta}{\eta_{1}^{2}}}\sqrt{\alpha_{2}^{2}-\frac{\delta}{\eta_{2}^{2}}} & = & \alpha_{1}\alpha_{2}+\delta/\eta_{1}\eta_{2}-2\omega.
\end{eqnarray*}
Squaring both sides, using $\frac{\alpha_{1}}{\eta_{2}}+\frac{\alpha_{2}}{\eta_{1}}=\frac{\alpha_{1}\eta_{1}+\alpha_{2}\eta_{2}}{\eta_{1}\eta_{2}}=\frac{\eta_{1}(1-q_{1})+\eta_{2}(1-q_{2})}{\eta_{1}\eta_{2}}=\frac{1-Q}{\eta_{1}\eta_{2}}$
and after some trivial algebra we get:

\begin{eqnarray}
\delta\left[\frac{4\omega}{\eta_{1}\eta_{2}}-\left(\frac{\alpha_{1}}{\eta_{2}}+\frac{\alpha_{2}}{\eta_{1}}\right)\right] & = & 4\omega^{2}-4\omega\alpha_{1}\alpha_{2},\nonumber \\
\delta\left[\frac{4\omega}{\eta_{1}\eta_{2}}-\frac{(1-Q)^{2}}{\eta_{1}^{2}\eta_{2}^{2}}\right] & = & 4\omega^{2}-4\omega\alpha_{1}\alpha_{2},\nonumber \\
\delta & = & \frac{\left(\omega^{2}-\omega\alpha_{1}\alpha_{2}\right)4\eta_{1}^{2}\eta_{2}^{2}}{4\omega\eta_{1}\eta_{2}-(1-Q)^{2}},
\end{eqnarray}
Now substitute $\delta$ into $r_{1}$ in (\ref{eq:r1(lambda)}) 
\begin{eqnarray}
r_{1} & = & \frac{1}{2}\left(\alpha_{1}-\sqrt{\alpha_{1}^{2}-\frac{\lambda^{2}C^{2}}{\eta_{1}^{2}}}\right)\nonumber \\
 & = & \frac{1}{2}\left(\alpha_{1}-\sqrt{\alpha_{1}^{2}-\frac{1}{\eta_{1}^{2}}\frac{(\omega^{2}-\omega\alpha_{1}\alpha_{2})4\eta_{1}^{2}\eta_{2}^{2}}{4\omega\eta_{1}\eta_{2}-(1-Q)^{2}}}\right)\nonumber \\
 & = & \frac{1}{2}\left(\alpha_{1}-\sqrt{\frac{\alpha_{1}^{2}[4\omega\eta_{1}\eta_{2}-(1-Q)^{2}]-4\eta[\omega^{2}-\omega\alpha_{1}\alpha_{2}]}{4\omega\eta_{1}\eta_{2}-(1-Q)^{2}}}\right).
\end{eqnarray}


The numerator can be greatly simplified:

$\alpha_{1}^{2}[4\omega\eta_{1}\eta_{2}-(1-Q)^{2}]-4\eta_{2}^{2}[\omega^{2}-\omega\alpha_{1}\alpha_{2}]=-\alpha_{1}^{2}(1-Q)^{2}-4\eta_{2}^{2}\omega^{2}+4\omega\eta_{2}\alpha_{1}[\eta_{1}\alpha_{1}+\eta_{2}\alpha_{2}]$

$=-[\alpha_{1}(1-Q)-2\eta_{2}\omega]^{2}=-[(1-q_{1})(1-Q)-2\eta_{2}(s-\sqrt{q_{1}q_{2}})^{2}]^{2}.$

The calculation for $r_{2}$ goes along the same line. Expression
for $r_{1}$ and $r_{2}$ become:

\begin{eqnarray}
r_{1} & = & \frac{1}{2}\left[\left(1-q_{1}\right)-\frac{\left(1-q_{1}\right)\left(1-Q\right)-2\eta_{2}\left(s-\sqrt{q_{1}q_{2}}\right)^{2}}{\sqrt{(\left(1-Q\right))^{2}-4\eta_{1}\eta_{2}\left(s-\sqrt{q_{1}q_{2}}\right)^{2}}}\right],\\
r_{2} & = & \frac{1}{2}\left[\left(1-q_{2}\right)-\frac{\left(1-q_{2}\right)\left(1-Q\right)-2\eta_{1}\left(s-\sqrt{q_{1}q_{2}}\right)^{2}}{\sqrt{\left(1-Q\right)^{2}-4\eta_{1}\eta_{2}\left(s-\sqrt{q_{1}q_{2}}\right)^{2}}}\right].
\end{eqnarray}
Finally $r_{1}$ and $r_{2}$ can be substituted into the overall
average error rate $P_{E}=\eta_{1}r_{1}+\eta_{2}r_{2}:$ 

\begin{eqnarray}
P_{E} & = & \frac{1}{2}\left[1-\left(\eta_{1}q_{1}+\eta_{2}q_{2}\right)-\frac{\left(1-Q\right)\left(\eta_{1}+\eta_{2}\right)-\left(\eta_{1}q_{1}+\eta_{2}q_{2}\right)-4\eta_{1}\eta_{2}\left(s-\sqrt{q_{1}q_{2}}\right)^{2}}{\sqrt{\left(1-Q\right)^{2}-4\eta_{1}\eta_{2}\left(s-\sqrt{q_{1}q_{2}}\right)^{2}}}\right]\nonumber \\
 & = & \frac{1}{2}\left[(1-Q)-\frac{\left(1-Q\right)^{2}-4\eta_{1}\eta_{2}\left(s-\sqrt{q_{1}q_{2}}\right)^{2}}{\sqrt{\left(1-Q\right)^{2}-4\eta_{1}\eta_{2}\left(s-\sqrt{q_{1}q_{2}}\right)^{2}}}\right]\nonumber \\
 & = & \frac{1}{2}\left[(1-Q)-\sqrt{\left(1-Q\right)^{2}-4\eta_{1}\eta_{2}\left(s-\sqrt{q_{1}q_{2}}\right)^{2}}\right]\label{eq:P_E(q1,q2)}
\end{eqnarray}


It has been showed in previous sections that (\ref{eq:P_E(q1,q2)})
is optimized for a fixed value of failure rate when $\eta_{1}q_{1}=\eta_{2}q_{2}.$
Eq (\ref{eq:P_E(q1,q2)}) then reduces to the now well know FRIO form:

\begin{equation}
P_{E}=\frac{1}{2}\left[(1-Q)-\sqrt{(1-Q)^{2}-(Q-Q_{0})^{2}}\right].
\end{equation}


The individual error and success rates can now be expressed explicitly
in terms of $\eta_{i},$ $Q_{o}$ and most importantly the fixed failure
rate $Q$ as: 
\begin{align}
r_{i} & =\frac{1}{2}\left[\left(1-\frac{Q}{2\eta_{i}}\right)-\frac{\left(1-\frac{Q}{2\eta_{i}}\right)\left(1-Q\right)-\frac{1}{2\eta_{i}}(Q_{o}-Q)^{2}}{\sqrt{(1-Q)^{2}-(Q-Q_{o})^{2}}}\right],\label{eq:r_i}\\
p_{i} & =\frac{1}{2}\left[\left(1-\frac{Q}{2\eta_{i}}\right)+\frac{\left(1-\frac{Q}{2\eta_{i}}\right)\left(1-Q\right)-\frac{1}{2\eta_{i}}(Q_{o}-Q)^{2}}{\sqrt{(1-Q)^{2}-(Q-Q_{o})^{2}}}\right].\label{eq:p_i}
\end{align}


This is the first time that the individual error and failure rates
have been calculated. An immediate application is that it can now
be used in the calculations of the coefficients beam splitters. 


\section{Choosing the physical implementation }

The main reason to seek a solution using the Neumark setup is because
it lends itself to an optical implementation. This implementation,
as we will see, can be carried out using only linear optical elements
(beam splitters and a mirror). The possible states are represented
by single photons and a photodetector will carry out the measurement
process at the output. To choose the basis we start with the two mode
vacuum state $|00\rangle.$ The total number of photons in both modes
is one. This two dimensional Hilbert space where our photons live
can be spanned by the states $\{|10\rangle,|01\rangle\}$, where $|10\rangle=a_{1}^{\dagger}|00\rangle$
and $|01\rangle=a_{2}^{\dagger}|00\rangle$ and $a_{i}^{\dagger}$
are creation operators corresponding to two different modes of the
electromagnetic field. The basis $\{|10\rangle,|01\rangle\}$ corresponds
to the basis of qubit in $\{|0\rangle,|1\rangle\}.$ The most general
input state can be written as $|\psi_{i}\rangle=\alpha_{i}|0\rangle+\beta_{i}|1\rangle=\alpha_{i}|10\rangle+\beta_{i}|01\rangle$
which can be produced by sending a photon into a beam splitter with
some transmission and reflection coefficient, where the modes 1 and
2 correspond to the output modes of the beam splitter. 

A general $2N$ port is a linear device with $N$ input and $N$ output
ports. It can be constructed from beam splitters and mirrors \cite{Bergou2009}.
For our work we will need a six-port, three input ports and three
output ports. Let us denote the annihilation operators corresponding
to the input modes by $a_{j\text{\thinspace in }},$ $j=1,2,3$ then
the output operators are given by

\[
a_{j\text{\thinspace out }}=U^{-1}a_{i\text{\thinspace in }}U=\sum M_{jk}a_{k\text{\thinspace in }},
\]
where $M_{jk}$ are the elements of the $N\times N$ unitary matrix
$M.$ In the Schrodinger picture, the $in$ and $out$ states are
related by 

\[
\ket{\psi}_{out}=U\ket{\psi}_{in}.
\]
 In general an $in$ state that contains a single photon can be described
by

\[
\ket{\psi}_{in}=\sum_{j=1}^{3}c_{j}a_{j}^{\dagger}\ket{000},
\]
 where $\sum_{j=1}^{3}\left|c_{j}\right|=1.$ The output state is
given by

\begin{eqnarray*}
\ket{\psi}_{in} & = & U\sum_{j=1}^{3}c_{j}a_{j}^{\dagger}U^{-1}\ket{000}\\
 & = & \sum_{j,k=1}^{3}c_{j}M_{jk}^{T}a_{j}^{\dagger}\ket{000},
\end{eqnarray*}
where we have made use of the fact that the vacuum is invariant under
the transformation, $U$. To simplify the notation in the implementation
section let:$\ket{100}\equiv\ket 1,\thinspace\ket{010}\equiv\ket 2,\thinspace\ket{001}\equiv\ket 3.$ 


\section{Implementation: equal priors}

We will first show the implementation of FRIO for equal priors. The
Neumark in direct sum notation setup will be used to calculate the
unitary matrix. The two input states to be discriminated can be written
as $|\psi_{1}\rangle_{in}=|1\rangle$ and $|\psi_{2}\rangle_{in}=\cos\theta|1\rangle+\sin\theta|2\rangle$. 

\begin{eqnarray}
U|1\rangle & = & \sqrt{p}|1\rangle+\sqrt{r}|2\rangle+\sqrt{q}|3\rangle,\label{eq:eq1}\\
U(\cos\theta|1\rangle+\sin\theta|2\rangle) & = & \sqrt{r}|1\rangle+\sqrt{p}|2\rangle+\sqrt{q}|3\rangle,\label{eq:eq2}
\end{eqnarray}
where the error and success rate was calculated in section 4.1.1:
\begin{eqnarray}
r & = & \frac{1}{2}\left[(1-Q)-\sqrt{(1-Q)^{2}-(Q_{o}-Q)^{2}}\right],\label{eq:r}\\
p & = & \frac{1}{2}\left[(1-Q)+\sqrt{(1-Q)^{2}-(Q_{o}-Q)^{2}}\right],\label{eq:p}
\end{eqnarray}


From the Neumark setup we can read out six out of nine elements of
the unitary matrix. Eq. (\ref{eq:eq1}) gives the first column, Eq.
(\ref{eq:eq2}) gives the second column and the last column can be
constructed from the conditions of unitarity. 

To get first column, multiply Eq. (\ref{eq:eq1}) from the left with
$\bra 1,$ $\bra 2$ and $\bra 3:$

\[
\langle1|U|1\rangle=U_{11}=\sqrt{p},
\]
 

\[
\langle2|U|1\rangle=U_{21}=\sqrt{q},
\]


\[
\langle3|U|1\rangle=U_{31}=\sqrt{r}.
\]
To get the second column, multiply \ref{eq:eq2} from the left with
$\bra 1,$ $\bra 2$ and $\bra 3:$

\[
\cos\theta\langle1|U|1\rangle+\sin\theta\langle1|U|2\rangle=\cos\theta U_{11}+\sin\theta U_{12}=\sqrt{r},
\]


\[
\cos\theta\langle2|U|1\rangle+\sin\theta\langle2|U|2\rangle=\cos\theta U_{21}+\sin\theta U_{22}=\sqrt{p},
\]


\[
\cos\theta\langle3|U|1\rangle+\sin\theta\langle3|U|2\rangle=\cos\theta U_{31}+\sin\theta U_{32}=\sqrt{q}.
\]
 Using the solution of the first column $U_{i1}$, gives the entries
to second column $U_{i2}$ ($i=1,2,3),$ 

$\cos\theta\sqrt{p}_{1}+\sin\theta U_{12}=\sqrt{r_{2}}\Rightarrow$
$U_{12}=\frac{\sqrt{r}-\sqrt{p}Q_{o}}{\sqrt{1-Q_{o}^{2}}}$,

$\cos\theta\sqrt{q_{1}}+\sin\theta U_{22}=\sqrt{p_{2}}\Rightarrow$
$U_{22}=\frac{[\sqrt{p}-\sqrt{r}Q_{o}]}{\sqrt{1-Q_{o}^{2}}}$,

$\cos\theta\sqrt{r_{1}}+\sin\theta U_{32}=\sqrt{q_{2}}\Rightarrow$
$U_{32}=\sqrt{\frac{Q(1-Q_{o})}{1+Q_{o}}}$ ,

where $\cos\theta=Q_{o}$ and $\sin\theta=\sqrt{1-Q_{o}^{2}}$

The remaining elements be calculated from the conditions of the unitarity,
$U^{T}U=I$, $U_{i1}^{2}+U_{i2}^{2}+U_{i3}^{2}=1$ where $i=1,2,3$

$U_{13}=\pm\sqrt{1-U_{11}^{2}-U_{12}^{2}}=\pm\sqrt{1-p-\frac{r+pQ_{o}^{2}-2\sqrt{pr}Q_{0}}{1-Q_{0}^{2}}}=\pm\sqrt{\frac{Q-Q_{o}^{2}+2\sqrt{pr}Q_{0}}{1-Q_{0}^{2}}}=\pm\sqrt{\frac{Q}{1-Q_{0}}}$, 

the relation $\sqrt{pr}=\frac{1}{2}(Q_{o}-Q)$ was used, which is
derived from the multiplication of (\ref{eq:r}) and (\ref{eq:p}). 

$U_{23}=\pm\sqrt{1-U_{21}^{2}-U_{22}^{2}}=\pm\sqrt{1-r-\frac{p+rQ_{o}^{2}-2\sqrt{pr}Q_{0}}{1-Q_{0}^{2}}}=\pm\sqrt{\frac{Q}{1-Q_{0}}}$,

$U_{33}=\pm\sqrt{1-U_{31}^{2}-U_{32}^{2}}=\pm\sqrt{1-Q-\frac{Q(1-Q_{o})}{1+Q_{o}}}=\pm\sqrt{\frac{1+Q_{o}-2Q}{1+Q_{o}}}=\pm\frac{\sqrt{p}+\sqrt{r}}{\sqrt{1+Q_{o}}}$.

It is important to notice the relation $\sqrt{(1+Q_{o}-2Q)}=\sqrt{p}+\sqrt{r}$
which is somewhat unexpected. 

The full unitary, with the signs of the last column elements chosen
so that $U_{13}^{2}+U_{23}^{2}+U_{33}^{2}=1,$ is

\begin{equation}
U=\begin{pmatrix}\sqrt{p} & \frac{\sqrt{r}-\sqrt{p}Q_{o}}{\sqrt{1-Q_{o}^{2}}} & -\sqrt{\frac{Q}{1+Q_{o}}}\\
\sqrt{r} & \frac{\sqrt{p}-\sqrt{r}Q_{o}}{\sqrt{1-Q_{o}^{2}}} & -\sqrt{\frac{Q}{1+Q_{o}}}\\
\sqrt{Q} & \sqrt{\frac{Q(1-Q_{o})}{1+Q_{o}}} & \frac{\sqrt{p}+\sqrt{r}}{\sqrt{1+Q_{o}}}
\end{pmatrix}.\label{eq:U(equal prior)}
\end{equation}
In this representation the above matrix can be shown that it satisfies
all the unitary conditions. 

The unitary in (\ref{eq:U(equal prior)}) interpolates between the
optimal ME and UD schemes varying the fixed rate of inconclusive results
$Q.$ Setting the failure rate to zero, $Q=0,$ collapses it into
the unitary of optimal ME:

\[
U_{ME}=\begin{pmatrix}\sqrt{p} & \frac{\sqrt{r}-\sqrt{p}Q_{o}}{\sqrt{1-Q_{o}^{2}}} & 0\\
\sqrt{r} & \frac{\sqrt{p}-\sqrt{r}Q_{o}}{\sqrt{1-Q_{o}^{2}}} & 0\\
0 & 0 & 1
\end{pmatrix},
\]
which can be simplified further by noticing $(U_{12})^{2}=\left(\frac{\sqrt{r}-\sqrt{p}Q_{o}}{\sqrt{1-Q_{o}^{2}}}\right)^{2}=r,$
similarly $(U_{22})^{2}=\left(\frac{\sqrt{p}-\sqrt{r}Q_{o}}{\sqrt{1-Q_{o}^{2}}}\right)^{2}=p$,
simplifying the unitary into: 

\[
U_{ME}=\begin{pmatrix}\sqrt{p} & \sqrt{r} & 0\\
\sqrt{r} & -\sqrt{p} & 0\\
0 & 0 & 1
\end{pmatrix},
\]
only one beam splitter in needed for optimal ME measurements. 

On the other hand setting the error rate of the unitary \ref{eq:U(equal prior)}
to zero gives the optimal UD unitary,

\[
U_{UD}=\begin{pmatrix}\sqrt{p} & -\frac{\sqrt{p}Q_{o}}{\sqrt{1-Q_{o}^{2}}} & -\sqrt{\frac{Q_{0}}{1+Q_{o}}}\\
0 & \frac{\sqrt{p}}{\sqrt{1-Q_{o}^{2}}} & -\sqrt{\frac{Q_{o}}{1+Q_{o}}}\\
\sqrt{Q_{0}} & \sqrt{\frac{Q_{o}(1-Q_{o})}{1+Q_{o}}} & \sqrt{\frac{1-Q_{o}}{1+Q_{o}}}
\end{pmatrix}.
\]


All three beamsplitters are still necessary for a general UD measurement.
This is because the measurement is essentially two-step: in the first
step the states are made orthogonal, then upon succeeding a projective
measurement is performed. 

Let us now express the interpolating unitary in terms of three beamsplitters,
as $U=M_{1}M_{2}M_{3}$. This ordering was derived using the Reck-Zeilinger
algorithm which says that any discreet finite unitary matrix can be
expressed in terms of beamsplitters and phase shifters. The beamsplitters
can be written in terms of $\sin\omega_{i}$ and $\cos\omega_{i}$
and it is easy to check the unitarity condition, $\sin^{2}\omega_{i}+\cos^{2}\omega_{i}=1.$
Then the task is that of calculating $\omega_{i}.$

\[
M_{1}=\begin{pmatrix}\sin\omega & \cos\omega_{1} & 0\\
\cos\omega & -\sin\omega & 0\\
0 & 0 & 1
\end{pmatrix},
\]


\[
M_{2}=\begin{pmatrix}\sin\omega_{2} & 0 & \cos\omega_{2}\\
0 & 1 & 0\\
\cos\omega_{2} & 0 & -\sin\omega_{2}
\end{pmatrix},
\]


\[
M_{3}=\begin{pmatrix}1 & 0 & 0\\
0 & \sin\omega_{3} & \cos\omega_{3}\\
0 & \cos\omega_{3} & -\sin\omega_{3}
\end{pmatrix},
\]


\[
U=M_{1}M_{2}M_{3}=\begin{pmatrix}\sqrt{p} & \frac{\sqrt{r}-\sqrt{p}Q_{o}}{\sqrt{1-Q_{o}^{2}}} & \sqrt{\frac{Q}{1+Q_{o}}}\\
\sqrt{r} & \frac{[\sqrt{p}-\sqrt{r}Q_{o}]}{\sqrt{1-Q_{o}^{2}}} & \sqrt{\frac{Q}{1+Q_{o}}}\\
\sqrt{Q} & \sqrt{\frac{Q(1-Q_{o})}{1+Q_{o}}} & \sqrt{\frac{1+Q_{o}-2Q}{1+Q_{o}}}
\end{pmatrix}
\]


\[
=\begin{pmatrix}\sin\omega_{1}\sin\omega_{2} & \cos\omega_{1}\sin\omega_{3}+\sin\omega_{1}\cos\omega_{2}\cos\omega_{3} & \cos\omega_{1}\cos\omega_{3}-\sin\omega_{1}\cos\omega_{2}\sin\omega_{3}\\
\cos\omega_{1}\sin\omega_{2} & -\sin\omega_{1}\sin\omega_{3}+\cos\omega_{1}\cos\omega_{2}\cos\omega_{3} & -\sin\omega_{1}\cos\omega_{3}-\cos\omega_{1}\cos\omega_{2}\sin\omega_{3}\\
\cos\omega_{2} & -\sin\omega_{2}\cos\omega_{3} & \sin\omega_{2}\sin\omega_{3}
\end{pmatrix}.
\]


This gives nine equations and only three independent variables to
be calculated. All the elements can be obtained by using just $U_{31},U_{32},U_{21}:$ 

$\cos\omega_{2}=U_{31}=\sqrt{Q},\sin\omega_{2}=\sqrt{1-r^{2}}=\sqrt{1-Q}$, 

$\cos\omega_{3}=-\sqrt{\frac{Q(1-Q_{o})}{(1+Q_{o})(1-Q)}},\sin\omega_{3}=\sqrt{\frac{1+Q_{o}-2Q}{(1-Q)(1+Q_{o})}}=\frac{\sqrt{p}+\sqrt{r}}{\sqrt{(1-Q)(1+Q_{o})}}$, 

$\cos\omega_{1}=\sqrt{\frac{r}{1-Q}},\sin\omega_{1}=\sqrt{\frac{p}{1-Q}}$. 

The three beamsplitters with the proper coefficients of reflectivity
and transmittance are:

\[
M_{1}=\begin{pmatrix}\sqrt{\frac{p}{1-Q}} & \sqrt{\frac{r}{1-Q}} & 0\\
\sqrt{\frac{r}{1-Q}} & -\sqrt{\frac{p}{1-Q}} & 0\\
0 & 0 & 1
\end{pmatrix},
\]


\[
M_{2}=\begin{pmatrix}\sqrt{1-Q} & 0 & \sqrt{Q}\\
0 & 1 & 0\\
\sqrt{Q} & 0 & -\sqrt{1-Q}
\end{pmatrix},
\]


\[
M_{3}=\begin{pmatrix}1 & 0 & 0\\
0 & \sqrt{\frac{1+Q_{o}-2Q}{(1-Q)(1+Q_{o})}} & -\sqrt{\frac{Q(1-Q_{o})}{(1+Q_{o})(1-Q)}}\\
0 & -\sqrt{\frac{Q(1-Q_{o})}{(1+Q_{o})(1-Q)}} & -\sqrt{\frac{1+Q_{o}-2Q}{(1-Q)(1+Q_{o})}}
\end{pmatrix},
\]


\bigskip{}


By choosing the FRIO this matrix minimizes the error rate and maximizes
the rate of success. Hence, by setting the FRIO to zero we obtain
the setup to the minimum error problem. On the other hand, setting
the error rate to zero gives the setup of the optimal unambiguous
discrimination where the optimal inconclusive rate is the $Q_{o}=s$.
This simplifies the works of the experimentalists because now they
only need one setup and are not restrained to the extreme points.


\section{Implementation: Unequal priors}

In this section we derive the beamsplitter coefficients necessary
to interpolate minimum error measurements with a $FRIO$ when the
input states are prepared with different a priori probabilities. The
two input states to be discriminated are $|\psi_{1}\rangle_{in}=|1\rangle$
and $|\psi_{2}\rangle_{in}=\cos\theta|1\rangle+\sin\theta|2\rangle$.
A unitary operator carries out the operation:

\begin{align}
U|1\rangle & =\sqrt{p_{1}}|1\rangle+\sqrt{r_{1}}|2\rangle+\sqrt{q_{1}}|3\rangle,\label{eq:U1}\\
U(\cos\theta|1\rangle+\sin\theta|2\rangle) & =\sqrt{r_{2}}|1\rangle+\sqrt{p_{2}}|2\rangle+\sqrt{q_{2}}|3\rangle.\label{eq:U2}
\end{align}


The error and success rates where calculated in Section 4.1.4

\begin{align}
r_{i} & =\frac{1}{2}\left[(1-\frac{Q}{2\eta_{i}})-\frac{(1-\frac{Q}{2\eta_{i}})(1-Q)-\frac{1}{2\eta_{i}}(Q_{o}-Q)^{2}}{\sqrt{(1-Q)^{2}-(Q-Q_{o})^{2}}}\right],\\
p_{i} & =\frac{1}{2}\left[(1-\frac{Q}{2\eta_{i}})+\frac{(1-\frac{Q}{2\eta_{i}})(1-Q)-\frac{1}{2\eta_{i}}(Q_{o}-Q)^{2}}{\sqrt{(1-Q)^{2}-(Q-Q_{o})^{2}}}\right].
\end{align}


From the two equation in (\ref{eq:U1}) and (\ref{eq:U2}) we can
read out six of nine elements of the three by three unitary matrix.
Multiplying (\ref{eq:U1}) on the left hand side by $\{\langle1|,\bra 2,\bra 3\}$
will give the elements $U_{i1},$ $i=1,2,3.$ Similarly we can obtain
three more elements for the second column. 

The first column is:

$\langle1|U|1\rangle=U_{11}=\sqrt{p_{1}},$

$\langle2|U|1\rangle=U_{21}=\sqrt{q_{1}},$

$\langle3|U|1\rangle=U_{31}=\sqrt{r_{1}}.$

Second Column:

$\cos\theta\langle1|U|1\rangle+\sin\theta\langle1|U|2\rangle=\cos\theta U_{11}+\sin\theta U_{12}=\sqrt{r_{2}},$

$\cos\theta\langle2|U|1\rangle+\sin\theta\langle2|U|2\rangle=\cos\theta U_{21}+\sin\theta U_{22}=\sqrt{p_{2}},$

$\cos\theta\langle3|U|1\rangle+\sin\theta\langle3|U|2\rangle=\cos\theta U_{31}+\sin\theta U_{32}=\sqrt{q_{2}}$
.

Using the solution of the first column $U_{i1}$, gives the explicit
entries to second column $U_{i2}:$ 

$\cos\theta\sqrt{p}_{1}+\sin\theta U_{12}=\sqrt{r_{2}}\Rightarrow$
$U_{12}=\frac{\sqrt{r_{2}}-\sqrt{p_{1}}\cos\theta}{\sin\theta}$,

$\cos\theta\sqrt{q_{1}}+\sin\theta U_{22}=\sqrt{p_{2}}\Rightarrow$
$U_{22}=\frac{\sqrt{p_{2}}-\sqrt{r_{1}}\cos\theta}{\sin\theta}$,

$\cos\theta\sqrt{r_{1}}+\sin\theta U_{32}=\sqrt{q_{2}}\Rightarrow$
$U_{32}=\frac{\sqrt{q_{2}}-\sqrt{q_{1}}\cos\theta}{\sin\theta}$,

The last column be calculated from the conditions of the unitarity,
$U^{T}U=I$, $U_{i1}^{2}+U_{i2}^{2}+U_{i3}^{2}=1$ where $i=1,2,3$

$U_{13}=\pm\sqrt{1-U_{11}^{2}-U_{12}^{2}}=\pm\sqrt{1-p_{1}-\frac{r_{2}+p_{1}\cos\theta-2\sqrt{p_{1}r_{2}}\cos\theta}{\sin^{2}\theta}}=\pm\frac{\sqrt{\sin^{2}\theta-p_{1}-r_{2}+2\sqrt{p_{1}r_{2}}\cos\theta}}{\sin\theta}$.

Similarly:

$U_{23}=\pm\frac{\sqrt{\sin^{2}\theta-r_{1}-p_{2}+2\sqrt{p_{2}r_{1}}\cos\theta}}{\sin\theta},$

$U_{33}=\pm\frac{\sqrt{sin^{2}\theta-q_{1}-q_{2}+2\sqrt{q_{1}q_{2}}\cos\theta}}{\sin\theta}.$

Now that all the elements have been calculated the unitary is: 

\begin{equation}
U=\begin{pmatrix}\sqrt{p_{1}} & \frac{\sqrt{r_{2}}-\sqrt{p_{1}}\cos\theta}{\sin\theta} & -\frac{\sqrt{\sin^{2}\theta-p_{1}-r_{2}+2\sqrt{p_{1}r_{2}}\cos\theta}}{\sin\theta}\\
\sqrt{r_{1}} & \frac{\sqrt{p_{2}}-\sqrt{r_{1}}\cos\theta}{\sin\theta} & -\frac{\sqrt{\sin^{2}\theta-r_{1}-p_{2}+2\sqrt{p_{2}r_{1}}\cos\theta}}{\sin\theta}\\
\sqrt{q_{1}} & \frac{\sqrt{q_{2}}-\sqrt{q_{1}}\cos\theta}{\sin\theta} & +\frac{\sqrt{sin^{2}\theta-q_{1}-q_{2}+2\sqrt{q_{1}q_{2}}\cos\theta}}{\sin\theta}
\end{pmatrix}.
\end{equation}


\smallskip{}


It is worth mentioning that all equations in this section referencing
$r_{i}$ and $p_{i}$ are using the optimal values (\ref{eq:r_i})
and (\ref{eq:p_i}) derived in the previous section.

Now that we have a full unitary matrix we want to express it in terms
of linear optical devices. Again the Reck-Zeilinger algorithm is used
to decompose the unitary in terms of beamsplitters and their ordering
\ref{sixport}. The operator $U$ is decomposed into beamsplitters
in the order of $U=M_{1}\cdot M_{2}\cdot M_{3}$, and no phase shifters
are needed: 
\begin{align*}
M_{1} & =\begin{pmatrix}\sin\omega_{1} & \cos\omega_{1} & 0\\
\cos\omega_{1} & -\sin\omega_{1} & 0\\
0 & 0 & 1
\end{pmatrix},\\
M_{2} & =\begin{pmatrix}\sin\omega_{2} & 0 & \cos\omega_{2}\\
0 & 1 & 0\\
\cos\omega_{2} & 0 & -\sin\omega_{2}
\end{pmatrix},\\
M_{3} & =\begin{pmatrix}1 & 0 & 0\\
0 & \sin\omega_{3} & \cos\omega_{3}\\
0 & \cos\omega_{3} & -\sin\omega_{3}
\end{pmatrix},\\
\end{align*}


\bigskip{}


\begin{figure}
\includegraphics[width=8.5cm,height=8.5cm]{BeamSplitters}

\protect\caption[\hspace{1cm}Six port interferometer]{}


\label{sixport}
\end{figure}
where the coefficients of reflectivity and transmittance are given
by $\sqrt{R_{i}}=\sin\omega_{i}$ and $\sqrt{T_{i}}=\cos\omega_{i}$.

$U=M_{1}M_{2}M_{3}$=$\begin{pmatrix}\sqrt{p_{1}} & \frac{\sqrt{r_{2}}-\sqrt{p_{1}}cos\theta}{sin\theta} & \pm\frac{\sqrt{sin^{2}\theta-p_{1}-r_{2}+2\sqrt{p_{1}r_{2}}cos\theta}}{sin^{2}\theta}\\
\sqrt{r_{1}} & \frac{\sqrt{p_{2}}-\sqrt{r_{1}}cos\theta}{sin\theta} & \pm\frac{\sqrt{sin^{2}\theta-r_{1}-p_{2}+2\sqrt{p_{2}r_{1}}cos\theta}}{sin^{2}\theta}\\
\sqrt{q_{1}} & \frac{\sqrt{q_{2}}-\sqrt{q_{1}}cos\theta}{sin\theta} & \pm\frac{\sqrt{sin^{2}\theta-q_{1}-q_{2}+2\sqrt{q_{1}q_{2}}cos\theta}}{sin^{2}\theta}
\end{pmatrix}$ 

$=\begin{pmatrix}sin\omega_{1}sin\omega_{2} & cos\omega_{1}sin\omega_{3}+sin\omega_{1}cos\omega_{2}cos\omega_{3} & cos\omega_{1}cos\omega_{3}-sin\omega_{1}cos\omega_{2}sin\omega_{3}\\
cos\omega_{1}sin\omega_{2} & -sin\omega_{1}sin\omega_{3}+cos\omega_{1}cos\omega_{2}cos\omega_{3} & -sin\omega_{1}cos\omega_{3}-cos\omega_{1}cos\omega_{2}sin\omega_{3}\\
cos\omega_{2} & -sin\omega_{2}cos\omega_{3} & sin\omega_{2}sin\omega_{3}
\end{pmatrix}$ 

\bigskip{}


The coefficients of reflectivity and transmittance can be calculated
by matching the corresponding elements of the unitary and it's decomposition.
We can get all the elements by using just $U_{31},U_{32}$ and $U_{33}.$

$U_{31}=\sqrt{q_{1}}=\cos\omega_{2},\sin\omega_{2}=\sqrt{1-\cos\omega_{2}^{2}}=\sqrt{1-q_{1}}$, 

$U_{32}=\frac{\sqrt{q_{2}}-\sqrt{q_{1}}cos\theta}{sin\theta}=-\sin\omega_{2}\cos\omega_{3}=-\sqrt{1-q_{1}}\cos\omega_{3}\Rightarrow$
$\cos\omega_{3}=-\frac{1}{\sqrt{1-q_{1}}}[\frac{\sqrt{q_{2}}-\sqrt{q_{1}}cos\theta}{sin\theta}],$

$\sin\omega_{3}=\sqrt{1-\cos\omega_{3}}=-\frac{\sqrt{sin^{2}\theta-q_{1}-q_{2}+2\sqrt{q_{1}q_{2}}cos\theta}}{\sqrt{1-q_{1}}sin\theta},$

$U_{21}=\sqrt{r_{1}}=\cos\omega_{1}\sin\omega_{2}=\cos\omega_{1}\sqrt{1-q_{1}}\Rightarrow$
$\cos\omega_{1}=\sqrt{\frac{r_{1}}{1-q_{1}}},$

$\sin\omega_{1}=\sqrt{1-\cos\omega_{1}}=\sqrt{\frac{p_{1}}{1-q_{1}}}$. 

Substituting the coefficients of reflectivity and transmittance the
beamsplitters are:

$M_{1}=\begin{pmatrix}\sqrt{\frac{p_{1}}{1-q_{1}}} & \sqrt{\frac{r_{1}}{1-q_{1}}} & 0\\
\sqrt{\frac{r_{1}}{1-q_{1}}} & -\sqrt{\frac{p_{1}}{1-q_{1}}} & 0\\
0 & 0 & 1
\end{pmatrix},\,M_{2}=\begin{pmatrix}\sqrt{1-q_{1}} & 0 & \sqrt{q_{1}}\\
0 & 1 & 0\\
\sqrt{q_{1}} & 0 & -\sqrt{1-q_{1}}
\end{pmatrix},$

$M_{3}=\begin{pmatrix}1 & 0 & 0\\
0 & \frac{\sqrt{sin^{2}\theta-q_{1}-q_{2}+2\sqrt{q_{1}q_{2}}cos\theta}}{\sqrt{1-q_{1}}sin\theta} & -\frac{1}{\sqrt{1-q_{1}}}[\frac{\sqrt{q_{2}}-\sqrt{q_{1}}cos\theta}{sin\theta}]\\
0 & -\frac{1}{\sqrt{1-q_{1}}}[\frac{\sqrt{q_{2}}-\sqrt{q_{1}}cos\theta}{sin\theta}] & -\frac{\sqrt{sin^{2}\theta-q_{1}-q_{2}+2\sqrt{q_{1}q_{2}}cos\theta}}{\sqrt{1-q_{1}}sin\theta}
\end{pmatrix}$.

\bigskip{}


All the coefficients can be expressed in terms of the $FRIO$. Using
the optimal relationship between the individual failure rates $\eta_{1}q_{1}=\eta_{2}q_{2}=Q/2$,$\thinspace q_{1}=Q/2\eta_{1},\thinspace q_{2}=Q/2\eta_{2}$
and the above expressions of success and error rates. 

$\cos\omega_{1}=\sqrt{\frac{r_{1}}{1-Q/2\eta_{1}}}$ , $\sin\omega_{1}=\sqrt{\frac{p_{1}}{1-Q/2\eta_{1}}},$

$\cos\omega_{2}=\sqrt{Q/2\eta_{1}}$, $\sin\omega_{2}=\sqrt{1-Q/2\eta_{1}},$

$\cos\omega_{3}=-\frac{\sqrt{Q/2\eta_{2}}-Q_{o}/2\eta_{1}\sqrt{Q/2\eta_{2}}}{\sqrt{(1-Q/2\eta_{1})(1-Q_{o}^{2}/4\eta_{1}\eta_{2})}}$, 

$\sin\omega_{3}=\frac{\sqrt{1-Q_{o}^{2}/4\eta_{1}\eta_{2}-Q/(2\eta_{1}\eta_{2})+QQ_{o}/(2\eta_{1}\eta_{2})}}{\sqrt{(1-Q/2\eta_{1})(1-Q_{o}^{2}/4\eta_{1}\eta_{2})}},$

\bigskip{}


\[
M_{1}=\begin{pmatrix}\sqrt{\frac{p_{1}}{1-Q/2\eta_{1}}} & \sqrt{\frac{r_{1}}{1-Q/2\eta_{1}}} & 0\\
\sqrt{\frac{r_{1}}{1-Q/2\eta_{1}}} & -\sqrt{\frac{p_{1}}{1-Q/2\eta_{1}}} & 0\\
0 & 0 & 1
\end{pmatrix},
\]


\[
M_{2}=\begin{pmatrix}\sqrt{1-Q/2\eta_{1}} & 0 & \sqrt{Q/2\eta_{1}}\\
0 & 1 & 0\\
\sqrt{Q/2\eta_{1}} & 0 & -\sqrt{1-Q/2\eta_{1}}
\end{pmatrix},
\]


\[
M_{3}=\begin{pmatrix}1 & 0 & 0\\
0 & \frac{\sqrt{1-Q_{o}^{2}/4\eta_{1}\eta_{2}-Q/(2\eta_{1}\eta_{2})+QQ_{o}/(2\eta_{1}\eta_{2})}}{\sqrt{(1-Q/2\eta_{1})(1-Q_{o}^{2}/4\eta_{1}\eta_{2})}} & -\frac{\sqrt{Q/2\eta_{2}}-Q_{o}/2\eta_{1}\sqrt{Q/2\eta_{2}}}{\sqrt{(1-Q/2\eta_{1})(1-Q_{o}^{2}/4\eta_{1}\eta_{2})}}\\
0 & -\frac{\sqrt{Q/2\eta_{2}}-Q_{o}/2\eta_{1}\sqrt{Q/2\eta_{2}}}{\sqrt{(1-Q/2\eta_{1})(1-Q_{o}^{2}/4\eta_{1}\eta_{2})}} & -\frac{\sqrt{1-Q_{o}^{2}/4\eta_{1}\eta_{2}-Q/(2\eta_{1}\eta_{2})+QQ_{o}/(2\eta_{1}\eta_{2})}}{\sqrt{(1-Q/2\eta_{1})(1-Q_{o}^{2}/4\eta_{1}\eta_{2})}}
\end{pmatrix}.
\]
\vspace{0.05in}
 

Let us now check the bounds of the general unitary matrix for equal
priors to see if it reproduces the unitary in (\ref{eq:U(equal prior)}).
Indeed, everything checks out and the equal priors unitary matrix
is reproduced: 
\begin{equation}
U=\begin{pmatrix}\sqrt{p} & \frac{\sqrt{r}-\sqrt{p}Q_{o}}{\sqrt{1-Q_{o}^{2}}} & \sqrt{\frac{Q}{1+Q_{o}}}\\
\sqrt{r} & \frac{[\sqrt{p}-\sqrt{r}Q_{o}]}{\sqrt{1-Q_{o}^{2}}} & \sqrt{\frac{Q}{1+Q_{o}}}\\
\sqrt{Q} & \sqrt{\frac{Q(1-Q_{o})}{1+Q_{o}}} & -\frac{\sqrt{p}+\sqrt{r}}{\sqrt{1+Q_{o}}}
\end{pmatrix},
\end{equation}


In summary in this chapter we have shown that two nonorthogonal quantum
states, each realized as a photon split between two modes, in combination
with a six-port interferometer can be used to implement state discrimination
with FRIO. The implementation requires only optical elements: beam
splitters and mirrors. All the proper coefficients of transmittance
and reflectivity were calculated and we believe it should be possible
to construct the setup in a laboratory. The setup should give the
experimentalist more freedom when designing a quantum computation
network as now only one setup is needed to perform UD, ME and interpolate
with a fixed rate of inconclusive results. 


\chapter*{Appendix 1: Reck-Zeilinger Algorithm }

Optimizing the function $f(x_{1},x_{2},...,x_{n})$ we differentiate
with respect to all the independent variables $(x_{1},x_{2},...,x_{n})$
and follow the procedure defined above. 

In their letter \cite{Reck1994} prove that any discrete finite-dimensional
unitary operator can be constructed using optical devices only. Then
they provide a general algorithm which decomposes any $N$ $X$ $N$
unitary matrix into a product of two-dimensional $U(2)$ transformations
which can be expressed as beam splitters, phase shifters and mirrors.
This optical multi-port can act upon various fields such as electrons,
neutrons, atoms, photons etc. The authors decide to work with photons
purely for convenience and widespread availability of high power lasers.
It is this very proof which allows us to implement our various works
in state discrimination and cloning. In addition the proof has greatly
simplified the experimental realizations of many quantum computation,
quantum information and quantum cryptography schemes. Besides these
very practical applications it has also answered a long standing question:
Does an experiment measuring the variables corresponding to any arbitrary
Hermitian operator exists? They show that indeed an experimental realization
does exist for an arbitrary operator in a finite dimensional Hilbert
space. 

It has long been known that a lossless beam splitter and a phase shifter
can implement any $U(2)$ transformation: a beam splitter and a phase
shifter at one output port transforms the input operators into output
operators as 

\begin{equation}
\begin{pmatrix}a'_{1}\\
a'_{2}
\end{pmatrix}=\begin{pmatrix}e^{i\phi}\sin\omega & e^{i\phi}\cos\omega\\
\cos\omega & -\sin\omega
\end{pmatrix}\begin{pmatrix}a_{1}\\
a_{2}
\end{pmatrix},
\end{equation}
where, $\phi$ is the phase shifter which can be realized as an external
phase shifter after the beam splitter, $\omega$ represents the transmittance
and reflectivity coefficient, $\sqrt{T}=\cos\omega,$ $\sqrt{R}=\sin\omega.$
In their Letter, Reck $et$ $al.$ considered the use of a Mach-Zehner
interferometer to simulate the effect of a beam splitter which splits
the incoming beam according to the given parameters of transmittance
and reflectivity. For an actual two by two beam splitter the coefficients
of transmittance and reflectivity should be $\sqrt{T}=\sin\omega$
and $\sqrt{R}=\sin\theta.$

The authors show that starting with an $N$ $\times$ $N$ unitary
matrix $U(N),$ it can be expressed into a succession of two-dimensional
matrices which correspond to beam splitters and phase shifters. Hence
the $U(N)$ unitary matrix can be realized in the full $N$ dimensional
Hilbert space through a succession of two-dimensional $U(2)$ matrices. 

The order in which the matrices are multiplied correspond to the sequence
in which the beamsplitters are set up. The task of realizing the experimental
setup of an arbitrary unitary matrix becomes that of factorizing the
matrix in terms of two dimensional beam splitter matrices with phase
shifters which can be placed after the beam splitters. 

Define an $N-$dimensional identity matrix $T_{pq}$ which multiplies
the $N$ dimensional unitary matrix from the right to reduce the dimensionality
to $N-1.$ In the identity matrix $T_{pq}$ the elements $I_{pq},\;I_{pp},\;I_{qp},\;I_{qq}$
are replaced by the corresponding beam splitter matrix elements $(\cos\omega,\sin\omega)$.
Thus:

\begin{equation}
U(N)\times T_{N,N-1}\times T_{N,N-2}\times...T_{N,1}=\begin{pmatrix}U(N-1) & 0\\
0 & e^{i\phi}
\end{pmatrix}.
\end{equation}
This reduces the dimensionality of $U(N)$ to $U(N-1).$ The process
is repeated again until all the off diagonal elements of the original
unitary matrix are zero. 

\begin{equation}
U(N)\cdot T_{N,N-1}\cdot T_{N,N-2}\cdot...T_{N,1}\cdot T_{N-1,N-2}\cdot T_{N-2,N-2}\cdot...T_{2,1}\cdot...T_{2,1}=\begin{pmatrix}e^{i\alpha_{1}} & 0 & .. & 0\\
\vdots & e^{i\alpha_{2}}\\
 &  & \ddots\\
0 & \cdots &  & e^{i\alpha N}
\end{pmatrix}.
\end{equation}


Let:

\begin{equation}
D=\begin{pmatrix}e^{-i\alpha_{1}} & 0 & .. & 0\\
\vdots & e^{-i\alpha_{2}}\\
 &  & \ddots\\
0 & \cdots &  & e^{-i\alpha N}
\end{pmatrix}.
\end{equation}
Then we have 

\begin{equation}
U(N)\cdot T_{N,N-1}\cdot T_{N,N-2}\cdot...T_{N,1}\cdot T_{N-1,N-2}\cdot T_{N-2,N-2}\cdot...T_{2,1}\cdot D=I
\end{equation}
The unitary matrix can be expressed in terms of $Tp,q$ and $D:$ 

\begin{equation}
U(N)=D^{-1}\cdot T_{2,1}....\cdot T_{N-2,N-2}^{-1}\cdot T_{N-1,N-2}^{-1}\cdot T_{N,1}^{-1}....\cdot T_{N,N-2}^{-1}\cdot T_{N,N-1}^{-1}.\label{eq:reck-seilinger algorithm}
\end{equation}
 Since the product of matrices represents the order in which the beam
splitters are set up, then (\ref{eq:reck-seilinger algorithm}) is
all one needs to implement a finite dimensional unitary matrix. Since
this algorithm is recursive, it can factorize any finite dimensional
unitary operator. For example a $3\times3$ unitary matrix, three
beam splitters are needed $T_{21},T_{31},T_{32},$ a $4\times4$ unitary
matrix requires six beamsplitters $T_{4,3},T_{4,2},T_{4,1},T_{32},T_{31},T_{21}$
in reversed order. In general the maximum number of beam splitters
required for any $N$ dimensional unitary operator is $\begin{pmatrix}N\\
2
\end{pmatrix}=\frac{N(N-1)}{2}.$ In practice this method involves a triangular array of beamsplitters
(\ref{coherent}), with each diagonal row effectively reducing the
dimension of the Hilbert space by one.  

Let us now give an example to see explicitly how this algorithm works.
For a three dimensional unitary operator $U(3),$ the algorithm in
(\ref{eq:reck-seilinger algorithm}) gives:

\begin{equation}
U(3)=D^{-1}\times T_{2,1}^{-1}\times T_{3,1}^{-1}\times T_{3,2}^{-1}\label{eq:U(3)}
\end{equation}
where:

$D^{-1}=\begin{pmatrix}e^{i\alpha_{1}} & 0 & 0\\
0 & e^{i\alpha_{2}} & 0\\
0 & 0 & e^{i\alpha_{3}}
\end{pmatrix},\ T_{21}=\begin{pmatrix}\sin\omega_{1} & \cos\omega_{1} & 0\\
\cos\omega_{1} & -\sin\omega_{1} & 0\\
0 & 0 & 1
\end{pmatrix},$

\bigskip{}


$T_{31}=\begin{pmatrix}\sin\omega_{2} & 0 & \cos\omega_{2}\\
0 & 1 & 0\\
\cos\omega_{2} & 0 & -\sin\omega_{2}
\end{pmatrix},\thinspace T_{32}=\begin{pmatrix}1 & 0 & 0\\
0 & \sin\omega_{3} & \cos\omega_{3}\\
0 & \cos\omega_{3} & -\sin\omega_{3}
\end{pmatrix}.$

To obtain the transmittance and reflective coefficients match the
corresponding entries of $U_{ij}$ with the elements on right hand
side multiplying the three beam splitter matrix with the phase shifter
matrix. In the process nine equations and six independent unknowns
are produced. 



\begin{figure}
\includegraphics[width=8.5cm,height=8.5cm]{fig1-coherent}

\protect\caption[\hspace{1cm}NxN interferometer]{}


\label{coherent}
\end{figure}



\chapter*{Appendix 2: Lagrange Multipliers}

In our works we have relied quite heavily on the method of Lagrange
multipliers when optimizing a function which was under the restriction
of a constraint. We now show how it works \cite{Barnett2009}. The
method can be applied to a function of any number of variables but
it can be more clearly explained in two variables. Suppose that we
need to find the stationary points of a function $f(x,y),$ where
$x$ and $y$ are the two variables, subject to the constraint $g(x,y)=0.$
If the constraint is simple then we can solve for $x$ in terms of
$y,$ plug it into the function and solve $\partial f/\partial y=0.$
However for a more complicated constraint this can easily lead to
a very high order equation with cannot be solved analytically. In
the case of exact cloning, doing just so leads to a sixth order equation
which is of little use. 

To find the stationary points of a function of two variables such
as $f(x,y),$ we could just take the total differential $df$ and
set it to zero

\begin{equation}
df=\frac{\partial f}{\partial x}dx+\frac{\partial f}{\partial y}dy=0,\label{eq:lagrange 1}
\end{equation}
which leads to two conditions:

\begin{equation}
\frac{\partial f}{\partial x}=0,\ \ \frac{\partial f}{\partial y}=0.\label{eq:lagrange 0}
\end{equation}


However there is a constraint which means that the differentials $dx$
and $dy$ are not independent, they are related to the total differential
of $g$ by:

\begin{equation}
dg=\frac{\partial g}{\partial x}dx+\frac{\partial g}{\partial y}dy=0.\label{eq:lagrange 2}
\end{equation}


Multiplying (\ref{eq:lagrange 2}) by the Lagrange parameter $\lambda$
and adding it to (\ref{eq:lagrange 1}) we get 

\begin{equation}
d(f+\lambda g)=(\frac{\partial f}{\partial x}+\lambda\frac{\partial g}{\partial x})dx+(\frac{\partial f}{\partial y}+\lambda\frac{\partial g}{\partial y})dy
\end{equation}


This equation can be satisfied by choosing the Lagrange multiplier
$\lambda$ such that the following two conditions are satisfied:

\begin{equation}
\frac{\partial f}{\partial x}+\lambda\frac{\partial g}{\partial x}=0\label{eq:lagrange x}
\end{equation}


and

\begin{equation}
\frac{\partial f}{\partial y}+\lambda\frac{\partial g}{\partial y}=0\label{eq:lagrange y}
\end{equation}


To get the stationary points of $f(x,y)$ follow this procedure:
\begin{itemize}
\item Solve the two equations: (\ref{eq:lagrange x}) and (\ref{eq:lagrange y})
in terms of $\lambda,$ $x(\lambda)$ and $y(\lambda)$; 
\item Plug $x(\lambda)$ and $y(\lambda)$ into the constraint $g(x,y)$
;
\item Solve for $\lambda$; 
\item Plug the value of $\lambda$ into $x(\lambda)$ and $y(\lambda)$; 
\item Plug $x(\lambda)$ and $y(\lambda)$ into the function which was to
be optimized $f(x,y)$.
\end{itemize}
Now that we have seen how the Lagrange multipliers method works, we
can simplify the procedure by optimizing the function following function:

\begin{equation}
F(x,y)=f(x,y)+\lambda g(x,y)\label{eq:lagrange full}
\end{equation}
with respect to the the independent variable $x$ and $y.$ Differentiating
(\ref{eq:lagrange full}) with respect to $x$ and $y,$ we obtain
equations (\ref{eq:lagrange x}) and (\ref{eq:lagrange y}). The rest
of the procedure is the same. This is the exact procedure we used
for our works, for example in optimizing the error rate $P_{E}(r_{1},r_{2})$
with one constraint $s(r_{1},r_{2}).$ 



\bibliographystyle{unsrt}
\bibliography{/Users/ashehu/Desktop/mendeley}

\end{document}
